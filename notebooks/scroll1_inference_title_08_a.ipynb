{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb4nzBvLfZUj"
      },
      "source": [
        "#Vesuvius Scroll Challenge\n",
        "scroll 1 - pherc.paris4\n",
        "\n",
        "TITLE SEARCH\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Zxb1PzrbUx"
      },
      "source": [
        "#set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt9q1aNPezo-",
        "outputId": "06716868-f5dd-4fed-eff0-7108cb04f4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIsuYNU5glnV",
        "outputId": "0b1742a9-cb00-45ef-d641-66f0e4160920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 2,473 kB of archives.\n",
            "After this operation, 2,884 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.4 [1,680 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.1 [788 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.4 [5,712 B]\n",
            "Fetched 2,473 kB in 0s (17.5 MB/s)\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 123576 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.4_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.4) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.4) ...\n"
          ]
        }
      ],
      "source": [
        "!apt install python3.10-venv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BpUxZ7R8gdXC"
      },
      "outputs": [],
      "source": [
        "!python3 -m venv ~/scroll_venv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MVC-0_ClgrdZ"
      },
      "outputs": [],
      "source": [
        "!source ~/scroll_venv/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Jtwxk4NgwVL",
        "outputId": "2f9d6382-2d0f-4f4b-ac53-2eff8200e511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Collecting torchio\n",
            "  Downloading torchio-0.19.8-py2.py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Collecting Deprecated (from torchio)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting SimpleITK!=2.0.*,!=2.1.1.1 (from torchio)\n",
            "  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from torchio) (4.7.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from torchio) (4.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torchio) (1.11.4)\n",
            "INFO: pip is looking at multiple versions of torchio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchio\n",
            "  Downloading torchio-0.19.7-py2.py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchio-0.19.6-py2.py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer[all] in /usr/local/lib/python3.10/dist-packages (from torchio) (0.12.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.9.0-py2.py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->torchio) (1.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: typer 0.12.3 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (13.7.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer[all]->torchio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer[all]->torchio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer[all]->torchio) (0.1.2)\n",
            "Installing collected packages: SimpleITK, smmap, setproctitle, sentry-sdk, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, docker-pycreds, Deprecated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gitdb, nvidia-cusolver-cu12, gitpython, wandb, torchio\n",
            "Successfully installed Deprecated-1.2.14 SimpleITK-2.3.1 docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 sentry-sdk-2.9.0 setproctitle-1.3.3 smmap-5.0.1 torchio-0.19.6 wandb-0.17.4\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision pillow torchio tqdm wandb matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coP6-9N17di_",
        "outputId": "6e269b08-e8ed-4520-82f5-aa5b2f258499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts imagemagick-6-common\n",
            "  imagemagick-6.q16 libdjvulibre-text libdjvulibre21 libfftw3-double3 libgs9 libgs9-common libidn12\n",
            "  libijs-0.35 libjbig2dec0 libjxr-tools libjxr0 liblqr-1-0 libmagickcore-6.q16-6\n",
            "  libmagickcore-6.q16-6-extra libmagickwand-6.q16-6 libnetpbm10 libwmflite-0.2-7 netpbm\n",
            "  poppler-data\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf fonts-texgyre ghostscript-x imagemagick-doc\n",
            "  autotrace cups-bsd | lpr | lprng enscript gimp gnuplot grads hp2xx html2ps libwmf-bin mplayer\n",
            "  povray radiance sane-utils texlive-base-bin transfig ufraw-batch libfftw3-bin libfftw3-dev\n",
            "  inkscape poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts imagemagick\n",
            "  imagemagick-6-common imagemagick-6.q16 libdjvulibre-text libdjvulibre21 libfftw3-double3 libgs9\n",
            "  libgs9-common libidn12 libijs-0.35 libjbig2dec0 libjxr-tools libjxr0 liblqr-1-0\n",
            "  libmagickcore-6.q16-6 libmagickcore-6.q16-6-extra libmagickwand-6.q16-6 libnetpbm10\n",
            "  libwmflite-0.2-7 netpbm poppler-data\n",
            "0 upgraded, 26 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 25.1 MB of archives.\n",
            "After this operation, 87.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfftw3-double3 amd64 3.3.8-2ubuntu8 [770 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6-common all 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3 [63.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3 [1,788 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickwand-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3 [328 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.7 [752 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.7 [5,028 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ghostscript amd64 9.55.0~dfsg1-0ubuntu5.7 [49.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.5 [3,120 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6.q16 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3 [224 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3 [14.6 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdjvulibre-text all 3.5.28-2build2 [50.9 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdjvulibre21 amd64 3.5.28-2build2 [624 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjxr0 amd64 1.2~git20170615.f752187-5 [174 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjxr-tools amd64 1.2~git20170615.f752187-5 [16.0 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwmflite-0.2-7 amd64 0.2.12-5ubuntu1 [68.9 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6-extra amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3 [70.1 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libnetpbm10 amd64 2:10.0-15.4 [59.1 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/universe amd64 netpbm amd64 2:10.0-15.4 [1,007 kB]\n",
            "Fetched 25.1 MB in 0s (57.1 MB/s)\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 123591 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package libfftw3-double3:amd64.\n",
            "Preparing to unpack .../01-libfftw3-double3_3.3.8-2ubuntu8_amd64.deb ...\n",
            "Unpacking libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Selecting previously unselected package liblqr-1-0:amd64.\n",
            "Preparing to unpack .../02-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n",
            "Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Selecting previously unselected package imagemagick-6-common.\n",
            "Preparing to unpack .../03-imagemagick-6-common_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6:amd64.\n",
            "Preparing to unpack .../04-libmagickcore-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libmagickwand-6.q16-6:amd64.\n",
            "Preparing to unpack .../05-libmagickwand-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../06-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../07-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../08-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.55.0~dfsg1-0ubuntu5.7_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.7) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../10-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../11-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../12-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../13-libgs9_9.55.0~dfsg1-0ubuntu5.7_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.7) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../14-ghostscript_9.55.0~dfsg1-0ubuntu5.7_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.7) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../15-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.5_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Selecting previously unselected package imagemagick-6.q16.\n",
            "Preparing to unpack .../16-imagemagick-6.q16_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package imagemagick.\n",
            "Preparing to unpack .../17-imagemagick_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libdjvulibre-text.\n",
            "Preparing to unpack .../18-libdjvulibre-text_3.5.28-2build2_all.deb ...\n",
            "Unpacking libdjvulibre-text (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libdjvulibre21:amd64.\n",
            "Preparing to unpack .../19-libdjvulibre21_3.5.28-2build2_amd64.deb ...\n",
            "Unpacking libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libjxr0:amd64.\n",
            "Preparing to unpack .../20-libjxr0_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libjxr-tools.\n",
            "Preparing to unpack .../21-libjxr-tools_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libwmflite-0.2-7:amd64.\n",
            "Preparing to unpack .../22-libwmflite-0.2-7_0.2.12-5ubuntu1_amd64.deb ...\n",
            "Unpacking libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6-extra:amd64.\n",
            "Preparing to unpack .../23-libmagickcore-6.q16-6-extra_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libnetpbm10.\n",
            "Preparing to unpack .../24-libnetpbm10_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking libnetpbm10 (2:10.0-15.4) ...\n",
            "Selecting previously unselected package netpbm.\n",
            "Preparing to unpack .../25-netpbm_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking netpbm (2:10.0-15.4) ...\n",
            "Setting up imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Setting up libnetpbm10 (2:10.0-15.4) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up netpbm (2:10.0-15.4) ...\n",
            "Setting up libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up libdjvulibre-text (3.5.28-2build2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.7) ...\n",
            "Setting up libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.7) ...\n",
            "Setting up libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.7) ...\n",
            "Setting up libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3) ...\n",
            "Setting up libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3) ...\n",
            "Setting up libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3) ...\n",
            "Setting up imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3) ...\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare (compare) in auto mode\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare-im6 (compare-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate (animate) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate-im6 (animate-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert (convert) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert-im6 (convert-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite (composite) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite-im6 (composite-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure (conjure) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure-im6 (conjure-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import (import) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import-im6 (import-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify (identify) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify-im6 (identify-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream (stream) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream-im6 (stream-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display (display) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display-im6 (display-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage (montage) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage-im6 (montage-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify (mogrify) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify-im6 (mogrify-im6) in auto mode\n",
            "Setting up imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install imagemagick\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjLBu9qarkMj"
      },
      "source": [
        "##install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk6C4991CbN6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_INCbCNqH_rQ"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/younader/Vesuvius-First-Letters.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTnViEOQqdtE",
        "outputId": "c583acce-0791-458c-f14a-23b3102e5e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/A_Scroll/inkception-3d\n"
          ]
        }
      ],
      "source": [
        "#%cd /content/drive/MyDrive/inkception-3d\n",
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX9K3ul_qdvk",
        "outputId": "30fb1714-365a-43ac-b1ee-5bd4cf097051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm@ git+https://github.com/rwightman/pytorch-image-models.git@95ba90157fbbee293e8d10ac108ced2d9b990cbc (from -r requirements.txt (line 225))\n",
            "  Cloning https://github.com/rwightman/pytorch-image-models.git (to revision 95ba90157fbbee293e8d10ac108ced2d9b990cbc) to /tmp/pip-install-r3_gv09_/timm_b6b2a2526a1847238393ffff33f34853\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rwightman/pytorch-image-models.git /tmp/pip-install-r3_gv09_/timm_b6b2a2526a1847238393ffff33f34853\n",
            "  Running command git rev-parse -q --verify 'sha^95ba90157fbbee293e8d10ac108ced2d9b990cbc'\n",
            "  Running command git fetch -q https://github.com/rwightman/pytorch-image-models.git 95ba90157fbbee293e8d10ac108ced2d9b990cbc\n",
            "  Running command git checkout -q 95ba90157fbbee293e8d10ac108ced2d9b990cbc\n",
            "  Resolved https://github.com/rwightman/pytorch-image-models.git to commit 95ba90157fbbee293e8d10ac108ced2d9b990cbc\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting absl-py==0.15.0 (from -r requirements.txt (line 1))\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aicrowd-cli==0.1.15 (from -r requirements.txt (line 2))\n",
            "  Downloading aicrowd_cli-0.1.15-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles==22.1.0 (from -r requirements.txt (line 3))\n",
            "  Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiohttp==3.8.5 (from -r requirements.txt (line 4))\n",
            "  Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.3.1)\n",
            "Collecting aiosqlite==0.18.0 (from -r requirements.txt (line 6))\n",
            "  Downloading aiosqlite-0.18.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: albumentations==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.3.1)\n",
            "Collecting anyio==3.6.2 (from -r requirements.txt (line 8))\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs==1.4.3 (from -r requirements.txt (line 9))\n",
            "  Downloading appdirs-1.4.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting argon2-cffi==21.3.0 (from -r requirements.txt (line 10))\n",
            "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (21.2.0)\n",
            "Collecting arrow==1.2.3 (from -r requirements.txt (line 12))\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astunparse==1.6.2 (from -r requirements.txt (line 13))\n",
            "  Downloading astunparse-1.6.2-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: async-timeout==4.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (4.0.3)\n",
            "Collecting atomicwrites==1.1.5 (from -r requirements.txt (line 15))\n",
            "  Downloading atomicwrites-1.1.5-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting attrs==19.3.0 (from -r requirements.txt (line 16))\n",
            "  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting Automat==0.8.0 (from -r requirements.txt (line 17))\n",
            "  Downloading Automat-0.8.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting Babel==2.12.1 (from -r requirements.txt (line 18))\n",
            "  Downloading Babel-2.12.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backcall==0.1.0 (from -r requirements.txt (line 19))\n",
            "  Downloading backcall-0.1.0.zip (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beautifulsoup4==4.8.2 (from -r requirements.txt (line 20))\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bleach==3.1.1 (from -r requirements.txt (line 21))\n",
            "  Downloading bleach-3.1.1-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: blinker==1.4 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 22)) (1.4)\n",
            "Collecting blosc==1.7.0 (from -r requirements.txt (line 23))\n",
            "  Downloading blosc-1.7.0.tar.gz (756 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.8/756.8 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cachetools==4.0.0 (from -r requirements.txt (line 25))\n",
            "  Downloading cachetools-4.0.0-py3-none-any.whl (10 kB)\n",
            "Collecting flake8==3.7.9 (from -r requirements.txt (line 27))\n",
            "  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers==1.12 (from -r requirements.txt (line 28))\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting fonttools==4.39.0 (from -r requirements.txt (line 29))\n",
            "  Downloading fonttools-4.39.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fqdn==1.5.1 (from -r requirements.txt (line 30))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting frozenlist==1.4.0 (from -r requirements.txt (line 31))\n",
            "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec==2023.9.2 (from -r requirements.txt (line 32))\n",
            "  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting future==0.18.2 (from -r requirements.txt (line 33))\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gast==0.4.0 (from -r requirements.txt (line 34))\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting gitdb==4.0.10 (from -r requirements.txt (line 35))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython==3.1.18 (from -r requirements.txt (line 36))\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.1/170.1 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Glances==3.1.3 (from -r requirements.txt (line 37))\n",
            "  Downloading Glances-3.1.3.tar.gz (44.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting google-auth==1.5.1 (from -r requirements.txt (line 38))\n",
            "  Downloading google_auth-1.5.1-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib==0.4.1 (from -r requirements.txt (line 39))\n",
            "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (0.2.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement grpcio==1.29.1 (from versions: 0.4.0a0, 0.4.0a1, 0.4.0a2, 0.4.0a3, 0.4.0a4, 0.4.0a5, 0.4.0a6, 0.4.0a7, 0.4.0a8, 0.4.0a13, 0.4.0a14, 0.5.0a0, 0.5.0a1, 0.5.0a2, 0.9.0a0, 0.9.0a1, 0.10.0a0, 0.11.0b0, 0.11.0b1, 0.12.0b0, 0.13.0, 0.13.1rc1, 0.13.1, 0.14.0rc1, 0.14.0, 0.15.0, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1rc1, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.1.0, 1.1.3, 1.2.0, 1.2.1, 1.3.0, 1.3.5, 1.4.0, 1.6.0, 1.6.3, 1.7.0, 1.7.3, 1.8.1, 1.8.2, 1.8.3, 1.8.4, 1.8.6, 1.9.0rc1, 1.9.0rc2, 1.9.0rc3, 1.9.0, 1.9.1, 1.10.0rc2, 1.10.0, 1.10.1rc1, 1.10.1rc2, 1.10.1, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.11.1rc1, 1.11.1, 1.12.0rc1, 1.12.0, 1.12.1, 1.13.0rc1, 1.13.0rc2, 1.13.0rc3, 1.13.0, 1.14.0rc1, 1.14.0rc2, 1.14.0, 1.14.1, 1.14.2rc1, 1.14.2, 1.15.0rc1, 1.15.0, 1.16.0rc1, 1.16.0, 1.16.1, 1.17.0, 1.17.1, 1.18.0, 1.19.0, 1.20.0rc1, 1.20.0rc2, 1.20.0rc3, 1.20.0, 1.20.1, 1.21.0rc1, 1.21.1rc1, 1.21.1, 1.22.0rc1, 1.22.0, 1.22.1, 1.23.0rc1, 1.23.0, 1.23.1, 1.24.0rc1, 1.24.0, 1.24.1, 1.24.3, 1.25.0rc1, 1.25.0, 1.26.0rc1, 1.26.0, 1.27.0rc1, 1.27.0rc2, 1.27.1, 1.27.2, 1.28.0rc1, 1.28.0rc2, 1.28.1, 1.29.0, 1.30.0, 1.31.0, 1.32.0, 1.33.1, 1.33.2, 1.34.0rc1, 1.34.0, 1.34.1, 1.35.0rc1, 1.35.0, 1.36.0rc1, 1.36.0, 1.36.1, 1.37.0rc1, 1.37.0, 1.37.1, 1.38.0rc1, 1.38.0, 1.38.1, 1.39.0rc1, 1.39.0, 1.40.0rc1, 1.40.0, 1.41.0rc2, 1.41.0, 1.41.1, 1.42.0rc1, 1.42.0, 1.43.0rc1, 1.43.0, 1.44.0rc1, 1.44.0rc2, 1.44.0, 1.45.0rc1, 1.45.0, 1.46.0rc1, 1.46.0rc2, 1.46.0, 1.46.1, 1.46.3, 1.46.5, 1.47.0rc1, 1.47.0, 1.47.2, 1.47.5, 1.48.0rc1, 1.48.0, 1.48.1, 1.48.2, 1.49.0rc1, 1.49.0rc3, 1.49.0, 1.49.1, 1.50.0rc1, 1.50.0, 1.51.0rc1, 1.51.0, 1.51.1, 1.51.3, 1.52.0rc1, 1.52.0, 1.53.0rc2, 1.53.0, 1.53.1, 1.53.2, 1.54.0rc1, 1.54.0, 1.54.2, 1.54.3, 1.55.0rc1, 1.55.0, 1.55.3, 1.56.0rc2, 1.56.0, 1.56.2, 1.57.0rc1, 1.57.0, 1.58.0rc1, 1.58.0, 1.59.0rc1, 1.59.0, 1.59.2, 1.59.3, 1.60.0rc1, 1.60.0, 1.60.1, 1.62.0rc1, 1.62.0, 1.62.1, 1.62.2, 1.63.0rc1, 1.63.0rc2, 1.63.0, 1.64.0rc1, 1.64.0, 1.64.1, 1.65.0rc1, 1.65.0rc2, 1.65.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for grpcio==1.29.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6ZFzd3GrJqU",
        "outputId": "22c4d6df-dc41-4ceb-a453-2d14547d8157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.4-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pytorch_lightning) (12.5.82)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->pytorch_lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->pytorch_lightning) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.11.4 pytorch_lightning-2.3.3 torchmetrics-1.4.0.post0\n",
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.18.0+cu121)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation_models_pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.0+cu121)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.23.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.5.82)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=23b16096ebdc428b6bd11bdbbfcf01d0e2cad732033f9a088551a21f948fd750\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=2a47f6083bee26bc4236ae95efca7176764530707f9fc281e8ae0404e3d89165\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3 timm-0.9.2\n",
            "Collecting warmup_scheduler\n",
            "  Downloading warmup_scheduler-0.3.tar.gz (2.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: warmup_scheduler\n",
            "  Building wheel for warmup_scheduler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warmup_scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2967 sha256=689463a70e446352b04cf81da1a9e6083ea612d5d0b2ca41e2f07fcfc95188a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/01/9e/d1820991c32916e9808c940f572b462f3e46427f3e76c4d852\n",
            "Successfully built warmup_scheduler\n",
            "Installing collected packages: warmup_scheduler\n",
            "Successfully installed warmup_scheduler-0.3\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.4)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.9.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Collecting typed-argument-parser\n",
            "  Downloading typed_argument_parser-1.10.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from typed-argument-parser) (0.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from typed-argument-parser) (24.1)\n",
            "Collecting typing-inspect>=0.7.1 (from typed-argument-parser)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.7.1->typed-argument-parser)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.7.1->typed-argument-parser) (4.12.2)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, typed-argument-parser\n",
            "Successfully installed mypy-extensions-1.0.0 typed-argument-parser-1.10.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install segmentation_models_pytorch\n",
        "!pip install warmup_scheduler\n",
        "!pip install wandb\n",
        "!pip install typed-argument-parser  # Install the correct package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjDZjjFa3NzM",
        "outputId": "71e6cac4-63b5-4bd8-9ff2-041297aa7c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.12.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (24.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "F8U2w3MTx2xY"
      },
      "outputs": [],
      "source": [
        "# Play an audio beep. Any audio URL will do.\n",
        "#from google.colab import output\n",
        "#output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwUlEMT72ZIg"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlpWPgvYIsFb"
      },
      "source": [
        "#Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##720"
      ],
      "metadata": {
        "id": "kH9frdLTdsAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 00 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/wild14_deduped_64_pretrained2_20231210121321_0_fr_i3depoch=3-v2_256.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 00 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/wild14_deduped_64_pretrained2_20231210121321_0_fr_i3depoch=3-v2_256.ckpt"
      ],
      "metadata": {
        "id": "WPI8AaOw74WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyYgmIxZtxba",
        "outputId": "aaca3ba1-e941-4dab-ee45-929758f7ee56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 684, in <module>\n",
            "    model = RegressionPLModel.load_from_checkpoint(args.model_path, strict=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/model_helpers.py\", line 125, in wrapper\n",
            "    return self.method(cls, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1586, in load_from_checkpoint\n",
            "    loaded = _load_from_checkpoint(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 91, in _load_from_checkpoint\n",
            "    model = _load_state(cls, checkpoint, strict=strict, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 187, in _load_state\n",
            "    keys = obj.load_state_dict(checkpoint[\"state_dict\"], strict=strict)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2189, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for RegressionPLModel:\n",
            "\tsize mismatch for decoder.convs.0.0.weight: copying a param with shape torch.Size([256, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 672, 3, 3]).\n",
            "\tsize mismatch for decoder.convs.0.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([192]).\n",
            "\tsize mismatch for decoder.convs.0.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([192]).\n",
            "\tsize mismatch for decoder.convs.0.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([192]).\n",
            "\tsize mismatch for decoder.convs.0.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([192]).\n",
            "\tsize mismatch for decoder.convs.1.0.weight: copying a param with shape torch.Size([512, 1536, 3, 3]) from checkpoint, the shape in current model is torch.Size([480, 1312, 3, 3]).\n",
            "\tsize mismatch for decoder.convs.1.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([480]).\n",
            "\tsize mismatch for decoder.convs.1.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([480]).\n",
            "\tsize mismatch for decoder.convs.1.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([480]).\n",
            "\tsize mismatch for decoder.convs.1.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([480]).\n",
            "\tsize mismatch for decoder.convs.2.0.weight: copying a param with shape torch.Size([1024, 3072, 3, 3]) from checkpoint, the shape in current model is torch.Size([832, 1856, 3, 3]).\n",
            "\tsize mismatch for decoder.convs.2.1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([832]).\n",
            "\tsize mismatch for decoder.convs.2.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([832]).\n",
            "\tsize mismatch for decoder.convs.2.1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([832]).\n",
            "\tsize mismatch for decoder.convs.2.1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([832]).\n",
            "\tsize mismatch for decoder.logit.weight: copying a param with shape torch.Size([1, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 192, 1, 1]).\n",
            "set dataset path\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 684, in <module>\n",
            "    model = RegressionPLModel.load_from_checkpoint(args.model_path, strict=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/model_helpers.py\", line 125, in wrapper\n",
            "    return self.method(cls, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1586, in load_from_checkpoint\n",
            "    loaded = _load_from_checkpoint(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 91, in _load_from_checkpoint\n",
            "    model = _load_state(cls, checkpoint, strict=strict, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 187, in _load_state\n",
            "    keys = obj.load_state_dict(checkpoint[\"state_dict\"], strict=strict)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2189, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for RegressionPLModel:\n",
            "\tsize mismatch for decoder.convs.0.0.weight: copying a param with shape torch.Size([256, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 672, 3, 3]).\n",
            "\tsize mismatch for decoder.convs.0.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([192]).\n",
            "\tsize mismatch for decoder.convs.0.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([192]).\n",
            "\tsize mismatch for decoder.convs.0.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([192]).\n",
            "\tsize mismatch for decoder.convs.0.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([192]).\n",
            "\tsize mismatch for decoder.convs.1.0.weight: copying a param with shape torch.Size([512, 1536, 3, 3]) from checkpoint, the shape in current model is torch.Size([480, 1312, 3, 3]).\n",
            "\tsize mismatch for decoder.convs.1.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([480]).\n",
            "\tsize mismatch for decoder.convs.1.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([480]).\n",
            "\tsize mismatch for decoder.convs.1.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([480]).\n",
            "\tsize mismatch for decoder.convs.1.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([480]).\n",
            "\tsize mismatch for decoder.convs.2.0.weight: copying a param with shape torch.Size([1024, 3072, 3, 3]) from checkpoint, the shape in current model is torch.Size([832, 1856, 3, 3]).\n",
            "\tsize mismatch for decoder.convs.2.1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([832]).\n",
            "\tsize mismatch for decoder.convs.2.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([832]).\n",
            "\tsize mismatch for decoder.convs.2.1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([832]).\n",
            "\tsize mismatch for decoder.convs.2.1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([832]).\n",
            "\tsize mismatch for decoder.logit.weight: copying a param with shape torch.Size([1, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 192, 1, 1]).\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 00 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/wild14_deduped_64_pretrained2_20231210121321_0_fr_i3depoch=3-v2_256.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 00 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/wild14_deduped_64_pretrained2_20231210121321_0_fr_i3depoch=3-v2_256.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32_KFLpSt3Tx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9z1sf68ItQ5",
        "outputId": "84e28966-d002-4ad0-af4f-68df3ef056c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py:191: Found keys that are in the model state dict but not in the checkpoint: ['backbone.logits.conv3d.weight', 'backbone.logits.conv3d.bias', 'backbone.Conv3d_1a_7x7.conv3d.weight', 'backbone.Conv3d_1a_7x7.bn.weight', 'backbone.Conv3d_1a_7x7.bn.bias', 'backbone.Conv3d_1a_7x7.bn.running_mean', 'backbone.Conv3d_1a_7x7.bn.running_var', 'backbone.Conv3d_2b_1x1.conv3d.weight', 'backbone.Conv3d_2b_1x1.bn.weight', 'backbone.Conv3d_2b_1x1.bn.bias', 'backbone.Conv3d_2b_1x1.bn.running_mean', 'backbone.Conv3d_2b_1x1.bn.running_var', 'backbone.Conv3d_2c_3x3.conv3d.weight', 'backbone.Conv3d_2c_3x3.bn.weight', 'backbone.Conv3d_2c_3x3.bn.bias', 'backbone.Conv3d_2c_3x3.bn.running_mean', 'backbone.Conv3d_2c_3x3.bn.running_var', 'backbone.Mixed_3b.b0.conv3d.weight', 'backbone.Mixed_3b.b0.bn.weight', 'backbone.Mixed_3b.b0.bn.bias', 'backbone.Mixed_3b.b0.bn.running_mean', 'backbone.Mixed_3b.b0.bn.running_var', 'backbone.Mixed_3b.b1a.conv3d.weight', 'backbone.Mixed_3b.b1a.bn.weight', 'backbone.Mixed_3b.b1a.bn.bias', 'backbone.Mixed_3b.b1a.bn.running_mean', 'backbone.Mixed_3b.b1a.bn.running_var', 'backbone.Mixed_3b.b1b.conv3d.weight', 'backbone.Mixed_3b.b1b.bn.weight', 'backbone.Mixed_3b.b1b.bn.bias', 'backbone.Mixed_3b.b1b.bn.running_mean', 'backbone.Mixed_3b.b1b.bn.running_var', 'backbone.Mixed_3b.b2a.conv3d.weight', 'backbone.Mixed_3b.b2a.bn.weight', 'backbone.Mixed_3b.b2a.bn.bias', 'backbone.Mixed_3b.b2a.bn.running_mean', 'backbone.Mixed_3b.b2a.bn.running_var', 'backbone.Mixed_3b.b2b.conv3d.weight', 'backbone.Mixed_3b.b2b.bn.weight', 'backbone.Mixed_3b.b2b.bn.bias', 'backbone.Mixed_3b.b2b.bn.running_mean', 'backbone.Mixed_3b.b2b.bn.running_var', 'backbone.Mixed_3b.b3b.conv3d.weight', 'backbone.Mixed_3b.b3b.bn.weight', 'backbone.Mixed_3b.b3b.bn.bias', 'backbone.Mixed_3b.b3b.bn.running_mean', 'backbone.Mixed_3b.b3b.bn.running_var', 'backbone.Mixed_3c.b0.conv3d.weight', 'backbone.Mixed_3c.b0.bn.weight', 'backbone.Mixed_3c.b0.bn.bias', 'backbone.Mixed_3c.b0.bn.running_mean', 'backbone.Mixed_3c.b0.bn.running_var', 'backbone.Mixed_3c.b1a.conv3d.weight', 'backbone.Mixed_3c.b1a.bn.weight', 'backbone.Mixed_3c.b1a.bn.bias', 'backbone.Mixed_3c.b1a.bn.running_mean', 'backbone.Mixed_3c.b1a.bn.running_var', 'backbone.Mixed_3c.b1b.conv3d.weight', 'backbone.Mixed_3c.b1b.bn.weight', 'backbone.Mixed_3c.b1b.bn.bias', 'backbone.Mixed_3c.b1b.bn.running_mean', 'backbone.Mixed_3c.b1b.bn.running_var', 'backbone.Mixed_3c.b2a.conv3d.weight', 'backbone.Mixed_3c.b2a.bn.weight', 'backbone.Mixed_3c.b2a.bn.bias', 'backbone.Mixed_3c.b2a.bn.running_mean', 'backbone.Mixed_3c.b2a.bn.running_var', 'backbone.Mixed_3c.b2b.conv3d.weight', 'backbone.Mixed_3c.b2b.bn.weight', 'backbone.Mixed_3c.b2b.bn.bias', 'backbone.Mixed_3c.b2b.bn.running_mean', 'backbone.Mixed_3c.b2b.bn.running_var', 'backbone.Mixed_3c.b3b.conv3d.weight', 'backbone.Mixed_3c.b3b.bn.weight', 'backbone.Mixed_3c.b3b.bn.bias', 'backbone.Mixed_3c.b3b.bn.running_mean', 'backbone.Mixed_3c.b3b.bn.running_var', 'backbone.Mixed_4b.b0.conv3d.weight', 'backbone.Mixed_4b.b0.bn.weight', 'backbone.Mixed_4b.b0.bn.bias', 'backbone.Mixed_4b.b0.bn.running_mean', 'backbone.Mixed_4b.b0.bn.running_var', 'backbone.Mixed_4b.b1a.conv3d.weight', 'backbone.Mixed_4b.b1a.bn.weight', 'backbone.Mixed_4b.b1a.bn.bias', 'backbone.Mixed_4b.b1a.bn.running_mean', 'backbone.Mixed_4b.b1a.bn.running_var', 'backbone.Mixed_4b.b1b.conv3d.weight', 'backbone.Mixed_4b.b1b.bn.weight', 'backbone.Mixed_4b.b1b.bn.bias', 'backbone.Mixed_4b.b1b.bn.running_mean', 'backbone.Mixed_4b.b1b.bn.running_var', 'backbone.Mixed_4b.b2a.conv3d.weight', 'backbone.Mixed_4b.b2a.bn.weight', 'backbone.Mixed_4b.b2a.bn.bias', 'backbone.Mixed_4b.b2a.bn.running_mean', 'backbone.Mixed_4b.b2a.bn.running_var', 'backbone.Mixed_4b.b2b.conv3d.weight', 'backbone.Mixed_4b.b2b.bn.weight', 'backbone.Mixed_4b.b2b.bn.bias', 'backbone.Mixed_4b.b2b.bn.running_mean', 'backbone.Mixed_4b.b2b.bn.running_var', 'backbone.Mixed_4b.b3b.conv3d.weight', 'backbone.Mixed_4b.b3b.bn.weight', 'backbone.Mixed_4b.b3b.bn.bias', 'backbone.Mixed_4b.b3b.bn.running_mean', 'backbone.Mixed_4b.b3b.bn.running_var', 'backbone.Mixed_4c.b0.conv3d.weight', 'backbone.Mixed_4c.b0.bn.weight', 'backbone.Mixed_4c.b0.bn.bias', 'backbone.Mixed_4c.b0.bn.running_mean', 'backbone.Mixed_4c.b0.bn.running_var', 'backbone.Mixed_4c.b1a.conv3d.weight', 'backbone.Mixed_4c.b1a.bn.weight', 'backbone.Mixed_4c.b1a.bn.bias', 'backbone.Mixed_4c.b1a.bn.running_mean', 'backbone.Mixed_4c.b1a.bn.running_var', 'backbone.Mixed_4c.b1b.conv3d.weight', 'backbone.Mixed_4c.b1b.bn.weight', 'backbone.Mixed_4c.b1b.bn.bias', 'backbone.Mixed_4c.b1b.bn.running_mean', 'backbone.Mixed_4c.b1b.bn.running_var', 'backbone.Mixed_4c.b2a.conv3d.weight', 'backbone.Mixed_4c.b2a.bn.weight', 'backbone.Mixed_4c.b2a.bn.bias', 'backbone.Mixed_4c.b2a.bn.running_mean', 'backbone.Mixed_4c.b2a.bn.running_var', 'backbone.Mixed_4c.b2b.conv3d.weight', 'backbone.Mixed_4c.b2b.bn.weight', 'backbone.Mixed_4c.b2b.bn.bias', 'backbone.Mixed_4c.b2b.bn.running_mean', 'backbone.Mixed_4c.b2b.bn.running_var', 'backbone.Mixed_4c.b3b.conv3d.weight', 'backbone.Mixed_4c.b3b.bn.weight', 'backbone.Mixed_4c.b3b.bn.bias', 'backbone.Mixed_4c.b3b.bn.running_mean', 'backbone.Mixed_4c.b3b.bn.running_var', 'backbone.Mixed_4d.b0.conv3d.weight', 'backbone.Mixed_4d.b0.bn.weight', 'backbone.Mixed_4d.b0.bn.bias', 'backbone.Mixed_4d.b0.bn.running_mean', 'backbone.Mixed_4d.b0.bn.running_var', 'backbone.Mixed_4d.b1a.conv3d.weight', 'backbone.Mixed_4d.b1a.bn.weight', 'backbone.Mixed_4d.b1a.bn.bias', 'backbone.Mixed_4d.b1a.bn.running_mean', 'backbone.Mixed_4d.b1a.bn.running_var', 'backbone.Mixed_4d.b1b.conv3d.weight', 'backbone.Mixed_4d.b1b.bn.weight', 'backbone.Mixed_4d.b1b.bn.bias', 'backbone.Mixed_4d.b1b.bn.running_mean', 'backbone.Mixed_4d.b1b.bn.running_var', 'backbone.Mixed_4d.b2a.conv3d.weight', 'backbone.Mixed_4d.b2a.bn.weight', 'backbone.Mixed_4d.b2a.bn.bias', 'backbone.Mixed_4d.b2a.bn.running_mean', 'backbone.Mixed_4d.b2a.bn.running_var', 'backbone.Mixed_4d.b2b.conv3d.weight', 'backbone.Mixed_4d.b2b.bn.weight', 'backbone.Mixed_4d.b2b.bn.bias', 'backbone.Mixed_4d.b2b.bn.running_mean', 'backbone.Mixed_4d.b2b.bn.running_var', 'backbone.Mixed_4d.b3b.conv3d.weight', 'backbone.Mixed_4d.b3b.bn.weight', 'backbone.Mixed_4d.b3b.bn.bias', 'backbone.Mixed_4d.b3b.bn.running_mean', 'backbone.Mixed_4d.b3b.bn.running_var', 'backbone.Mixed_4e.b0.conv3d.weight', 'backbone.Mixed_4e.b0.bn.weight', 'backbone.Mixed_4e.b0.bn.bias', 'backbone.Mixed_4e.b0.bn.running_mean', 'backbone.Mixed_4e.b0.bn.running_var', 'backbone.Mixed_4e.b1a.conv3d.weight', 'backbone.Mixed_4e.b1a.bn.weight', 'backbone.Mixed_4e.b1a.bn.bias', 'backbone.Mixed_4e.b1a.bn.running_mean', 'backbone.Mixed_4e.b1a.bn.running_var', 'backbone.Mixed_4e.b1b.conv3d.weight', 'backbone.Mixed_4e.b1b.bn.weight', 'backbone.Mixed_4e.b1b.bn.bias', 'backbone.Mixed_4e.b1b.bn.running_mean', 'backbone.Mixed_4e.b1b.bn.running_var', 'backbone.Mixed_4e.b2a.conv3d.weight', 'backbone.Mixed_4e.b2a.bn.weight', 'backbone.Mixed_4e.b2a.bn.bias', 'backbone.Mixed_4e.b2a.bn.running_mean', 'backbone.Mixed_4e.b2a.bn.running_var', 'backbone.Mixed_4e.b2b.conv3d.weight', 'backbone.Mixed_4e.b2b.bn.weight', 'backbone.Mixed_4e.b2b.bn.bias', 'backbone.Mixed_4e.b2b.bn.running_mean', 'backbone.Mixed_4e.b2b.bn.running_var', 'backbone.Mixed_4e.b3b.conv3d.weight', 'backbone.Mixed_4e.b3b.bn.weight', 'backbone.Mixed_4e.b3b.bn.bias', 'backbone.Mixed_4e.b3b.bn.running_mean', 'backbone.Mixed_4e.b3b.bn.running_var', 'backbone.Mixed_4f.b0.conv3d.weight', 'backbone.Mixed_4f.b0.bn.weight', 'backbone.Mixed_4f.b0.bn.bias', 'backbone.Mixed_4f.b0.bn.running_mean', 'backbone.Mixed_4f.b0.bn.running_var', 'backbone.Mixed_4f.b1a.conv3d.weight', 'backbone.Mixed_4f.b1a.bn.weight', 'backbone.Mixed_4f.b1a.bn.bias', 'backbone.Mixed_4f.b1a.bn.running_mean', 'backbone.Mixed_4f.b1a.bn.running_var', 'backbone.Mixed_4f.b1b.conv3d.weight', 'backbone.Mixed_4f.b1b.bn.weight', 'backbone.Mixed_4f.b1b.bn.bias', 'backbone.Mixed_4f.b1b.bn.running_mean', 'backbone.Mixed_4f.b1b.bn.running_var', 'backbone.Mixed_4f.b2a.conv3d.weight', 'backbone.Mixed_4f.b2a.bn.weight', 'backbone.Mixed_4f.b2a.bn.bias', 'backbone.Mixed_4f.b2a.bn.running_mean', 'backbone.Mixed_4f.b2a.bn.running_var', 'backbone.Mixed_4f.b2b.conv3d.weight', 'backbone.Mixed_4f.b2b.bn.weight', 'backbone.Mixed_4f.b2b.bn.bias', 'backbone.Mixed_4f.b2b.bn.running_mean', 'backbone.Mixed_4f.b2b.bn.running_var', 'backbone.Mixed_4f.b3b.conv3d.weight', 'backbone.Mixed_4f.b3b.bn.weight', 'backbone.Mixed_4f.b3b.bn.bias', 'backbone.Mixed_4f.b3b.bn.running_mean', 'backbone.Mixed_4f.b3b.bn.running_var', 'backbone.Mixed_5b.b0.conv3d.weight', 'backbone.Mixed_5b.b0.bn.weight', 'backbone.Mixed_5b.b0.bn.bias', 'backbone.Mixed_5b.b0.bn.running_mean', 'backbone.Mixed_5b.b0.bn.running_var', 'backbone.Mixed_5b.b1a.conv3d.weight', 'backbone.Mixed_5b.b1a.bn.weight', 'backbone.Mixed_5b.b1a.bn.bias', 'backbone.Mixed_5b.b1a.bn.running_mean', 'backbone.Mixed_5b.b1a.bn.running_var', 'backbone.Mixed_5b.b1b.conv3d.weight', 'backbone.Mixed_5b.b1b.bn.weight', 'backbone.Mixed_5b.b1b.bn.bias', 'backbone.Mixed_5b.b1b.bn.running_mean', 'backbone.Mixed_5b.b1b.bn.running_var', 'backbone.Mixed_5b.b2a.conv3d.weight', 'backbone.Mixed_5b.b2a.bn.weight', 'backbone.Mixed_5b.b2a.bn.bias', 'backbone.Mixed_5b.b2a.bn.running_mean', 'backbone.Mixed_5b.b2a.bn.running_var', 'backbone.Mixed_5b.b2b.conv3d.weight', 'backbone.Mixed_5b.b2b.bn.weight', 'backbone.Mixed_5b.b2b.bn.bias', 'backbone.Mixed_5b.b2b.bn.running_mean', 'backbone.Mixed_5b.b2b.bn.running_var', 'backbone.Mixed_5b.b3b.conv3d.weight', 'backbone.Mixed_5b.b3b.bn.weight', 'backbone.Mixed_5b.b3b.bn.bias', 'backbone.Mixed_5b.b3b.bn.running_mean', 'backbone.Mixed_5b.b3b.bn.running_var', 'backbone.Mixed_5c.b0.conv3d.weight', 'backbone.Mixed_5c.b0.bn.weight', 'backbone.Mixed_5c.b0.bn.bias', 'backbone.Mixed_5c.b0.bn.running_mean', 'backbone.Mixed_5c.b0.bn.running_var', 'backbone.Mixed_5c.b1a.conv3d.weight', 'backbone.Mixed_5c.b1a.bn.weight', 'backbone.Mixed_5c.b1a.bn.bias', 'backbone.Mixed_5c.b1a.bn.running_mean', 'backbone.Mixed_5c.b1a.bn.running_var', 'backbone.Mixed_5c.b1b.conv3d.weight', 'backbone.Mixed_5c.b1b.bn.weight', 'backbone.Mixed_5c.b1b.bn.bias', 'backbone.Mixed_5c.b1b.bn.running_mean', 'backbone.Mixed_5c.b1b.bn.running_var', 'backbone.Mixed_5c.b2a.conv3d.weight', 'backbone.Mixed_5c.b2a.bn.weight', 'backbone.Mixed_5c.b2a.bn.bias', 'backbone.Mixed_5c.b2a.bn.running_mean', 'backbone.Mixed_5c.b2a.bn.running_var', 'backbone.Mixed_5c.b2b.conv3d.weight', 'backbone.Mixed_5c.b2b.bn.weight', 'backbone.Mixed_5c.b2b.bn.bias', 'backbone.Mixed_5c.b2b.bn.running_mean', 'backbone.Mixed_5c.b2b.bn.running_var', 'backbone.Mixed_5c.b3b.conv3d.weight', 'backbone.Mixed_5c.b3b.bn.weight', 'backbone.Mixed_5c.b3b.bn.bias', 'backbone.Mixed_5c.b3b.bn.running_mean', 'backbone.Mixed_5c.b3b.bn.running_var', 'decoder.convs.0.0.weight', 'decoder.convs.0.1.weight', 'decoder.convs.0.1.bias', 'decoder.convs.0.1.running_mean', 'decoder.convs.0.1.running_var', 'decoder.convs.1.0.weight', 'decoder.convs.1.1.weight', 'decoder.convs.1.1.bias', 'decoder.convs.1.1.running_mean', 'decoder.convs.1.1.running_var', 'decoder.convs.2.0.weight', 'decoder.convs.2.1.weight', 'decoder.convs.2.1.bias', 'decoder.convs.2.1.running_mean', 'decoder.convs.2.1.running_var', 'decoder.logit.weight', 'decoder.logit.bias']\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['backbone.cls_token', 'backbone.to_patch_embedding.weight', 'backbone.to_patch_embedding.bias', 'backbone.frame_rot_emb.inv_freqs', 'backbone.image_rot_emb.scales', 'backbone.layers.0.0.fn.to_qkv.weight', 'backbone.layers.0.0.fn.to_out.0.weight', 'backbone.layers.0.0.fn.to_out.0.bias', 'backbone.layers.0.0.norm.weight', 'backbone.layers.0.0.norm.bias', 'backbone.layers.0.1.fn.to_qkv.weight', 'backbone.layers.0.1.fn.to_out.0.weight', 'backbone.layers.0.1.fn.to_out.0.bias', 'backbone.layers.0.1.norm.weight', 'backbone.layers.0.1.norm.bias', 'backbone.layers.0.2.fn.net.0.weight', 'backbone.layers.0.2.fn.net.0.bias', 'backbone.layers.0.2.fn.net.3.weight', 'backbone.layers.0.2.fn.net.3.bias', 'backbone.layers.0.2.norm.weight', 'backbone.layers.0.2.norm.bias', 'backbone.layers.1.0.fn.to_qkv.weight', 'backbone.layers.1.0.fn.to_out.0.weight', 'backbone.layers.1.0.fn.to_out.0.bias', 'backbone.layers.1.0.norm.weight', 'backbone.layers.1.0.norm.bias', 'backbone.layers.1.1.fn.to_qkv.weight', 'backbone.layers.1.1.fn.to_out.0.weight', 'backbone.layers.1.1.fn.to_out.0.bias', 'backbone.layers.1.1.norm.weight', 'backbone.layers.1.1.norm.bias', 'backbone.layers.1.2.fn.net.0.weight', 'backbone.layers.1.2.fn.net.0.bias', 'backbone.layers.1.2.fn.net.3.weight', 'backbone.layers.1.2.fn.net.3.bias', 'backbone.layers.1.2.norm.weight', 'backbone.layers.1.2.norm.bias', 'backbone.layers.2.0.fn.to_qkv.weight', 'backbone.layers.2.0.fn.to_out.0.weight', 'backbone.layers.2.0.fn.to_out.0.bias', 'backbone.layers.2.0.norm.weight', 'backbone.layers.2.0.norm.bias', 'backbone.layers.2.1.fn.to_qkv.weight', 'backbone.layers.2.1.fn.to_out.0.weight', 'backbone.layers.2.1.fn.to_out.0.bias', 'backbone.layers.2.1.norm.weight', 'backbone.layers.2.1.norm.bias', 'backbone.layers.2.2.fn.net.0.weight', 'backbone.layers.2.2.fn.net.0.bias', 'backbone.layers.2.2.fn.net.3.weight', 'backbone.layers.2.2.fn.net.3.bias', 'backbone.layers.2.2.norm.weight', 'backbone.layers.2.2.norm.bias', 'backbone.layers.3.0.fn.to_qkv.weight', 'backbone.layers.3.0.fn.to_out.0.weight', 'backbone.layers.3.0.fn.to_out.0.bias', 'backbone.layers.3.0.norm.weight', 'backbone.layers.3.0.norm.bias', 'backbone.layers.3.1.fn.to_qkv.weight', 'backbone.layers.3.1.fn.to_out.0.weight', 'backbone.layers.3.1.fn.to_out.0.bias', 'backbone.layers.3.1.norm.weight', 'backbone.layers.3.1.norm.bias', 'backbone.layers.3.2.fn.net.0.weight', 'backbone.layers.3.2.fn.net.0.bias', 'backbone.layers.3.2.fn.net.3.weight', 'backbone.layers.3.2.fn.net.3.bias', 'backbone.layers.3.2.norm.weight', 'backbone.layers.3.2.norm.bias', 'backbone.layers.4.0.fn.to_qkv.weight', 'backbone.layers.4.0.fn.to_out.0.weight', 'backbone.layers.4.0.fn.to_out.0.bias', 'backbone.layers.4.0.norm.weight', 'backbone.layers.4.0.norm.bias', 'backbone.layers.4.1.fn.to_qkv.weight', 'backbone.layers.4.1.fn.to_out.0.weight', 'backbone.layers.4.1.fn.to_out.0.bias', 'backbone.layers.4.1.norm.weight', 'backbone.layers.4.1.norm.bias', 'backbone.layers.4.2.fn.net.0.weight', 'backbone.layers.4.2.fn.net.0.bias', 'backbone.layers.4.2.fn.net.3.weight', 'backbone.layers.4.2.fn.net.3.bias', 'backbone.layers.4.2.norm.weight', 'backbone.layers.4.2.norm.bias', 'backbone.layers.5.0.fn.to_qkv.weight', 'backbone.layers.5.0.fn.to_out.0.weight', 'backbone.layers.5.0.fn.to_out.0.bias', 'backbone.layers.5.0.norm.weight', 'backbone.layers.5.0.norm.bias', 'backbone.layers.5.1.fn.to_qkv.weight', 'backbone.layers.5.1.fn.to_out.0.weight', 'backbone.layers.5.1.fn.to_out.0.bias', 'backbone.layers.5.1.norm.weight', 'backbone.layers.5.1.norm.bias', 'backbone.layers.5.2.fn.net.0.weight', 'backbone.layers.5.2.fn.net.0.bias', 'backbone.layers.5.2.fn.net.3.weight', 'backbone.layers.5.2.fn.net.3.bias', 'backbone.layers.5.2.norm.weight', 'backbone.layers.5.2.norm.bias', 'backbone.layers.6.0.fn.to_qkv.weight', 'backbone.layers.6.0.fn.to_out.0.weight', 'backbone.layers.6.0.fn.to_out.0.bias', 'backbone.layers.6.0.norm.weight', 'backbone.layers.6.0.norm.bias', 'backbone.layers.6.1.fn.to_qkv.weight', 'backbone.layers.6.1.fn.to_out.0.weight', 'backbone.layers.6.1.fn.to_out.0.bias', 'backbone.layers.6.1.norm.weight', 'backbone.layers.6.1.norm.bias', 'backbone.layers.6.2.fn.net.0.weight', 'backbone.layers.6.2.fn.net.0.bias', 'backbone.layers.6.2.fn.net.3.weight', 'backbone.layers.6.2.fn.net.3.bias', 'backbone.layers.6.2.norm.weight', 'backbone.layers.6.2.norm.bias', 'backbone.layers.7.0.fn.to_qkv.weight', 'backbone.layers.7.0.fn.to_out.0.weight', 'backbone.layers.7.0.fn.to_out.0.bias', 'backbone.layers.7.0.norm.weight', 'backbone.layers.7.0.norm.bias', 'backbone.layers.7.1.fn.to_qkv.weight', 'backbone.layers.7.1.fn.to_out.0.weight', 'backbone.layers.7.1.fn.to_out.0.bias', 'backbone.layers.7.1.norm.weight', 'backbone.layers.7.1.norm.bias', 'backbone.layers.7.2.fn.net.0.weight', 'backbone.layers.7.2.fn.net.0.bias', 'backbone.layers.7.2.fn.net.3.weight', 'backbone.layers.7.2.fn.net.3.bias', 'backbone.layers.7.2.norm.weight', 'backbone.layers.7.2.norm.bias', 'backbone.to_out.0.weight', 'backbone.to_out.0.bias', 'backbone.to_out.1.weight', 'backbone.to_out.1.bias']\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_9to16_1718317772/20240109095720_9to16_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:05<00:16,  2.32s/it]Progress image saved at step 2 (22%): ./outputs/20240109095720_9to16_1718317772/20240109095720_9to16_normal_stride32_size64_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:08<00:08,  1.80s/it]Progress image saved at step 4 (44%): ./outputs/20240109095720_9to16_1718317772/20240109095720_9to16_normal_stride32_size64_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:11<00:04,  1.65s/it]Progress image saved at step 6 (66%): ./outputs/20240109095720_9to16_1718317772/20240109095720_9to16_normal_stride32_size64_batchsize512_progress_66percent.png\n",
            "100% 9/9 [00:14<00:00,  1.64s/it]\n",
            "set dataset path\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py:191: Found keys that are in the model state dict but not in the checkpoint: ['backbone.logits.conv3d.weight', 'backbone.logits.conv3d.bias', 'backbone.Conv3d_1a_7x7.conv3d.weight', 'backbone.Conv3d_1a_7x7.bn.weight', 'backbone.Conv3d_1a_7x7.bn.bias', 'backbone.Conv3d_1a_7x7.bn.running_mean', 'backbone.Conv3d_1a_7x7.bn.running_var', 'backbone.Conv3d_2b_1x1.conv3d.weight', 'backbone.Conv3d_2b_1x1.bn.weight', 'backbone.Conv3d_2b_1x1.bn.bias', 'backbone.Conv3d_2b_1x1.bn.running_mean', 'backbone.Conv3d_2b_1x1.bn.running_var', 'backbone.Conv3d_2c_3x3.conv3d.weight', 'backbone.Conv3d_2c_3x3.bn.weight', 'backbone.Conv3d_2c_3x3.bn.bias', 'backbone.Conv3d_2c_3x3.bn.running_mean', 'backbone.Conv3d_2c_3x3.bn.running_var', 'backbone.Mixed_3b.b0.conv3d.weight', 'backbone.Mixed_3b.b0.bn.weight', 'backbone.Mixed_3b.b0.bn.bias', 'backbone.Mixed_3b.b0.bn.running_mean', 'backbone.Mixed_3b.b0.bn.running_var', 'backbone.Mixed_3b.b1a.conv3d.weight', 'backbone.Mixed_3b.b1a.bn.weight', 'backbone.Mixed_3b.b1a.bn.bias', 'backbone.Mixed_3b.b1a.bn.running_mean', 'backbone.Mixed_3b.b1a.bn.running_var', 'backbone.Mixed_3b.b1b.conv3d.weight', 'backbone.Mixed_3b.b1b.bn.weight', 'backbone.Mixed_3b.b1b.bn.bias', 'backbone.Mixed_3b.b1b.bn.running_mean', 'backbone.Mixed_3b.b1b.bn.running_var', 'backbone.Mixed_3b.b2a.conv3d.weight', 'backbone.Mixed_3b.b2a.bn.weight', 'backbone.Mixed_3b.b2a.bn.bias', 'backbone.Mixed_3b.b2a.bn.running_mean', 'backbone.Mixed_3b.b2a.bn.running_var', 'backbone.Mixed_3b.b2b.conv3d.weight', 'backbone.Mixed_3b.b2b.bn.weight', 'backbone.Mixed_3b.b2b.bn.bias', 'backbone.Mixed_3b.b2b.bn.running_mean', 'backbone.Mixed_3b.b2b.bn.running_var', 'backbone.Mixed_3b.b3b.conv3d.weight', 'backbone.Mixed_3b.b3b.bn.weight', 'backbone.Mixed_3b.b3b.bn.bias', 'backbone.Mixed_3b.b3b.bn.running_mean', 'backbone.Mixed_3b.b3b.bn.running_var', 'backbone.Mixed_3c.b0.conv3d.weight', 'backbone.Mixed_3c.b0.bn.weight', 'backbone.Mixed_3c.b0.bn.bias', 'backbone.Mixed_3c.b0.bn.running_mean', 'backbone.Mixed_3c.b0.bn.running_var', 'backbone.Mixed_3c.b1a.conv3d.weight', 'backbone.Mixed_3c.b1a.bn.weight', 'backbone.Mixed_3c.b1a.bn.bias', 'backbone.Mixed_3c.b1a.bn.running_mean', 'backbone.Mixed_3c.b1a.bn.running_var', 'backbone.Mixed_3c.b1b.conv3d.weight', 'backbone.Mixed_3c.b1b.bn.weight', 'backbone.Mixed_3c.b1b.bn.bias', 'backbone.Mixed_3c.b1b.bn.running_mean', 'backbone.Mixed_3c.b1b.bn.running_var', 'backbone.Mixed_3c.b2a.conv3d.weight', 'backbone.Mixed_3c.b2a.bn.weight', 'backbone.Mixed_3c.b2a.bn.bias', 'backbone.Mixed_3c.b2a.bn.running_mean', 'backbone.Mixed_3c.b2a.bn.running_var', 'backbone.Mixed_3c.b2b.conv3d.weight', 'backbone.Mixed_3c.b2b.bn.weight', 'backbone.Mixed_3c.b2b.bn.bias', 'backbone.Mixed_3c.b2b.bn.running_mean', 'backbone.Mixed_3c.b2b.bn.running_var', 'backbone.Mixed_3c.b3b.conv3d.weight', 'backbone.Mixed_3c.b3b.bn.weight', 'backbone.Mixed_3c.b3b.bn.bias', 'backbone.Mixed_3c.b3b.bn.running_mean', 'backbone.Mixed_3c.b3b.bn.running_var', 'backbone.Mixed_4b.b0.conv3d.weight', 'backbone.Mixed_4b.b0.bn.weight', 'backbone.Mixed_4b.b0.bn.bias', 'backbone.Mixed_4b.b0.bn.running_mean', 'backbone.Mixed_4b.b0.bn.running_var', 'backbone.Mixed_4b.b1a.conv3d.weight', 'backbone.Mixed_4b.b1a.bn.weight', 'backbone.Mixed_4b.b1a.bn.bias', 'backbone.Mixed_4b.b1a.bn.running_mean', 'backbone.Mixed_4b.b1a.bn.running_var', 'backbone.Mixed_4b.b1b.conv3d.weight', 'backbone.Mixed_4b.b1b.bn.weight', 'backbone.Mixed_4b.b1b.bn.bias', 'backbone.Mixed_4b.b1b.bn.running_mean', 'backbone.Mixed_4b.b1b.bn.running_var', 'backbone.Mixed_4b.b2a.conv3d.weight', 'backbone.Mixed_4b.b2a.bn.weight', 'backbone.Mixed_4b.b2a.bn.bias', 'backbone.Mixed_4b.b2a.bn.running_mean', 'backbone.Mixed_4b.b2a.bn.running_var', 'backbone.Mixed_4b.b2b.conv3d.weight', 'backbone.Mixed_4b.b2b.bn.weight', 'backbone.Mixed_4b.b2b.bn.bias', 'backbone.Mixed_4b.b2b.bn.running_mean', 'backbone.Mixed_4b.b2b.bn.running_var', 'backbone.Mixed_4b.b3b.conv3d.weight', 'backbone.Mixed_4b.b3b.bn.weight', 'backbone.Mixed_4b.b3b.bn.bias', 'backbone.Mixed_4b.b3b.bn.running_mean', 'backbone.Mixed_4b.b3b.bn.running_var', 'backbone.Mixed_4c.b0.conv3d.weight', 'backbone.Mixed_4c.b0.bn.weight', 'backbone.Mixed_4c.b0.bn.bias', 'backbone.Mixed_4c.b0.bn.running_mean', 'backbone.Mixed_4c.b0.bn.running_var', 'backbone.Mixed_4c.b1a.conv3d.weight', 'backbone.Mixed_4c.b1a.bn.weight', 'backbone.Mixed_4c.b1a.bn.bias', 'backbone.Mixed_4c.b1a.bn.running_mean', 'backbone.Mixed_4c.b1a.bn.running_var', 'backbone.Mixed_4c.b1b.conv3d.weight', 'backbone.Mixed_4c.b1b.bn.weight', 'backbone.Mixed_4c.b1b.bn.bias', 'backbone.Mixed_4c.b1b.bn.running_mean', 'backbone.Mixed_4c.b1b.bn.running_var', 'backbone.Mixed_4c.b2a.conv3d.weight', 'backbone.Mixed_4c.b2a.bn.weight', 'backbone.Mixed_4c.b2a.bn.bias', 'backbone.Mixed_4c.b2a.bn.running_mean', 'backbone.Mixed_4c.b2a.bn.running_var', 'backbone.Mixed_4c.b2b.conv3d.weight', 'backbone.Mixed_4c.b2b.bn.weight', 'backbone.Mixed_4c.b2b.bn.bias', 'backbone.Mixed_4c.b2b.bn.running_mean', 'backbone.Mixed_4c.b2b.bn.running_var', 'backbone.Mixed_4c.b3b.conv3d.weight', 'backbone.Mixed_4c.b3b.bn.weight', 'backbone.Mixed_4c.b3b.bn.bias', 'backbone.Mixed_4c.b3b.bn.running_mean', 'backbone.Mixed_4c.b3b.bn.running_var', 'backbone.Mixed_4d.b0.conv3d.weight', 'backbone.Mixed_4d.b0.bn.weight', 'backbone.Mixed_4d.b0.bn.bias', 'backbone.Mixed_4d.b0.bn.running_mean', 'backbone.Mixed_4d.b0.bn.running_var', 'backbone.Mixed_4d.b1a.conv3d.weight', 'backbone.Mixed_4d.b1a.bn.weight', 'backbone.Mixed_4d.b1a.bn.bias', 'backbone.Mixed_4d.b1a.bn.running_mean', 'backbone.Mixed_4d.b1a.bn.running_var', 'backbone.Mixed_4d.b1b.conv3d.weight', 'backbone.Mixed_4d.b1b.bn.weight', 'backbone.Mixed_4d.b1b.bn.bias', 'backbone.Mixed_4d.b1b.bn.running_mean', 'backbone.Mixed_4d.b1b.bn.running_var', 'backbone.Mixed_4d.b2a.conv3d.weight', 'backbone.Mixed_4d.b2a.bn.weight', 'backbone.Mixed_4d.b2a.bn.bias', 'backbone.Mixed_4d.b2a.bn.running_mean', 'backbone.Mixed_4d.b2a.bn.running_var', 'backbone.Mixed_4d.b2b.conv3d.weight', 'backbone.Mixed_4d.b2b.bn.weight', 'backbone.Mixed_4d.b2b.bn.bias', 'backbone.Mixed_4d.b2b.bn.running_mean', 'backbone.Mixed_4d.b2b.bn.running_var', 'backbone.Mixed_4d.b3b.conv3d.weight', 'backbone.Mixed_4d.b3b.bn.weight', 'backbone.Mixed_4d.b3b.bn.bias', 'backbone.Mixed_4d.b3b.bn.running_mean', 'backbone.Mixed_4d.b3b.bn.running_var', 'backbone.Mixed_4e.b0.conv3d.weight', 'backbone.Mixed_4e.b0.bn.weight', 'backbone.Mixed_4e.b0.bn.bias', 'backbone.Mixed_4e.b0.bn.running_mean', 'backbone.Mixed_4e.b0.bn.running_var', 'backbone.Mixed_4e.b1a.conv3d.weight', 'backbone.Mixed_4e.b1a.bn.weight', 'backbone.Mixed_4e.b1a.bn.bias', 'backbone.Mixed_4e.b1a.bn.running_mean', 'backbone.Mixed_4e.b1a.bn.running_var', 'backbone.Mixed_4e.b1b.conv3d.weight', 'backbone.Mixed_4e.b1b.bn.weight', 'backbone.Mixed_4e.b1b.bn.bias', 'backbone.Mixed_4e.b1b.bn.running_mean', 'backbone.Mixed_4e.b1b.bn.running_var', 'backbone.Mixed_4e.b2a.conv3d.weight', 'backbone.Mixed_4e.b2a.bn.weight', 'backbone.Mixed_4e.b2a.bn.bias', 'backbone.Mixed_4e.b2a.bn.running_mean', 'backbone.Mixed_4e.b2a.bn.running_var', 'backbone.Mixed_4e.b2b.conv3d.weight', 'backbone.Mixed_4e.b2b.bn.weight', 'backbone.Mixed_4e.b2b.bn.bias', 'backbone.Mixed_4e.b2b.bn.running_mean', 'backbone.Mixed_4e.b2b.bn.running_var', 'backbone.Mixed_4e.b3b.conv3d.weight', 'backbone.Mixed_4e.b3b.bn.weight', 'backbone.Mixed_4e.b3b.bn.bias', 'backbone.Mixed_4e.b3b.bn.running_mean', 'backbone.Mixed_4e.b3b.bn.running_var', 'backbone.Mixed_4f.b0.conv3d.weight', 'backbone.Mixed_4f.b0.bn.weight', 'backbone.Mixed_4f.b0.bn.bias', 'backbone.Mixed_4f.b0.bn.running_mean', 'backbone.Mixed_4f.b0.bn.running_var', 'backbone.Mixed_4f.b1a.conv3d.weight', 'backbone.Mixed_4f.b1a.bn.weight', 'backbone.Mixed_4f.b1a.bn.bias', 'backbone.Mixed_4f.b1a.bn.running_mean', 'backbone.Mixed_4f.b1a.bn.running_var', 'backbone.Mixed_4f.b1b.conv3d.weight', 'backbone.Mixed_4f.b1b.bn.weight', 'backbone.Mixed_4f.b1b.bn.bias', 'backbone.Mixed_4f.b1b.bn.running_mean', 'backbone.Mixed_4f.b1b.bn.running_var', 'backbone.Mixed_4f.b2a.conv3d.weight', 'backbone.Mixed_4f.b2a.bn.weight', 'backbone.Mixed_4f.b2a.bn.bias', 'backbone.Mixed_4f.b2a.bn.running_mean', 'backbone.Mixed_4f.b2a.bn.running_var', 'backbone.Mixed_4f.b2b.conv3d.weight', 'backbone.Mixed_4f.b2b.bn.weight', 'backbone.Mixed_4f.b2b.bn.bias', 'backbone.Mixed_4f.b2b.bn.running_mean', 'backbone.Mixed_4f.b2b.bn.running_var', 'backbone.Mixed_4f.b3b.conv3d.weight', 'backbone.Mixed_4f.b3b.bn.weight', 'backbone.Mixed_4f.b3b.bn.bias', 'backbone.Mixed_4f.b3b.bn.running_mean', 'backbone.Mixed_4f.b3b.bn.running_var', 'backbone.Mixed_5b.b0.conv3d.weight', 'backbone.Mixed_5b.b0.bn.weight', 'backbone.Mixed_5b.b0.bn.bias', 'backbone.Mixed_5b.b0.bn.running_mean', 'backbone.Mixed_5b.b0.bn.running_var', 'backbone.Mixed_5b.b1a.conv3d.weight', 'backbone.Mixed_5b.b1a.bn.weight', 'backbone.Mixed_5b.b1a.bn.bias', 'backbone.Mixed_5b.b1a.bn.running_mean', 'backbone.Mixed_5b.b1a.bn.running_var', 'backbone.Mixed_5b.b1b.conv3d.weight', 'backbone.Mixed_5b.b1b.bn.weight', 'backbone.Mixed_5b.b1b.bn.bias', 'backbone.Mixed_5b.b1b.bn.running_mean', 'backbone.Mixed_5b.b1b.bn.running_var', 'backbone.Mixed_5b.b2a.conv3d.weight', 'backbone.Mixed_5b.b2a.bn.weight', 'backbone.Mixed_5b.b2a.bn.bias', 'backbone.Mixed_5b.b2a.bn.running_mean', 'backbone.Mixed_5b.b2a.bn.running_var', 'backbone.Mixed_5b.b2b.conv3d.weight', 'backbone.Mixed_5b.b2b.bn.weight', 'backbone.Mixed_5b.b2b.bn.bias', 'backbone.Mixed_5b.b2b.bn.running_mean', 'backbone.Mixed_5b.b2b.bn.running_var', 'backbone.Mixed_5b.b3b.conv3d.weight', 'backbone.Mixed_5b.b3b.bn.weight', 'backbone.Mixed_5b.b3b.bn.bias', 'backbone.Mixed_5b.b3b.bn.running_mean', 'backbone.Mixed_5b.b3b.bn.running_var', 'backbone.Mixed_5c.b0.conv3d.weight', 'backbone.Mixed_5c.b0.bn.weight', 'backbone.Mixed_5c.b0.bn.bias', 'backbone.Mixed_5c.b0.bn.running_mean', 'backbone.Mixed_5c.b0.bn.running_var', 'backbone.Mixed_5c.b1a.conv3d.weight', 'backbone.Mixed_5c.b1a.bn.weight', 'backbone.Mixed_5c.b1a.bn.bias', 'backbone.Mixed_5c.b1a.bn.running_mean', 'backbone.Mixed_5c.b1a.bn.running_var', 'backbone.Mixed_5c.b1b.conv3d.weight', 'backbone.Mixed_5c.b1b.bn.weight', 'backbone.Mixed_5c.b1b.bn.bias', 'backbone.Mixed_5c.b1b.bn.running_mean', 'backbone.Mixed_5c.b1b.bn.running_var', 'backbone.Mixed_5c.b2a.conv3d.weight', 'backbone.Mixed_5c.b2a.bn.weight', 'backbone.Mixed_5c.b2a.bn.bias', 'backbone.Mixed_5c.b2a.bn.running_mean', 'backbone.Mixed_5c.b2a.bn.running_var', 'backbone.Mixed_5c.b2b.conv3d.weight', 'backbone.Mixed_5c.b2b.bn.weight', 'backbone.Mixed_5c.b2b.bn.bias', 'backbone.Mixed_5c.b2b.bn.running_mean', 'backbone.Mixed_5c.b2b.bn.running_var', 'backbone.Mixed_5c.b3b.conv3d.weight', 'backbone.Mixed_5c.b3b.bn.weight', 'backbone.Mixed_5c.b3b.bn.bias', 'backbone.Mixed_5c.b3b.bn.running_mean', 'backbone.Mixed_5c.b3b.bn.running_var', 'decoder.convs.0.0.weight', 'decoder.convs.0.1.weight', 'decoder.convs.0.1.bias', 'decoder.convs.0.1.running_mean', 'decoder.convs.0.1.running_var', 'decoder.convs.1.0.weight', 'decoder.convs.1.1.weight', 'decoder.convs.1.1.bias', 'decoder.convs.1.1.running_mean', 'decoder.convs.1.1.running_var', 'decoder.convs.2.0.weight', 'decoder.convs.2.1.weight', 'decoder.convs.2.1.bias', 'decoder.convs.2.1.running_mean', 'decoder.convs.2.1.running_var', 'decoder.logit.weight', 'decoder.logit.bias']\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['backbone.cls_token', 'backbone.to_patch_embedding.weight', 'backbone.to_patch_embedding.bias', 'backbone.frame_rot_emb.inv_freqs', 'backbone.image_rot_emb.scales', 'backbone.layers.0.0.fn.to_qkv.weight', 'backbone.layers.0.0.fn.to_out.0.weight', 'backbone.layers.0.0.fn.to_out.0.bias', 'backbone.layers.0.0.norm.weight', 'backbone.layers.0.0.norm.bias', 'backbone.layers.0.1.fn.to_qkv.weight', 'backbone.layers.0.1.fn.to_out.0.weight', 'backbone.layers.0.1.fn.to_out.0.bias', 'backbone.layers.0.1.norm.weight', 'backbone.layers.0.1.norm.bias', 'backbone.layers.0.2.fn.net.0.weight', 'backbone.layers.0.2.fn.net.0.bias', 'backbone.layers.0.2.fn.net.3.weight', 'backbone.layers.0.2.fn.net.3.bias', 'backbone.layers.0.2.norm.weight', 'backbone.layers.0.2.norm.bias', 'backbone.layers.1.0.fn.to_qkv.weight', 'backbone.layers.1.0.fn.to_out.0.weight', 'backbone.layers.1.0.fn.to_out.0.bias', 'backbone.layers.1.0.norm.weight', 'backbone.layers.1.0.norm.bias', 'backbone.layers.1.1.fn.to_qkv.weight', 'backbone.layers.1.1.fn.to_out.0.weight', 'backbone.layers.1.1.fn.to_out.0.bias', 'backbone.layers.1.1.norm.weight', 'backbone.layers.1.1.norm.bias', 'backbone.layers.1.2.fn.net.0.weight', 'backbone.layers.1.2.fn.net.0.bias', 'backbone.layers.1.2.fn.net.3.weight', 'backbone.layers.1.2.fn.net.3.bias', 'backbone.layers.1.2.norm.weight', 'backbone.layers.1.2.norm.bias', 'backbone.layers.2.0.fn.to_qkv.weight', 'backbone.layers.2.0.fn.to_out.0.weight', 'backbone.layers.2.0.fn.to_out.0.bias', 'backbone.layers.2.0.norm.weight', 'backbone.layers.2.0.norm.bias', 'backbone.layers.2.1.fn.to_qkv.weight', 'backbone.layers.2.1.fn.to_out.0.weight', 'backbone.layers.2.1.fn.to_out.0.bias', 'backbone.layers.2.1.norm.weight', 'backbone.layers.2.1.norm.bias', 'backbone.layers.2.2.fn.net.0.weight', 'backbone.layers.2.2.fn.net.0.bias', 'backbone.layers.2.2.fn.net.3.weight', 'backbone.layers.2.2.fn.net.3.bias', 'backbone.layers.2.2.norm.weight', 'backbone.layers.2.2.norm.bias', 'backbone.layers.3.0.fn.to_qkv.weight', 'backbone.layers.3.0.fn.to_out.0.weight', 'backbone.layers.3.0.fn.to_out.0.bias', 'backbone.layers.3.0.norm.weight', 'backbone.layers.3.0.norm.bias', 'backbone.layers.3.1.fn.to_qkv.weight', 'backbone.layers.3.1.fn.to_out.0.weight', 'backbone.layers.3.1.fn.to_out.0.bias', 'backbone.layers.3.1.norm.weight', 'backbone.layers.3.1.norm.bias', 'backbone.layers.3.2.fn.net.0.weight', 'backbone.layers.3.2.fn.net.0.bias', 'backbone.layers.3.2.fn.net.3.weight', 'backbone.layers.3.2.fn.net.3.bias', 'backbone.layers.3.2.norm.weight', 'backbone.layers.3.2.norm.bias', 'backbone.layers.4.0.fn.to_qkv.weight', 'backbone.layers.4.0.fn.to_out.0.weight', 'backbone.layers.4.0.fn.to_out.0.bias', 'backbone.layers.4.0.norm.weight', 'backbone.layers.4.0.norm.bias', 'backbone.layers.4.1.fn.to_qkv.weight', 'backbone.layers.4.1.fn.to_out.0.weight', 'backbone.layers.4.1.fn.to_out.0.bias', 'backbone.layers.4.1.norm.weight', 'backbone.layers.4.1.norm.bias', 'backbone.layers.4.2.fn.net.0.weight', 'backbone.layers.4.2.fn.net.0.bias', 'backbone.layers.4.2.fn.net.3.weight', 'backbone.layers.4.2.fn.net.3.bias', 'backbone.layers.4.2.norm.weight', 'backbone.layers.4.2.norm.bias', 'backbone.layers.5.0.fn.to_qkv.weight', 'backbone.layers.5.0.fn.to_out.0.weight', 'backbone.layers.5.0.fn.to_out.0.bias', 'backbone.layers.5.0.norm.weight', 'backbone.layers.5.0.norm.bias', 'backbone.layers.5.1.fn.to_qkv.weight', 'backbone.layers.5.1.fn.to_out.0.weight', 'backbone.layers.5.1.fn.to_out.0.bias', 'backbone.layers.5.1.norm.weight', 'backbone.layers.5.1.norm.bias', 'backbone.layers.5.2.fn.net.0.weight', 'backbone.layers.5.2.fn.net.0.bias', 'backbone.layers.5.2.fn.net.3.weight', 'backbone.layers.5.2.fn.net.3.bias', 'backbone.layers.5.2.norm.weight', 'backbone.layers.5.2.norm.bias', 'backbone.layers.6.0.fn.to_qkv.weight', 'backbone.layers.6.0.fn.to_out.0.weight', 'backbone.layers.6.0.fn.to_out.0.bias', 'backbone.layers.6.0.norm.weight', 'backbone.layers.6.0.norm.bias', 'backbone.layers.6.1.fn.to_qkv.weight', 'backbone.layers.6.1.fn.to_out.0.weight', 'backbone.layers.6.1.fn.to_out.0.bias', 'backbone.layers.6.1.norm.weight', 'backbone.layers.6.1.norm.bias', 'backbone.layers.6.2.fn.net.0.weight', 'backbone.layers.6.2.fn.net.0.bias', 'backbone.layers.6.2.fn.net.3.weight', 'backbone.layers.6.2.fn.net.3.bias', 'backbone.layers.6.2.norm.weight', 'backbone.layers.6.2.norm.bias', 'backbone.layers.7.0.fn.to_qkv.weight', 'backbone.layers.7.0.fn.to_out.0.weight', 'backbone.layers.7.0.fn.to_out.0.bias', 'backbone.layers.7.0.norm.weight', 'backbone.layers.7.0.norm.bias', 'backbone.layers.7.1.fn.to_qkv.weight', 'backbone.layers.7.1.fn.to_out.0.weight', 'backbone.layers.7.1.fn.to_out.0.bias', 'backbone.layers.7.1.norm.weight', 'backbone.layers.7.1.norm.bias', 'backbone.layers.7.2.fn.net.0.weight', 'backbone.layers.7.2.fn.net.0.bias', 'backbone.layers.7.2.fn.net.3.weight', 'backbone.layers.7.2.fn.net.3.bias', 'backbone.layers.7.2.norm.weight', 'backbone.layers.7.2.norm.bias', 'backbone.to_out.0.weight', 'backbone.to_out.0.bias', 'backbone.to_out.1.weight', 'backbone.to_out.1.bias']\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_9to16_1718317830/20240109095720_9to16_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:04<00:15,  2.22s/it]Progress image saved at step 2 (22%): ./outputs/20240109095720_9to16_1718317830/20240109095720_9to16_reversed_stride32_size64_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:07<00:08,  1.76s/it]Progress image saved at step 4 (44%): ./outputs/20240109095720_9to16_1718317830/20240109095720_9to16_reversed_stride32_size64_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:11<00:04,  1.65s/it]Progress image saved at step 6 (66%): ./outputs/20240109095720_9to16_1718317830/20240109095720_9to16_reversed_stride32_size64_batchsize512_progress_66percent.png\n",
            "100% 9/9 [00:14<00:00,  1.62s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 09 --end_idx 16 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 09 --end_idx 16 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytI26bRutoRA"
      },
      "outputs": [],
      "source": [
        "/content/drive/MyDrive/A_Scroll/inkception-3d/models/wild14_deduped_64_pretrained2_20231210121321_0_fr_i3depoch=3-v2_256.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGhli41vtoTf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNGddwrStoWS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZGLqx4sIya4",
        "outputId": "fa26a347-03dd-4635-cf97-1fc6498cde36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_10to20_1718225279/20240109095720_10to20_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:05<00:16,  2.36s/it]Progress image saved at step 2 (22%): ./outputs/20240109095720_10to20_1718225279/20240109095720_10to20_normal_stride32_size64_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:08<00:09,  1.89s/it]Progress image saved at step 4 (44%): ./outputs/20240109095720_10to20_1718225279/20240109095720_10to20_normal_stride32_size64_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:11<00:05,  1.78s/it]Progress image saved at step 6 (66%): ./outputs/20240109095720_10to20_1718225279/20240109095720_10to20_normal_stride32_size64_batchsize512_progress_66percent.png\n",
            "100% 9/9 [00:15<00:00,  1.77s/it]\n",
            "set dataset path\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_10to20_1718225345/20240109095720_10to20_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:04<00:16,  2.30s/it]Progress image saved at step 2 (22%): ./outputs/20240109095720_10to20_1718225345/20240109095720_10to20_reversed_stride32_size64_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:08<00:09,  1.88s/it]Progress image saved at step 4 (44%): ./outputs/20240109095720_10to20_1718225345/20240109095720_10to20_reversed_stride32_size64_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:11<00:05,  1.79s/it]Progress image saved at step 6 (66%): ./outputs/20240109095720_10to20_1718225345/20240109095720_10to20_reversed_stride32_size64_batchsize512_progress_66percent.png\n",
            "100% 9/9 [00:15<00:00,  1.77s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 10 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 10 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QQa_S_GIydN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPYKcusPIyfu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bvJvlXksl3y"
      },
      "source": [
        "##500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGCsnf5MbEXQ",
        "outputId": "1ec75c51-6dd2-4d39-f0a8-5b5e1cfdd494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set dataset path\n",
            "  0% 0/27 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 172 --stride 32 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 172 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 172 --stride 32 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 172 --stride 32 --size 128"
      ],
      "metadata": {
        "id": "oLqJfL6bd9w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Obq-KTPdd9zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wL8002Jld91n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsfiVUqtbEZv",
        "outputId": "1637d690-624f-4489-c2f9-379e91b249de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 4/442 [00:08<13:25,  1.84s/it]Progress image saved at step 4 (0%): ./outputs/20231205141500_4_86_22to22_1720709312/20231205141500_4_86_22to22_normal_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 110/442 [02:52<08:28,  1.53s/it]Progress image saved at step 110 (24%): ./outputs/20231205141500_4_86_22to22_1720709312/20231205141500_4_86_22to22_normal_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 221/442 [05:43<05:38,  1.53s/it]Progress image saved at step 221 (50%): ./outputs/20231205141500_4_86_22to22_1720709312/20231205141500_4_86_22to22_normal_stride8_size64_batchsize512_progress_50percent.png\n",
            " 75% 331/442 [08:33<02:50,  1.54s/it]Progress image saved at step 331 (74%): ./outputs/20231205141500_4_86_22to22_1720709312/20231205141500_4_86_22to22_normal_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 442/442 [11:25<00:00,  1.55s/it]\n",
            "set dataset path\n",
            "  1% 4/442 [00:08<13:05,  1.79s/it]Progress image saved at step 4 (0%): ./outputs/20231205141500_4_86_22to22_1720710019/20231205141500_4_86_22to22_reversed_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 110/442 [02:51<08:27,  1.53s/it]Progress image saved at step 110 (24%): ./outputs/20231205141500_4_86_22to22_1720710019/20231205141500_4_86_22to22_reversed_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 221/442 [05:42<05:39,  1.54s/it]Progress image saved at step 221 (50%): ./outputs/20231205141500_4_86_22to22_1720710019/20231205141500_4_86_22to22_reversed_stride8_size64_batchsize512_progress_50percent.png\n",
            " 75% 331/442 [08:33<02:50,  1.54s/it]Progress image saved at step 331 (74%): ./outputs/20231205141500_4_86_22to22_1720710019/20231205141500_4_86_22to22_reversed_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 442/442 [11:25<00:00,  1.55s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 022 --end_idx 022 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 022 --end_idx 022 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKQURpgcMcIX",
        "outputId": "ff78e28d-f9f8-4498-d646-a6624e3ff5a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 4/442 [00:07<12:32,  1.72s/it]Progress image saved at step 4 (0%): ./outputs/20231205141500_4_86_33to33_1720710724/20231205141500_4_86_33to33_normal_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 110/442 [02:51<08:30,  1.54s/it]Progress image saved at step 110 (24%): ./outputs/20231205141500_4_86_33to33_1720710724/20231205141500_4_86_33to33_normal_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 221/442 [05:42<05:39,  1.54s/it]Progress image saved at step 221 (50%): ./outputs/20231205141500_4_86_33to33_1720710724/20231205141500_4_86_33to33_normal_stride8_size64_batchsize512_progress_50percent.png\n",
            " 75% 331/442 [08:32<02:50,  1.53s/it]Progress image saved at step 331 (74%): ./outputs/20231205141500_4_86_33to33_1720710724/20231205141500_4_86_33to33_normal_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 442/442 [11:24<00:00,  1.55s/it]\n",
            "set dataset path\n",
            "  1% 4/442 [00:08<13:20,  1.83s/it]Progress image saved at step 4 (0%): ./outputs/20231205141500_4_86_33to33_1720711429/20231205141500_4_86_33to33_reversed_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 110/442 [02:51<08:29,  1.53s/it]Progress image saved at step 110 (24%): ./outputs/20231205141500_4_86_33to33_1720711429/20231205141500_4_86_33to33_reversed_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 221/442 [05:43<05:39,  1.54s/it]Progress image saved at step 221 (50%): ./outputs/20231205141500_4_86_33to33_1720711429/20231205141500_4_86_33to33_reversed_stride8_size64_batchsize512_progress_50percent.png\n",
            " 75% 331/442 [08:33<02:50,  1.53s/it]Progress image saved at step 331 (74%): ./outputs/20231205141500_4_86_33to33_1720711429/20231205141500_4_86_33to33_reversed_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 442/442 [11:25<00:00,  1.55s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 033 --end_idx 033 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 033 --end_idx 033 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwGqUymEMcSv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myYNp3dYbEcZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "950kTMWA2dbY",
        "outputId": "0f8a35ad-c8b8-4ec4-f419-a37e70144294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_90to110_1720707372/20231205141500_4_86_90to110_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.63s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_90to110_1720707372/20231205141500_4_86_90to110_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:24<00:22,  1.59s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_90to110_1720707372/20231205141500_4_86_90to110_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.62s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_90to110_1720707372/20231205141500_4_86_90to110_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.76s/it]\n",
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_90to110_1720707451/20231205141500_4_86_90to110_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.64s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_90to110_1720707451/20231205141500_4_86_90to110_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.60s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_90to110_1720707451/20231205141500_4_86_90to110_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.63s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_90to110_1720707451/20231205141500_4_86_90to110_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.77s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 090 --end_idx 110 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 090 --end_idx 110 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbloSxa92ddp",
        "outputId": "e549ac31-d9fc-4176-8acb-777d1b118ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_25to30_1720699295/20231205141500_4_86_25to30_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:33,  1.61s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_25to30_1720699295/20231205141500_4_86_25to30_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:24<00:21,  1.57s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_25to30_1720699295/20231205141500_4_86_25to30_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:36<00:11,  1.60s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_25to30_1720699295/20231205141500_4_86_25to30_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.75s/it]\n",
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_25to30_1720699361/20231205141500_4_86_25to30_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:35,  1.67s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_25to30_1720699361/20231205141500_4_86_25to30_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.61s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_25to30_1720699361/20231205141500_4_86_25to30_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.62s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_25to30_1720699361/20231205141500_4_86_25to30_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:50<00:00,  1.79s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 025 --end_idx 030 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 025 --end_idx 030 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8JIPqEpX5jm",
        "outputId": "eed8263c-a37b-44c4-f9ec-1ce226c0a01b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_30to35_1720699427/20231205141500_4_86_30to35_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.65s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_30to35_1720699427/20231205141500_4_86_30to35_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.60s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_30to35_1720699427/20231205141500_4_86_30to35_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.63s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_30to35_1720699427/20231205141500_4_86_30to35_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:50<00:00,  1.79s/it]\n",
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_30to35_1720699493/20231205141500_4_86_30to35_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.64s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_30to35_1720699493/20231205141500_4_86_30to35_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.60s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_30to35_1720699493/20231205141500_4_86_30to35_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.63s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_30to35_1720699493/20231205141500_4_86_30to35_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.77s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 030 --end_idx 035 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 030 --end_idx 035 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Clcy3UAgyeE3",
        "outputId": "ee5abe59-82dd-4d6d-ab89-8bb9d08adf21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_69to69_1720698640/20231205141500_4_86_69to69_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:33,  1.59s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_69to69_1720698640/20231205141500_4_86_69to69_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:24<00:21,  1.54s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_69to69_1720698640/20231205141500_4_86_69to69_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:36<00:10,  1.56s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_69to69_1720698640/20231205141500_4_86_69to69_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:48<00:00,  1.72s/it]\n",
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_69to69_1720698705/20231205141500_4_86_69to69_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.65s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_69to69_1720698705/20231205141500_4_86_69to69_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.61s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_69to69_1720698705/20231205141500_4_86_69to69_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.63s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_69to69_1720698705/20231205141500_4_86_69to69_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.78s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 069 --end_idx 069 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 069 --end_idx 069 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCrrXAG_bcJ6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srVvUpsTbcMg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKcpSBoYbcPJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kdFLRsbspQW"
      },
      "source": [
        "##550"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwKo3XiTslHq"
      },
      "outputs": [],
      "source": [
        "20231206155550_15to50_stride16_size64_batchsize512_01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx1ya7UfslKd"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231206155550_og --start_idx 15 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231206155550_og --start_idx 15 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GKsTb1PzcqPD",
        "outputId": "ac32392c-5bc7-4786-a51c-0fa6d8bd2f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_og_15to16_1720746255/20231206155550_og_15to16_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:04<00:15,  2.27s/it]Progress image saved at step 2 (22%): ./outputs/20231206155550_og_15to16_1720746255/20231206155550_og_15to16_normal_stride32_size64_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:08<00:09,  1.84s/it]Progress image saved at step 4 (44%): ./outputs/20231206155550_og_15to16_1720746255/20231206155550_og_15to16_normal_stride32_size64_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:11<00:05,  1.75s/it]Progress image saved at step 6 (66%): ./outputs/20231206155550_og_15to16_1720746255/20231206155550_og_15to16_normal_stride32_size64_batchsize512_progress_66percent.png\n",
            "100% 9/9 [00:15<00:00,  1.75s/it]\n",
            "set dataset path\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_og_15to16_1720746282/20231206155550_og_15to16_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:04<00:16,  2.31s/it]Progress image saved at step 2 (22%): ./outputs/20231206155550_og_15to16_1720746282/20231206155550_og_15to16_reversed_stride32_size64_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:08<00:09,  1.85s/it]Progress image saved at step 4 (44%): ./outputs/20231206155550_og_15to16_1720746282/20231206155550_og_15to16_reversed_stride32_size64_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:11<00:05,  1.74s/it]Progress image saved at step 6 (66%): ./outputs/20231206155550_og_15to16_1720746282/20231206155550_og_15to16_reversed_stride32_size64_batchsize512_progress_66percent.png\n",
            "100% 9/9 [00:15<00:00,  1.76s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231206155550_og --start_idx 15 --end_idx 16 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231206155550_og --start_idx 15 --end_idx 16 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kGvrBkotH8c",
        "outputId": "904b0b24-fff9-4bb2-c2e6-800d4a1929e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/34 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_og_30to40_1720706831/20231206155550_og_30to40_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 8/34 [00:14<00:41,  1.59s/it]Progress image saved at step 8 (23%): ./outputs/20231206155550_og_30to40_1720706831/20231206155550_og_30to40_normal_stride16_size64_batchsize512_progress_23percent.png\n",
            " 50% 17/34 [00:28<00:26,  1.56s/it]Progress image saved at step 17 (50%): ./outputs/20231206155550_og_30to40_1720706831/20231206155550_og_30to40_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 74% 25/34 [00:41<00:14,  1.58s/it]Progress image saved at step 25 (73%): ./outputs/20231206155550_og_30to40_1720706831/20231206155550_og_30to40_normal_stride16_size64_batchsize512_progress_73percent.png\n",
            "100% 34/34 [00:55<00:00,  1.63s/it]\n",
            "set dataset path\n",
            "  0% 0/34 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_og_30to40_1720706916/20231206155550_og_30to40_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 8/34 [00:14<00:41,  1.59s/it]Progress image saved at step 8 (23%): ./outputs/20231206155550_og_30to40_1720706916/20231206155550_og_30to40_reversed_stride16_size64_batchsize512_progress_23percent.png\n",
            " 50% 17/34 [00:28<00:26,  1.55s/it]Progress image saved at step 17 (50%): ./outputs/20231206155550_og_30to40_1720706916/20231206155550_og_30to40_reversed_stride16_size64_batchsize512_progress_50percent.png\n",
            " 74% 25/34 [00:41<00:14,  1.58s/it]Progress image saved at step 25 (73%): ./outputs/20231206155550_og_30to40_1720706916/20231206155550_og_30to40_reversed_stride16_size64_batchsize512_progress_73percent.png\n",
            "100% 34/34 [00:55<00:00,  1.62s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231206155550_og --start_idx 30 --end_idx 40 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231206155550_og --start_idx 30 --end_idx 40 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0enyVnfKslM1",
        "outputId": "0d4cf01f-afa7-43cd-c33b-e471c6ac7e5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "Image file not found for index 40\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 697, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 272, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "set dataset path\n",
            "Image file not found for index 40\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 696, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 271, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231206155550 --start_idx 40 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231206155550 --start_idx 40 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZBxzSu_b0wA"
      },
      "source": [
        "##500 hide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTaxsDB92dZK",
        "outputId": "0b46f13a-edcb-4547-9869-64b563dbe8a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/111 [00:03<07:01,  3.83s/it]Progress image saved at step 1 (0%): ./outputs/20231205141500_4_86_50to55_1720686958/20231205141500_4_86_50to55_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 27/111 [00:46<02:11,  1.57s/it]Progress image saved at step 27 (24%): ./outputs/20231205141500_4_86_50to55_1720686958/20231205141500_4_86_50to55_normal_stride16_size64_batchsize512_progress_24percent.png\n",
            " 50% 55/111 [01:30<01:27,  1.55s/it]Progress image saved at step 55 (49%): ./outputs/20231205141500_4_86_50to55_1720686958/20231205141500_4_86_50to55_normal_stride16_size64_batchsize512_progress_49percent.png\n",
            " 75% 83/111 [02:16<00:42,  1.53s/it]Progress image saved at step 83 (74%): ./outputs/20231205141500_4_86_50to55_1720686958/20231205141500_4_86_50to55_normal_stride16_size64_batchsize512_progress_74percent.png\n",
            "100% 111/111 [03:01<00:00,  1.63s/it]\n",
            "set dataset path\n",
            "  1% 1/111 [00:03<06:47,  3.70s/it]Progress image saved at step 1 (0%): ./outputs/20231205141500_4_86_50to55_1720687156/20231205141500_4_86_50to55_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 27/111 [00:45<02:11,  1.56s/it]Progress image saved at step 27 (24%): ./outputs/20231205141500_4_86_50to55_1720687156/20231205141500_4_86_50to55_reversed_stride16_size64_batchsize512_progress_24percent.png\n",
            " 50% 55/111 [01:29<01:25,  1.53s/it]Progress image saved at step 55 (49%): ./outputs/20231205141500_4_86_50to55_1720687156/20231205141500_4_86_50to55_reversed_stride16_size64_batchsize512_progress_49percent.png\n",
            " 75% 83/111 [02:13<00:43,  1.54s/it]Progress image saved at step 83 (74%): ./outputs/20231205141500_4_86_50to55_1720687156/20231205141500_4_86_50to55_reversed_stride16_size64_batchsize512_progress_74percent.png\n",
            "100% 111/111 [02:57<00:00,  1.60s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 050 --end_idx 055 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 050 --end_idx 055 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdKsUO_zyeAJ",
        "outputId": "f99cab7b-9ffb-4e38-a0cb-3490a6da27ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_86to86_1720684779/20231205141500_4_86_86to86_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.62s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_86to86_1720684779/20231205141500_4_86_86to86_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:21,  1.56s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_86to86_1720684779/20231205141500_4_86_86to86_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.58s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_86to86_1720684779/20231205141500_4_86_86to86_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.75s/it]\n",
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_86to86_1720684910/20231205141500_4_86_86to86_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:35,  1.68s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_86to86_1720684910/20231205141500_4_86_86to86_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.62s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_86to86_1720684910/20231205141500_4_86_86to86_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:38<00:11,  1.61s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_86to86_1720684910/20231205141500_4_86_86to86_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.78s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 086 --end_idx 086 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 086 --end_idx 086 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAATRZ7GziNI",
        "outputId": "25cbb9fc-1725-4e82-f57c-50c2b9ab48d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_0to0_1720693278/20231205141500_4_86_0to0_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.64s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_0to0_1720693278/20231205141500_4_86_0to0_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.60s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_0to0_1720693278/20231205141500_4_86_0to0_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.64s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_0to0_1720693278/20231205141500_4_86_0to0_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:50<00:00,  1.79s/it]\n",
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_0to0_1720693350/20231205141500_4_86_0to0_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.64s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_0to0_1720693350/20231205141500_4_86_0to0_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.60s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_0to0_1720693350/20231205141500_4_86_0to0_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.63s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_0to0_1720693350/20231205141500_4_86_0to0_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:50<00:00,  1.79s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 000 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 000 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeWVdyz7zmgA",
        "outputId": "c2edfba6-22b8-4ffc-fd19-3495350bd50c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_40to40_1720693420/20231205141500_4_86_40to40_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.64s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_40to40_1720693420/20231205141500_4_86_40to40_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.60s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_40to40_1720693420/20231205141500_4_86_40to40_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.63s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_40to40_1720693420/20231205141500_4_86_40to40_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.78s/it]\n",
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_40to40_1720693486/20231205141500_4_86_40to40_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.65s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_40to40_1720693486/20231205141500_4_86_40to40_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.60s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_40to40_1720693486/20231205141500_4_86_40to40_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.63s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_40to40_1720693486/20231205141500_4_86_40to40_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.78s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 040 --end_idx 040 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 040 --end_idx 040 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypBAU9zSyeCo",
        "outputId": "54d35928-3c41-4ef9-a409-58641e524197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_30to30_1720693557/20231205141500_4_86_30to30_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.63s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_30to30_1720693557/20231205141500_4_86_30to30_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.60s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_30to30_1720693557/20231205141500_4_86_30to30_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.62s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_30to30_1720693557/20231205141500_4_86_30to30_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.77s/it]\n",
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_30to30_1720693623/20231205141500_4_86_30to30_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.64s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_30to30_1720693623/20231205141500_4_86_30to30_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.60s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_30to30_1720693623/20231205141500_4_86_30to30_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.63s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_30to30_1720693623/20231205141500_4_86_30to30_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.77s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 030 --end_idx 030 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 030 --end_idx 030 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Se1uJrj2rU4",
        "outputId": "246c73d9-9996-402d-f93d-2a46010b986b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/105 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "  1% 1/105 [00:10<18:49, 10.87s/it]Progress image saved at step 1 (0%): ./outputs/20231205141500_4_86_52to52_1720693694/20231205141500_4_86_52to52_normal_stride16_size128_batchsize512_progress_0percent.png\n",
            " 25% 26/105 [02:24<06:05,  4.63s/it]Progress image saved at step 26 (24%): ./outputs/20231205141500_4_86_52to52_1720693694/20231205141500_4_86_52to52_normal_stride16_size128_batchsize512_progress_24percent.png\n",
            " 50% 52/105 [04:27<04:04,  4.61s/it]Progress image saved at step 52 (49%): ./outputs/20231205141500_4_86_52to52_1720693694/20231205141500_4_86_52to52_normal_stride16_size128_batchsize512_progress_49percent.png\n",
            " 74% 78/105 [06:29<02:04,  4.61s/it]Progress image saved at step 78 (74%): ./outputs/20231205141500_4_86_52to52_1720693694/20231205141500_4_86_52to52_normal_stride16_size128_batchsize512_progress_74percent.png\n",
            " 99% 104/105 [08:32<00:04,  4.60s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.46 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "100% 105/105 [08:37<00:00,  4.92s/it]\n",
            "set dataset path\n",
            "  0% 0/105 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "  1% 1/105 [00:12<22:12, 12.81s/it]Progress image saved at step 1 (0%): ./outputs/20231205141500_4_86_52to52_1720694230/20231205141500_4_86_52to52_reversed_stride16_size128_batchsize512_progress_0percent.png\n",
            " 25% 26/105 [02:13<06:05,  4.63s/it]Progress image saved at step 26 (24%): ./outputs/20231205141500_4_86_52to52_1720694230/20231205141500_4_86_52to52_reversed_stride16_size128_batchsize512_progress_24percent.png\n",
            " 50% 52/105 [04:48<04:05,  4.62s/it]Progress image saved at step 52 (49%): ./outputs/20231205141500_4_86_52to52_1720694230/20231205141500_4_86_52to52_reversed_stride16_size128_batchsize512_progress_49percent.png\n",
            " 74% 78/105 [07:24<02:04,  4.63s/it]Progress image saved at step 78 (74%): ./outputs/20231205141500_4_86_52to52_1720694230/20231205141500_4_86_52to52_reversed_stride16_size128_batchsize512_progress_74percent.png\n",
            " 99% 104/105 [10:07<00:04,  4.62s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.46 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "100% 105/105 [10:12<00:00,  5.83s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 052 --end_idx 052 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 052 --end_idx 052 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I1NIeSR2rXV",
        "outputId": "f877375b-4a0d-44d6-8372-2471f31bdc34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_70to110_1720684274/20231205141500_4_86_70to110_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:33,  1.58s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_70to110_1720684274/20231205141500_4_86_70to110_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:24<00:21,  1.53s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_70to110_1720684274/20231205141500_4_86_70to110_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:36<00:10,  1.55s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_70to110_1720684274/20231205141500_4_86_70to110_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:47<00:00,  1.71s/it]\n",
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_70to110_1720684398/20231205141500_4_86_70to110_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.63s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_70to110_1720684398/20231205141500_4_86_70to110_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.57s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_70to110_1720684398/20231205141500_4_86_70to110_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.61s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_70to110_1720684398/20231205141500_4_86_70to110_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.76s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 070 --end_idx 110 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 070 --end_idx 110 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGgl2LR92rZO",
        "outputId": "a647af50-f45b-48c4-edd2-bf3dc778093e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_0to80_1720693136/20231205141500_4_86_0to80_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:33,  1.61s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_0to80_1720693136/20231205141500_4_86_0to80_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:24<00:21,  1.56s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_0to80_1720693136/20231205141500_4_86_0to80_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:36<00:11,  1.58s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_0to80_1720693136/20231205141500_4_86_0to80_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:48<00:00,  1.74s/it]\n",
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_0to80_1720693206/20231205141500_4_86_0to80_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:34,  1.65s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_0to80_1720693206/20231205141500_4_86_0to80_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:25<00:22,  1.61s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_0to80_1720693206/20231205141500_4_86_0to80_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:37<00:11,  1.62s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_0to80_1720693206/20231205141500_4_86_0to80_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:49<00:00,  1.78s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 080 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 080 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgy8IqBFtx_y",
        "outputId": "a3830243-2bf0-4756-9e4b-c9dbb2e435c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_86to172_1720692996/20231205141500_4_86_86to172_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:12<00:32,  1.55s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_86to172_1720692996/20231205141500_4_86_86to172_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:23<00:21,  1.50s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_86to172_1720692996/20231205141500_4_86_86to172_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:35<00:10,  1.51s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_86to172_1720692996/20231205141500_4_86_86to172_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:46<00:00,  1.67s/it]\n",
            "set dataset path\n",
            "  0% 0/28 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231205141500_4_86_86to172_1720693065/20231205141500_4_86_86to172_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 7/28 [00:13<00:33,  1.60s/it]Progress image saved at step 7 (25%): ./outputs/20231205141500_4_86_86to172_1720693065/20231205141500_4_86_86to172_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 14/28 [00:24<00:21,  1.55s/it]Progress image saved at step 14 (50%): ./outputs/20231205141500_4_86_86to172_1720693065/20231205141500_4_86_86to172_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 21/28 [00:36<00:11,  1.58s/it]Progress image saved at step 21 (75%): ./outputs/20231205141500_4_86_86to172_1720693065/20231205141500_4_86_86to172_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 28/28 [00:48<00:00,  1.74s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 086 --end_idx 172 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 086 --end_idx 172 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDIe_BWoxqh4"
      },
      "outputs": [],
      "source": [
        "# Play an audio beep. Any audio URL will do.\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kz0Z8PXx0IOg"
      },
      "outputs": [],
      "source": [
        "# Play an audio beep. Any audio URL will do.\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://www.myinstants.com/en/instant/mlg-air-horn/?utm_source=copy&utm_medium=share\").play()')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8VaxztV0Fiq"
      },
      "outputs": [],
      "source": [
        "https://www.myinstants.com/en/instant/mlg-air-horn/?utm_source=copy&utm_medium=share"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h_oDwJxm2eyN",
        "outputId": "19c79a71-2a08-4c50-e571-74c6f372e8d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20240101215220"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "20240101215220"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvFrXOxdvqYL"
      },
      "source": [
        "#4433"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433_og --start_idx 00 --end_idx 10 --stride 32 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433_og --start_idx 00 --end_idx 10 --stride 32 --size 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exndMAEQUw3I",
        "outputId": "8f7dc1d4-3a14-4f7b-e472-30bb3a5d3cbe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_og_0to10_1721029196/20240116164433_og_0to10_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:36<01:28,  4.91s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_og_0to10_1721029196/20240116164433_og_0to10_normal_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:02<00:53,  4.42s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_og_0to10_1721029196/20240116164433_og_0to10_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:30<00:26,  4.45s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_og_0to10_1721029196/20240116164433_og_0to10_normal_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [01:55<00:00,  4.80s/it]\n",
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_og_0to10_1721029384/20240116164433_og_0to10_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:34<01:31,  5.06s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_og_0to10_1721029384/20240116164433_og_0to10_reversed_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:03<00:55,  4.63s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_og_0to10_1721029384/20240116164433_og_0to10_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:30<00:27,  4.53s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_og_0to10_1721029384/20240116164433_og_0to10_reversed_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [01:56<00:00,  4.83s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433_og --start_idx 10 --end_idx 20 --stride 32 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433_og --start_idx 10 --end_idx 20 --stride 32 --size 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G9-BWAfUxti",
        "outputId": "a67f66a3-0543-4937-c806-c588eb4b43b3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_og_10to20_1721029517/20240116164433_og_10to20_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:36<01:31,  5.07s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_og_10to20_1721029517/20240116164433_og_10to20_normal_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:04<00:55,  4.62s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_og_10to20_1721029517/20240116164433_og_10to20_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:32<00:27,  4.54s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_og_10to20_1721029517/20240116164433_og_10to20_normal_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [01:57<00:00,  4.90s/it]\n",
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_og_10to20_1721029684/20240116164433_og_10to20_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:37<01:32,  5.16s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_og_10to20_1721029684/20240116164433_og_10to20_reversed_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:05<00:55,  4.62s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_og_10to20_1721029684/20240116164433_og_10to20_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:33<00:27,  4.53s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_og_10to20_1721029684/20240116164433_og_10to20_reversed_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [01:58<00:00,  4.93s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433_og --start_idx 10 --end_idx 20 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433_og --start_idx 10 --end_idx 20 --stride 8 --size 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3kd5CuKUxv4",
        "outputId": "cabd217d-a3df-4452-cbef-af6ff0602e8f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set dataset path\n",
            "  1% 3/393 [00:06<12:53,  1.98s/it]Progress image saved at step 3 (0%): ./outputs/20240116164433_og_10to20_1721029819/20240116164433_og_10to20_normal_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 98/393 [02:29<07:21,  1.50s/it]Progress image saved at step 98 (24%): ./outputs/20240116164433_og_10to20_1721029819/20240116164433_og_10to20_normal_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 196/393 [04:57<04:54,  1.50s/it]Progress image saved at step 196 (49%): ./outputs/20240116164433_og_10to20_1721029819/20240116164433_og_10to20_normal_stride8_size64_batchsize512_progress_49percent.png\n",
            " 75% 294/393 [07:25<02:28,  1.50s/it]Progress image saved at step 294 (74%): ./outputs/20240116164433_og_10to20_1721029819/20240116164433_og_10to20_normal_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 393/393 [09:53<00:00,  1.51s/it]\n",
            "set dataset path\n",
            "  1% 3/393 [00:06<12:39,  1.95s/it]Progress image saved at step 3 (0%): ./outputs/20240116164433_og_10to20_1721030431/20240116164433_og_10to20_reversed_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 98/393 [02:29<07:21,  1.50s/it]Progress image saved at step 98 (24%): ./outputs/20240116164433_og_10to20_1721030431/20240116164433_og_10to20_reversed_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 196/393 [04:56<04:55,  1.50s/it]Progress image saved at step 196 (49%): ./outputs/20240116164433_og_10to20_1721030431/20240116164433_og_10to20_reversed_stride8_size64_batchsize512_progress_49percent.png\n",
            " 75% 294/393 [07:24<02:28,  1.50s/it]Progress image saved at step 294 (74%): ./outputs/20240116164433_og_10to20_1721030431/20240116164433_og_10to20_reversed_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 393/393 [09:52<00:00,  1.51s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GmmPj23pUxyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433_og --start_idx 10 --end_idx 40 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433_og --start_idx 10 --end_idx 40 --stride 32 --size 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrpgMljpVuox",
        "outputId": "56757002-4fde-46ca-e199-ef0ce49bb9de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_og_10to40_1721031043/20240116164433_og_10to40_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.65s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_og_10to40_1721031043/20240116164433_og_10to40_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:20,  1.57s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_og_10to40_1721031043/20240116164433_og_10to40_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:31<00:11,  1.58s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_og_10to40_1721031043/20240116164433_og_10to40_normal_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:42<00:00,  1.72s/it]\n",
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_og_10to40_1721031103/20240116164433_og_10to40_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.65s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_og_10to40_1721031103/20240116164433_og_10to40_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:20,  1.56s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_og_10to40_1721031103/20240116164433_og_10to40_reversed_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:31<00:11,  1.57s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_og_10to40_1721031103/20240116164433_og_10to40_reversed_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:42<00:00,  1.72s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t3J3i2-4VurP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PrTKAnDjVutv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjW2SIKSvuA8",
        "outputId": "b3c97236-0d49-44bb-94b0-b0af97a89388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_2_64_54to54_1720694873/20240116164433_2_64_54to54_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:36<01:34,  5.23s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_2_64_54to54_1720694873/20240116164433_2_64_54to54_normal_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:41<01:24,  7.01s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_2_64_54to54_1720694873/20240116164433_2_64_54to54_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [02:18<00:31,  5.32s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_2_64_54to54_1720694873/20240116164433_2_64_54to54_normal_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [02:58<00:00,  7.43s/it]\n",
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_2_64_54to54_1720695127/20240116164433_2_64_54to54_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:37<01:37,  5.42s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_2_64_54to54_1720695127/20240116164433_2_64_54to54_reversed_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:07<00:59,  4.94s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_2_64_54to54_1720695127/20240116164433_2_64_54to54_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:36<00:28,  4.68s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_2_64_54to54_1720695127/20240116164433_2_64_54to54_reversed_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [02:01<00:00,  5.08s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433_2_64 --start_idx 054 --end_idx 054 --stride 32 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433_2_64 --start_idx 054 --end_idx 054 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0-QSTwav9WV",
        "outputId": "1ad60de7-61e0-405b-89b1-47d28f3772ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_30to36_1718587191/20240116164433_30to36_normal_stride16_size128_batchsize512_progress_0percent.png\n",
            " 25% 23/93 [01:55<05:17,  4.54s/it]Progress image saved at step 23 (24%): ./outputs/20240116164433_30to36_1718587191/20240116164433_30to36_normal_stride16_size128_batchsize512_progress_24percent.png\n",
            " 49% 46/93 [03:40<03:34,  4.57s/it]Progress image saved at step 46 (49%): ./outputs/20240116164433_30to36_1718587191/20240116164433_30to36_normal_stride16_size128_batchsize512_progress_49percent.png\n",
            " 74% 69/93 [05:27<01:49,  4.56s/it]Progress image saved at step 69 (74%): ./outputs/20240116164433_30to36_1718587191/20240116164433_30to36_normal_stride16_size128_batchsize512_progress_74percent.png\n",
            " 99% 92/93 [07:13<00:04,  4.58s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.11 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.79 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "100% 93/93 [07:18<00:00,  4.71s/it]\n",
            "set dataset path\n",
            "  0% 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_30to36_1718587654/20240116164433_30to36_reversed_stride16_size128_batchsize512_progress_0percent.png\n",
            " 25% 23/93 [01:54<05:18,  4.55s/it]Progress image saved at step 23 (24%): ./outputs/20240116164433_30to36_1718587654/20240116164433_30to36_reversed_stride16_size128_batchsize512_progress_24percent.png\n",
            " 49% 46/93 [03:40<03:34,  4.55s/it]Progress image saved at step 46 (49%): ./outputs/20240116164433_30to36_1718587654/20240116164433_30to36_reversed_stride16_size128_batchsize512_progress_49percent.png\n",
            " 74% 69/93 [05:26<01:49,  4.56s/it]Progress image saved at step 69 (74%): ./outputs/20240116164433_30to36_1718587654/20240116164433_30to36_reversed_stride16_size128_batchsize512_progress_74percent.png\n",
            " 99% 92/93 [07:12<00:04,  4.56s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.11 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.79 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "100% 93/93 [07:17<00:00,  4.70s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 30 --end_idx 36 --stride 16 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 30 --end_idx 36 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGBXSmILwLVC"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 30 --end_idx 36 --stride 16 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 30 --end_idx 36 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maWQ5_5YwFh7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqNFLfF_wFkw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzRYRzyrwFnX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_-_zSkywFp8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GO8SKanLXGU",
        "outputId": "c1c87308-72c1-47ef-b458-7df45b13ce86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: inference_v23_normal.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                               [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                               [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                               [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v23_normal.py: error: argument --start_idx: invalid int value: '26--end_idx'\n",
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_26to32_1718588708/20240116164433_26to32_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:32<01:26,  4.80s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_26to32_1718588708/20240116164433_26to32_reversed_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:00<00:53,  4.49s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_26to32_1718588708/20240116164433_26to32_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:28<00:27,  4.55s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_26to32_1718588708/20240116164433_26to32_reversed_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [01:53<00:00,  4.75s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 26--end_idx 32 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 26 --end_idx 32 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwMr0SGGyRT0",
        "outputId": "c5deaf30-b903-4db4-c989-ee466ef743e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_40to58_1718426075/20240116164433_40to58_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:34<01:28,  4.93s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_40to58_1718426075/20240116164433_40to58_normal_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:02<00:54,  4.57s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_40to58_1718426075/20240116164433_40to58_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:31<00:28,  4.68s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_40to58_1718426075/20240116164433_40to58_normal_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [01:57<00:00,  4.89s/it]\n",
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_40to58_1718426210/20240116164433_40to58_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:37<01:35,  5.30s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_40to58_1718426210/20240116164433_40to58_reversed_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:06<00:57,  4.82s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_40to58_1718426210/20240116164433_40to58_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:35<00:28,  4.67s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_40to58_1718426210/20240116164433_40to58_reversed_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [02:00<00:00,  5.03s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 40 --end_idx 58 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 40 --end_idx 58 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we0pyAReyRWa",
        "outputId": "f3faf334-5b0f-4296-90e0-1a9f97bec40e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_42to52_1718426347/20240116164433_42to52_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:38<01:36,  5.37s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_42to52_1718426347/20240116164433_42to52_normal_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:07<00:57,  4.76s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_42to52_1718426347/20240116164433_42to52_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:35<00:27,  4.65s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_42to52_1718426347/20240116164433_42to52_normal_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [02:01<00:00,  5.06s/it]\n",
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_42to42_1718426485/20240116164433_42to42_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:37<01:37,  5.39s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_42to42_1718426485/20240116164433_42to42_reversed_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:06<00:57,  4.78s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_42to42_1718426485/20240116164433_42to42_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:35<00:27,  4.65s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_42to42_1718426485/20240116164433_42to42_reversed_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [02:01<00:00,  5.05s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 42 --end_idx 52 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 42 --end_idx 42 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNiAr-mmyRY0",
        "outputId": "1d2d5c08-2541-4e79-e1f5-c3ca3d5b19f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/99 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_32to34_1718424396/20240116164433_32to34_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 24/99 [00:39<01:57,  1.56s/it]Progress image saved at step 24 (24%): ./outputs/20240116164433_32to34_1718424396/20240116164433_32to34_normal_stride16_size64_batchsize512_progress_24percent.png\n",
            " 49% 49/99 [01:18<01:15,  1.52s/it]Progress image saved at step 49 (49%): ./outputs/20240116164433_32to34_1718424396/20240116164433_32to34_normal_stride16_size64_batchsize512_progress_49percent.png\n",
            " 75% 74/99 [01:57<00:38,  1.53s/it]Progress image saved at step 74 (74%): ./outputs/20240116164433_32to34_1718424396/20240116164433_32to34_normal_stride16_size64_batchsize512_progress_74percent.png\n",
            "100% 99/99 [02:35<00:00,  1.57s/it]\n",
            "set dataset path\n",
            "  0% 0/99 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_32to34_1718424568/20240116164433_32to34_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 24/99 [00:39<01:57,  1.56s/it]Progress image saved at step 24 (24%): ./outputs/20240116164433_32to34_1718424568/20240116164433_32to34_reversed_stride16_size64_batchsize512_progress_24percent.png\n",
            " 49% 49/99 [01:18<01:16,  1.52s/it]Progress image saved at step 49 (49%): ./outputs/20240116164433_32to34_1718424568/20240116164433_32to34_reversed_stride16_size64_batchsize512_progress_49percent.png\n",
            " 75% 74/99 [01:57<00:38,  1.53s/it]Progress image saved at step 74 (74%): ./outputs/20240116164433_32to34_1718424568/20240116164433_32to34_reversed_stride16_size64_batchsize512_progress_74percent.png\n",
            "100% 99/99 [02:35<00:00,  1.57s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 32 --end_idx 34 --stride 16 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 32 --end_idx 34 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzIp5X6I2eu7",
        "outputId": "e0cd94d9-b525-4aaa-e923-1cef9ffb1b3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_42to44_1718424739/20240116164433_42to44_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:37<01:35,  5.31s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_42to44_1718424739/20240116164433_42to44_normal_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:06<00:57,  4.80s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_42to44_1718424739/20240116164433_42to44_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:34<00:27,  4.66s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_42to44_1718424739/20240116164433_42to44_normal_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [02:00<00:00,  5.02s/it]\n",
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_42to44_1718424879/20240116164433_42to44_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:36<01:35,  5.32s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_42to44_1718424879/20240116164433_42to44_reversed_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:06<00:57,  4.78s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_42to44_1718424879/20240116164433_42to44_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:34<00:27,  4.65s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_42to44_1718424879/20240116164433_42to44_reversed_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [02:00<00:00,  5.02s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 42 --end_idx 44 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 42 --end_idx 44 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW1nlxey2exJ",
        "outputId": "e32c4981-0f3f-48f9-9ee0-fef91e87c068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/101 [00:01<02:25,  1.46s/it]Progress image saved at step 1 (0%): ./outputs/20240116164433_20to30_1718425016/20240116164433_20to30_normal_stride16_size32_batchsize512_progress_0percent.png\n",
            " 25% 25/101 [00:16<00:47,  1.59it/s]Progress image saved at step 25 (24%): ./outputs/20240116164433_20to30_1718425016/20240116164433_20to30_normal_stride16_size32_batchsize512_progress_24percent.png\n",
            " 50% 50/101 [00:33<00:32,  1.56it/s]Progress image saved at step 50 (49%): ./outputs/20240116164433_20to30_1718425016/20240116164433_20to30_normal_stride16_size32_batchsize512_progress_49percent.png\n",
            " 74% 75/101 [00:50<00:16,  1.59it/s]Progress image saved at step 75 (74%): ./outputs/20240116164433_20to30_1718425016/20240116164433_20to30_normal_stride16_size32_batchsize512_progress_74percent.png\n",
            "100% 101/101 [01:08<00:00,  1.48it/s]\n",
            "set dataset path\n",
            "  1% 1/101 [00:01<02:36,  1.57s/it]Progress image saved at step 1 (0%): ./outputs/20240116164433_20to30_1718425100/20240116164433_20to30_reversed_stride16_size32_batchsize512_progress_0percent.png\n",
            " 25% 25/101 [00:17<00:47,  1.60it/s]Progress image saved at step 25 (24%): ./outputs/20240116164433_20to30_1718425100/20240116164433_20to30_reversed_stride16_size32_batchsize512_progress_24percent.png\n",
            " 50% 50/101 [00:33<00:32,  1.57it/s]Progress image saved at step 50 (49%): ./outputs/20240116164433_20to30_1718425100/20240116164433_20to30_reversed_stride16_size32_batchsize512_progress_49percent.png\n",
            " 74% 75/101 [00:50<00:16,  1.57it/s]Progress image saved at step 75 (74%): ./outputs/20240116164433_20to30_1718425100/20240116164433_20to30_reversed_stride16_size32_batchsize512_progress_74percent.png\n",
            "100% 101/101 [01:08<00:00,  1.48it/s]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 20 --end_idx 30 --stride 16 --size 32\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 20 --end_idx 30 --stride 16 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6ecsTNq2e00",
        "outputId": "e9f2d614-0f55-4675-dd1f-2d587ec9a23c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_30to40_1718425184/20240116164433_30to40_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:35<01:34,  5.22s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_30to40_1718425184/20240116164433_30to40_normal_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:05<00:57,  4.83s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_30to40_1718425184/20240116164433_30to40_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:34<00:27,  4.65s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_30to40_1718425184/20240116164433_30to40_normal_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [01:59<00:00,  4.98s/it]\n",
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_30to40_1718425320/20240116164433_30to40_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 6/24 [00:38<01:37,  5.42s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_30to40_1718425320/20240116164433_30to40_reversed_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 12/24 [01:07<00:57,  4.79s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_30to40_1718425320/20240116164433_30to40_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 18/24 [01:35<00:27,  4.66s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_30to40_1718425320/20240116164433_30to40_reversed_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 24/24 [02:01<00:00,  5.06s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 30 --end_idx 40 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 30 --end_idx 40 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zhMB-ucyRbT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YljtK96u7F8"
      },
      "source": [
        "#500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2pxUbzs08EC"
      },
      "source": [
        "#SELF segmented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfwDVu-iuCwn"
      },
      "outputs": [],
      "source": [
        "251_og and 220_og"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ks72-YST4LIX"
      },
      "outputs": [],
      "source": [
        "20240116164433_20to50_stride32_size128_batchsize512_01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO1E6QeiErl-"
      },
      "outputs": [],
      "source": [
        "20240710035048_1_64 20240116164433_og"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpKxGgkhHPOQ"
      },
      "outputs": [],
      "source": [
        "20240102231959_3_64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu0Vr4xuP53S",
        "outputId": "d59ee7ad-4a76-4246-810d-da724fbd9cd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_2_64_0to10_1720676269/20240116164433_2_64_0to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:12<00:31,  1.65s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_2_64_0to10_1720676269/20240116164433_2_64_0to10_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:22<00:19,  1.53s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_2_64_0to10_1720676269/20240116164433_2_64_0to10_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:33<00:11,  1.59s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_2_64_0to10_1720676269/20240116164433_2_64_0to10_normal_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:44<00:00,  1.79s/it]\n",
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_2_64_0to10_1720676389/20240116164433_2_64_0to10_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.65s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_2_64_0to10_1720676389/20240116164433_2_64_0to10_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:20,  1.55s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_2_64_0to10_1720676389/20240116164433_2_64_0to10_reversed_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:31<00:10,  1.57s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_2_64_0to10_1720676389/20240116164433_2_64_0to10_reversed_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:42<00:00,  1.71s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_2_64 --start_idx 000 --end_idx 010 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py   --reverse 1 --segment_id \t20240116164433_2_64 --start_idx 000 --end_idx 010 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOpJhbI6P55p",
        "outputId": "50a6721b-3def-426b-cf21-f848656a8fe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_2_64_10to20_1720676447/20240116164433_2_64_10to20_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.68s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_2_64_10to20_1720676447/20240116164433_2_64_10to20_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:20,  1.58s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_2_64_10to20_1720676447/20240116164433_2_64_10to20_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:32<00:11,  1.61s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_2_64_10to20_1720676447/20240116164433_2_64_10to20_normal_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:43<00:00,  1.75s/it]\n",
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_2_64_10to20_1720676519/20240116164433_2_64_10to20_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:12<00:32,  1.70s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_2_64_10to20_1720676519/20240116164433_2_64_10to20_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:22<00:20,  1.61s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_2_64_10to20_1720676519/20240116164433_2_64_10to20_reversed_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:32<00:11,  1.63s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_2_64_10to20_1720676519/20240116164433_2_64_10to20_reversed_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:44<00:00,  1.76s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_2_64 --start_idx 010 --end_idx 020 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240116164433_2_64 --start_idx 010 --end_idx 020 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM8l9tKfP58B",
        "outputId": "131f8633-7be5-4689-ac1a-23f8c1c9e0bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "Image file not found for index 129\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 697, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 272, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "set dataset path\n",
            "Image file not found for index 129\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 696, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 271, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_2_64 --start_idx 120 --end_idx 128 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240116164433_2_64 --start_idx 120 --end_idx 128 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47Tc1Of4TGt7",
        "outputId": "435ec992-64cd-4612-ceab-f40457bce57c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_2_64_70to90_1720676627/20240116164433_2_64_70to90_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.65s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_2_64_70to90_1720676627/20240116164433_2_64_70to90_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:22<00:20,  1.61s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_2_64_70to90_1720676627/20240116164433_2_64_70to90_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:32<00:11,  1.58s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_2_64_70to90_1720676627/20240116164433_2_64_70to90_normal_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:44<00:00,  1.76s/it]\n",
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_2_64_70to90_1720676746/20240116164433_2_64_70to90_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:12<00:32,  1.71s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_2_64_70to90_1720676746/20240116164433_2_64_70to90_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:22<00:20,  1.61s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_2_64_70to90_1720676746/20240116164433_2_64_70to90_reversed_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:32<00:11,  1.62s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_2_64_70to90_1720676746/20240116164433_2_64_70to90_reversed_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:44<00:00,  1.76s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_2_64 --start_idx 070 --end_idx 090 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240116164433_2_64 --start_idx 070 --end_idx 090 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA02Hr6YTGwZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axMiIW6rTGy1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqpE9QT6TG1L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a6JEYWpErqY",
        "outputId": "fc9c25f5-ad06-41bb-9c5c-d5c7b7404bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_og_10to10_1720675500/20240116164433_og_10to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.66s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_og_10to10_1720675500/20240116164433_og_10to10_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:20,  1.60s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_og_10to10_1720675500/20240116164433_og_10to10_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:32<00:11,  1.62s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_og_10to10_1720675500/20240116164433_og_10to10_normal_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:43<00:00,  1.75s/it]\n",
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_og_10to10_1720675559/20240116164433_og_10to10_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.68s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_og_10to10_1720675559/20240116164433_og_10to10_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:20,  1.60s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_og_10to10_1720675559/20240116164433_og_10to10_reversed_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:32<00:11,  1.63s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_og_10to10_1720675559/20240116164433_og_10to10_reversed_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:44<00:00,  1.76s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_og --start_idx 10 --end_idx 10 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240116164433_og --start_idx 10 --end_idx 10 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxNugbHxCXEn",
        "outputId": "0e42e1b8-d1fa-4a6e-f452-44306dd141fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_og_0to10_1720675220/20240116164433_og_0to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.65s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_og_0to10_1720675220/20240116164433_og_0to10_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:20,  1.56s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_og_0to10_1720675220/20240116164433_og_0to10_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:32<00:11,  1.59s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_og_0to10_1720675220/20240116164433_og_0to10_normal_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:43<00:00,  1.74s/it]\n",
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_og_0to10_1720675321/20240116164433_og_0to10_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:12<00:32,  1.70s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_og_0to10_1720675321/20240116164433_og_0to10_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:22<00:21,  1.62s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_og_0to10_1720675321/20240116164433_og_0to10_reversed_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:32<00:11,  1.63s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_og_0to10_1720675321/20240116164433_og_0to10_reversed_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:44<00:00,  1.77s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_og --start_idx 00 --end_idx 10 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240116164433_og --start_idx 00 --end_idx 10 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQc0ImT4CXG-",
        "outputId": "c7001ce7-2d77-44ce-f470-df920dcebc2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_og_0to0_1720675381/20240116164433_og_0to0_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.68s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_og_0to0_1720675381/20240116164433_og_0to0_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:20,  1.60s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_og_0to0_1720675381/20240116164433_og_0to0_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:32<00:11,  1.62s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_og_0to0_1720675381/20240116164433_og_0to0_normal_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:44<00:00,  1.76s/it]\n",
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_og_0to0_1720675440/20240116164433_og_0to0_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.68s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_og_0to0_1720675440/20240116164433_og_0to0_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:20,  1.60s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_og_0to0_1720675440/20240116164433_og_0to0_reversed_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:32<00:11,  1.63s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_og_0to0_1720675440/20240116164433_og_0to0_reversed_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:43<00:00,  1.76s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_og --start_idx 00 --end_idx 00 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240116164433_og --start_idx 00 --end_idx 00 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vAlmAg-NPQB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-KaxibqNPSS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FucnjW0SNPUy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iEbM-gACXJE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x_zeaw2aQ72",
        "outputId": "16c54d32-5802-4ebc-e361-25bfacd6b44c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_og_30to40_1720515010/20240107134630_og_30to40_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:04<00:18,  2.29s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_og_30to40_1720515010/20240107134630_og_30to40_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.69s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_og_30to40_1720515010/20240107134630_og_30to40_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.68s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_og_30to40_1720515010/20240107134630_og_30to40_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.75s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_og_30to40_1720515090/20240107134630_og_30to40_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:04<00:18,  2.27s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_og_30to40_1720515090/20240107134630_og_30to40_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.70s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_og_30to40_1720515090/20240107134630_og_30to40_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.69s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_og_30to40_1720515090/20240107134630_og_30to40_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.76s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240107134630_og --start_idx 30 --end_idx 40 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240107134630_og --start_idx 30 --end_idx 40 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVVFZIJStGFN",
        "outputId": "c9143a45-7f04-4d59-f857-b94b8fa4e01c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/153 [00:03<08:42,  3.43s/it]Progress image saved at step 1 (0%): ./outputs/20240107134630_og_20to50_1720515385/20240107134630_og_20to50_normal_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 38/153 [01:03<03:02,  1.58s/it]Progress image saved at step 38 (24%): ./outputs/20240107134630_og_20to50_1720515385/20240107134630_og_20to50_normal_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 76/153 [02:04<02:05,  1.62s/it]Progress image saved at step 76 (49%): ./outputs/20240107134630_og_20to50_1720515385/20240107134630_og_20to50_normal_stride8_size64_batchsize512_progress_49percent.png\n",
            " 75% 114/153 [03:05<01:02,  1.60s/it]Progress image saved at step 114 (74%): ./outputs/20240107134630_og_20to50_1720515385/20240107134630_og_20to50_normal_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 153/153 [04:07<00:00,  1.62s/it]\n",
            "set dataset path\n",
            "  1% 1/153 [00:03<09:04,  3.58s/it]Progress image saved at step 1 (0%): ./outputs/20240107134630_og_20to50_1720515679/20240107134630_og_20to50_reversed_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 38/153 [01:03<03:04,  1.61s/it]Progress image saved at step 38 (24%): ./outputs/20240107134630_og_20to50_1720515679/20240107134630_og_20to50_reversed_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 76/153 [02:04<02:05,  1.63s/it]Progress image saved at step 76 (49%): ./outputs/20240107134630_og_20to50_1720515679/20240107134630_og_20to50_reversed_stride8_size64_batchsize512_progress_49percent.png\n",
            " 75% 114/153 [03:05<01:02,  1.59s/it]Progress image saved at step 114 (74%): ./outputs/20240107134630_og_20to50_1720515679/20240107134630_og_20to50_reversed_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 153/153 [04:07<00:00,  1.62s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240107134630_og --start_idx 20 --end_idx 50 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240107134630_og --start_idx 20 --end_idx 50 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-HI4PV4sEfj",
        "outputId": "ba0b8c8a-1d9e-474f-9630-d9d5e87e37d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_og_30to38_1720515323/20240107134630_og_30to38_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:04<00:18,  2.30s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_og_30to38_1720515323/20240107134630_og_30to38_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.77s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_og_30to38_1720515323/20240107134630_og_30to38_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.78s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_og_30to38_1720515323/20240107134630_og_30to38_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:18<00:00,  1.82s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_og_30to38_1720515354/20240107134630_og_30to38_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:19,  2.48s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_og_30to38_1720515354/20240107134630_og_30to38_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:10<00:09,  1.86s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_og_30to38_1720515354/20240107134630_og_30to38_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:14<00:05,  1.85s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_og_30to38_1720515354/20240107134630_og_30to38_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:19<00:00,  1.92s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240107134630_og --start_idx 30 --end_idx 38 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240107134630_og --start_idx 30 --end_idx 38 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikt7gYSyaQ-J",
        "outputId": "a5ac672f-421e-404b-a891-de9986e40602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/38 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_48_60to70_1720515122/20240107134630_48_60to70_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 9/38 [00:15<00:44,  1.53s/it]Progress image saved at step 9 (23%): ./outputs/20240107134630_48_60to70_1720515122/20240107134630_48_60to70_normal_stride16_size64_batchsize512_progress_23percent.png\n",
            " 50% 19/38 [00:30<00:28,  1.52s/it]Progress image saved at step 19 (50%): ./outputs/20240107134630_48_60to70_1720515122/20240107134630_48_60to70_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 74% 28/38 [00:45<00:15,  1.54s/it]Progress image saved at step 28 (73%): ./outputs/20240107134630_48_60to70_1720515122/20240107134630_48_60to70_normal_stride16_size64_batchsize512_progress_73percent.png\n",
            "100% 38/38 [01:01<00:00,  1.61s/it]\n",
            "set dataset path\n",
            "  0% 0/38 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_48_60to70_1720515244/20240107134630_48_60to70_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 9/38 [00:16<00:47,  1.63s/it]Progress image saved at step 9 (23%): ./outputs/20240107134630_48_60to70_1720515244/20240107134630_48_60to70_reversed_stride16_size64_batchsize512_progress_23percent.png\n",
            " 50% 19/38 [00:33<00:31,  1.64s/it]Progress image saved at step 19 (50%): ./outputs/20240107134630_48_60to70_1720515244/20240107134630_48_60to70_reversed_stride16_size64_batchsize512_progress_50percent.png\n",
            " 74% 28/38 [00:48<00:16,  1.67s/it]Progress image saved at step 28 (73%): ./outputs/20240107134630_48_60to70_1720515244/20240107134630_48_60to70_reversed_stride16_size64_batchsize512_progress_73percent.png\n",
            "100% 38/38 [01:05<00:00,  1.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240107134630_48 --start_idx 60 --end_idx 70 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240107134630_48 --start_idx 60 --end_idx 70 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd9aFSCcaRAo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LVksY4OXDID"
      },
      "outputs": [],
      "source": [
        "20240109095720_64_90to90_stride32_size64_batchsize512_01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGwWoVkFXDLL",
        "outputId": "cfe5da5b-1188-4421-c267-89f6eb236aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 5/596 [00:09<16:22,  1.66s/it]Progress image saved at step 5 (0%): ./outputs/20240109095720_64_90to20_1720509737/20240109095720_64_90to20_normal_stride4_size64_batchsize512_progress_0percent.png\n",
            " 25% 149/596 [03:55<11:49,  1.59s/it]Progress image saved at step 149 (25%): ./outputs/20240109095720_64_90to20_1720509737/20240109095720_64_90to20_normal_stride4_size64_batchsize512_progress_25percent.png\n",
            " 50% 298/596 [07:53<07:55,  1.60s/it]Progress image saved at step 298 (50%): ./outputs/20240109095720_64_90to20_1720509737/20240109095720_64_90to20_normal_stride4_size64_batchsize512_progress_50percent.png\n",
            " 75% 447/596 [11:52<03:58,  1.60s/it]Progress image saved at step 447 (75%): ./outputs/20240109095720_64_90to20_1720509737/20240109095720_64_90to20_normal_stride4_size64_batchsize512_progress_75percent.png\n",
            "100% 596/596 [15:49<00:00,  1.59s/it]\n",
            "set dataset path\n",
            "  1% 5/596 [00:09<17:18,  1.76s/it]Progress image saved at step 5 (0%): ./outputs/20240109095720_64_90to20_1720510706/20240109095720_64_90to20_reversed_stride4_size64_batchsize512_progress_0percent.png\n",
            " 25% 149/596 [04:00<11:54,  1.60s/it]Progress image saved at step 149 (25%): ./outputs/20240109095720_64_90to20_1720510706/20240109095720_64_90to20_reversed_stride4_size64_batchsize512_progress_25percent.png\n",
            " 50% 298/596 [07:58<07:55,  1.59s/it]Progress image saved at step 298 (50%): ./outputs/20240109095720_64_90to20_1720510706/20240109095720_64_90to20_reversed_stride4_size64_batchsize512_progress_50percent.png\n",
            " 75% 447/596 [11:57<03:58,  1.60s/it]Progress image saved at step 447 (75%): ./outputs/20240109095720_64_90to20_1720510706/20240109095720_64_90to20_reversed_stride4_size64_batchsize512_progress_75percent.png\n",
            "100% 596/596 [15:54<00:00,  1.60s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 090 --end_idx 20 --stride 4 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 090 --end_idx 20 --stride 4 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSVljBzXXDNx"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64_90 --start_idx 090 --end_idx 20 --stride 4 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64_90 --start_idx 090 --end_idx 20 --stride 4 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSpyrQSVXDQL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTNdCXgOXDSZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2fSEzFW2cvv"
      },
      "source": [
        "#0251"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6jIteUl2e0n",
        "outputId": "296ad963-cf11-436f-e013-48e331ea0b6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1vZiQHEF-pSUl3u13ohkrWAMHoP2wt4tz/inkception-3d/inference_v25_normal.py\", line 701, in <module>\n",
            "    model = RegressionPLModel.load_from_checkpoint(args.model_path, strict=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/model_helpers.py\", line 125, in wrapper\n",
            "    return self.method(cls, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1586, in load_from_checkpoint\n",
            "    loaded = _load_from_checkpoint(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 63, in _load_from_checkpoint\n",
            "    checkpoint = pl_load(checkpoint_path, map_location=map_location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/cloud_io.py\", line 56, in _load\n",
            "    with fs.open(path_or_url, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/spec.py\", line 1241, in open\n",
            "    f = self._open(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py\", line 184, in _open\n",
            "    return LocalFileOpener(path, mode, fs=self, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py\", line 315, in __init__\n",
            "    self._open()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py\", line 320, in _open\n",
            "    self.f = open(self.path, mode=self.mode)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt'\n",
            "set dataset path\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1vZiQHEF-pSUl3u13ohkrWAMHoP2wt4tz/inkception-3d/inference_v25_reversed.py\", line 700, in <module>\n",
            "    model = RegressionPLModel.load_from_checkpoint(args.model_path, strict=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/model_helpers.py\", line 125, in wrapper\n",
            "    return self.method(cls, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1586, in load_from_checkpoint\n",
            "    loaded = _load_from_checkpoint(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 63, in _load_from_checkpoint\n",
            "    checkpoint = pl_load(checkpoint_path, map_location=map_location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/cloud_io.py\", line 56, in _load\n",
            "    with fs.open(path_or_url, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/spec.py\", line 1241, in open\n",
            "    f = self._open(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py\", line 184, in _open\n",
            "    return LocalFileOpener(path, mode, fs=self, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py\", line 315, in __init__\n",
            "    self._open()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py\", line 320, in _open\n",
            "    self.f = open(self.path, mode=self.mode)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231221180251_og --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231221180251_og --start_idx 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O7DLKvrjRmC",
        "outputId": "4ea0a22d-e0d7-41e1-a87f-e2c697d9aa18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 702, in <module>\n",
            "    model.cuda()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 72, in cuda\n",
            "    device = torch.device(\"cuda\", torch.cuda.current_device())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 778, in current_device\n",
            "    _lazy_init()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "set dataset path\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 701, in <module>\n",
            "    model.cuda()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 72, in cuda\n",
            "    device = torch.device(\"cuda\", torch.cuda.current_device())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 778, in current_device\n",
            "    _lazy_init()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231221180251_og --start_idx 30 --end_idx 40 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231221180251_og --start_idx 30 --end_idx 40 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRNvoYk62etg",
        "outputId": "eba65902-c9e8-42c4-d537-df8fb9ad805a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 8/878 [00:14<23:57,  1.65s/it]Progress image saved at step 8 (0%): ./outputs/20231221180251_og_48to64_1720506156/20231221180251_og_48to64_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 219/878 [05:57<17:34,  1.60s/it]Progress image saved at step 219 (24%): ./outputs/20231221180251_og_48to64_1720506156/20231221180251_og_48to64_reversed_stride16_size64_batchsize512_progress_24percent.png\n",
            " 50% 439/878 [11:56<11:42,  1.60s/it]Progress image saved at step 439 (50%): ./outputs/20231221180251_og_48to64_1720506156/20231221180251_og_48to64_reversed_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 658/878 [17:55<05:53,  1.61s/it]Progress image saved at step 658 (74%): ./outputs/20231221180251_og_48to64_1720506156/20231221180251_og_48to64_reversed_stride16_size64_batchsize512_progress_74percent.png\n",
            "100% 878/878 [23:59<00:00,  1.64s/it]\n"
          ]
        }
      ],
      "source": [
        "#!python inference_v23_normal.py --reverse 0 --segment_id 20231221180251_og --start_idx 48 --end_idx 64 --stride 16 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20231221180251_og --start_idx 48 --end_idx 64 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP3IIAWu2ev1",
        "outputId": "6e2c463f-41fb-4688-ef99-b57aedfc8c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 2/220 [00:05<08:55,  2.46s/it]Progress image saved at step 2 (0%): ./outputs/20231221180251_og_0to10_1720504400/20231221180251_og_0to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 55/220 [01:34<04:23,  1.59s/it]Progress image saved at step 55 (25%): ./outputs/20231221180251_og_0to10_1720504400/20231221180251_og_0to10_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 110/220 [03:10<02:55,  1.60s/it]Progress image saved at step 110 (50%): ./outputs/20231221180251_og_0to10_1720504400/20231221180251_og_0to10_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 165/220 [04:48<01:27,  1.60s/it]Progress image saved at step 165 (75%): ./outputs/20231221180251_og_0to10_1720504400/20231221180251_og_0to10_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 220/220 [06:28<00:00,  1.77s/it]\n",
            "set dataset path\n",
            "  1% 2/220 [00:05<09:05,  2.50s/it]Progress image saved at step 2 (0%): ./outputs/20231221180251_og_0to10_1720504839/20231221180251_og_0to10_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 55/220 [01:35<04:24,  1.61s/it]Progress image saved at step 55 (25%): ./outputs/20231221180251_og_0to10_1720504839/20231221180251_og_0to10_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 110/220 [03:10<02:56,  1.60s/it]Progress image saved at step 110 (50%): ./outputs/20231221180251_og_0to10_1720504839/20231221180251_og_0to10_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 165/220 [04:48<01:28,  1.62s/it]Progress image saved at step 165 (75%): ./outputs/20231221180251_og_0to10_1720504839/20231221180251_og_0to10_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 220/220 [06:28<00:00,  1.77s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231221180251_og --start_idx 00 --end_idx 10 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20231221180251_og --start_idx 00 --end_idx 10 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqVhd1vT2fzX"
      },
      "source": [
        "#604"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bvg4DoNRCYzm",
        "outputId": "7bfde123-2349-4787-8510-4914d6e9ab5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "Image file not found for index 64\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 697, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 272, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "set dataset path\n",
            "Image file not found for index 64\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 696, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 271, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240626040604_3_64 --start_idx 064 --end_idx 090 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240626040604_3_64 --start_idx 064 --end_idx 090 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4XAnYCrlZeu",
        "outputId": "37e644ea-1e42-4634-a11e-f33c8b90bd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 697, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 278, in get_img_splits\n",
            "    if not np.any(fragment_mask[y1:y2, x1:x2]==0):\n",
            "TypeError: 'NoneType' object is not subscriptable\n",
            "set dataset path\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 696, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 277, in get_img_splits\n",
            "    if not np.any(fragment_mask[y1:y2, x1:x2]==0):\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240626040604_3_64 --start_idx 000 --end_idx 020 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240626040604_3_64 --start_idx 000 --end_idx 020 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzo_SE6ZlZhM",
        "outputId": "956dc36d-f8f8-42f7-be2a-1c03ff578316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "Image file not found for index 100\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 697, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 272, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "set dataset path\n",
            "Image file not found for index 100\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 696, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 271, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240626040604_3_64 --start_idx 100 --end_idx 128 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240626040604_3_64 --start_idx 100 --end_idx 128 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPPhlXU3lm6v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Udtfj1FnlZjc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR5RKubXlZmG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPu_ZXvuZfH4",
        "outputId": "ed964ae5-0215-4dd6-9693-678d5b0ccfeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/38 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_110to128_1720427236/20240109095720_64_110to128_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 9/38 [00:15<00:43,  1.52s/it]Progress image saved at step 9 (23%): ./outputs/20240109095720_64_110to128_1720427236/20240109095720_64_110to128_normal_stride16_size64_batchsize512_progress_23percent.png\n",
            " 50% 19/38 [00:31<00:28,  1.49s/it]Progress image saved at step 19 (50%): ./outputs/20240109095720_64_110to128_1720427236/20240109095720_64_110to128_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 74% 28/38 [00:45<00:15,  1.52s/it]Progress image saved at step 28 (73%): ./outputs/20240109095720_64_110to128_1720427236/20240109095720_64_110to128_normal_stride16_size64_batchsize512_progress_73percent.png\n",
            "100% 38/38 [00:59<00:00,  1.57s/it]\n",
            "set dataset path\n",
            "  0% 0/38 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_110to128_1720427372/20240109095720_64_110to128_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 9/38 [00:16<00:45,  1.57s/it]Progress image saved at step 9 (23%): ./outputs/20240109095720_64_110to128_1720427372/20240109095720_64_110to128_reversed_stride16_size64_batchsize512_progress_23percent.png\n",
            " 50% 19/38 [00:31<00:29,  1.56s/it]Progress image saved at step 19 (50%): ./outputs/20240109095720_64_110to128_1720427372/20240109095720_64_110to128_reversed_stride16_size64_batchsize512_progress_50percent.png\n",
            " 74% 28/38 [00:46<00:15,  1.56s/it]Progress image saved at step 28 (73%): ./outputs/20240109095720_64_110to128_1720427372/20240109095720_64_110to128_reversed_stride16_size64_batchsize512_progress_73percent.png\n",
            "100% 38/38 [01:01<00:00,  1.61s/it]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J44qU_FUN9g9",
        "outputId": "2497e904-d3ac-4f9c-f2d8-41c642cdd652"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/149 [00:03<07:42,  3.12s/it]Progress image saved at step 1 (0%): ./outputs/20240109095720_64_100to110_1720497217/20240109095720_64_100to110_normal_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 37/149 [01:01<03:03,  1.64s/it]Progress image saved at step 37 (24%): ./outputs/20240109095720_64_100to110_1720497217/20240109095720_64_100to110_normal_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 74/149 [02:00<02:00,  1.60s/it]Progress image saved at step 74 (49%): ./outputs/20240109095720_64_100to110_1720497217/20240109095720_64_100to110_normal_stride8_size64_batchsize512_progress_49percent.png\n",
            " 74% 111/149 [03:00<01:00,  1.58s/it]Progress image saved at step 111 (74%): ./outputs/20240109095720_64_100to110_1720497217/20240109095720_64_100to110_normal_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 149/149 [04:01<00:00,  1.62s/it]\n",
            "set dataset path\n",
            "  1% 1/149 [00:03<09:21,  3.79s/it]Progress image saved at step 1 (0%): ./outputs/20240109095720_64_100to110_1720497473/20240109095720_64_100to110_reversed_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 37/149 [01:02<02:59,  1.60s/it]Progress image saved at step 37 (24%): ./outputs/20240109095720_64_100to110_1720497473/20240109095720_64_100to110_reversed_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 74/149 [02:01<02:01,  1.63s/it]Progress image saved at step 74 (49%): ./outputs/20240109095720_64_100to110_1720497473/20240109095720_64_100to110_reversed_stride8_size64_batchsize512_progress_49percent.png\n",
            " 74% 111/149 [03:01<01:00,  1.60s/it]Progress image saved at step 111 (74%): ./outputs/20240109095720_64_100to110_1720497473/20240109095720_64_100to110_reversed_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 149/149 [04:02<00:00,  1.63s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 100 --end_idx 110 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 100 --end_idx 110 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hZwjMkmm1Ut",
        "outputId": "39d6a873-ff4e-4b30-a093-3029006300fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_50to90_1720500483/20240109095720_64_50to90_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:19,  2.39s/it]Progress image saved at step 2 (20%): ./outputs/20240109095720_64_50to90_1720500483/20240109095720_64_50to90_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:10<00:08,  1.77s/it]Progress image saved at step 5 (50%): ./outputs/20240109095720_64_50to90_1720500483/20240109095720_64_50to90_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.75s/it]Progress image saved at step 7 (70%): ./outputs/20240109095720_64_50to90_1720500483/20240109095720_64_50to90_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.79s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_50to90_1720500557/20240109095720_64_50to90_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:18,  2.37s/it]Progress image saved at step 2 (20%): ./outputs/20240109095720_64_50to90_1720500557/20240109095720_64_50to90_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:10<00:08,  1.78s/it]Progress image saved at step 5 (50%): ./outputs/20240109095720_64_50to90_1720500557/20240109095720_64_50to90_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.78s/it]Progress image saved at step 7 (70%): ./outputs/20240109095720_64_50to90_1720500557/20240109095720_64_50to90_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:18<00:00,  1.81s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 050 --end_idx 90 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 050 --end_idx 90 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGMHcb47zOnO",
        "outputId": "4b221fbb-80fb-455e-d453-5b19e7753ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_20to20_1720500588/20240109095720_64_20to20_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:19,  2.38s/it]Progress image saved at step 2 (20%): ./outputs/20240109095720_64_20to20_1720500588/20240109095720_64_20to20_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:10<00:08,  1.79s/it]Progress image saved at step 5 (50%): ./outputs/20240109095720_64_20to20_1720500588/20240109095720_64_20to20_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.78s/it]Progress image saved at step 7 (70%): ./outputs/20240109095720_64_20to20_1720500588/20240109095720_64_20to20_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:18<00:00,  1.81s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_20to20_1720500664/20240109095720_64_20to20_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:19,  2.44s/it]Progress image saved at step 2 (20%): ./outputs/20240109095720_64_20to20_1720500664/20240109095720_64_20to20_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:10<00:09,  1.83s/it]Progress image saved at step 5 (50%): ./outputs/20240109095720_64_20to20_1720500664/20240109095720_64_20to20_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:14<00:05,  1.82s/it]Progress image saved at step 7 (70%): ./outputs/20240109095720_64_20to20_1720500664/20240109095720_64_20to20_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:18<00:00,  1.86s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 020 --end_idx 020 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 020 --end_idx 020 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "johqnj2wzOpd",
        "outputId": "06b72545-96fa-49ec-f2ac-5db14e62626c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/38 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_95to100_1720500696/20240109095720_64_95to100_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 9/38 [00:17<00:49,  1.70s/it]Progress image saved at step 9 (23%): ./outputs/20240109095720_64_95to100_1720500696/20240109095720_64_95to100_normal_stride16_size64_batchsize512_progress_23percent.png\n",
            " 50% 19/38 [00:34<00:31,  1.67s/it]Progress image saved at step 19 (50%): ./outputs/20240109095720_64_95to100_1720500696/20240109095720_64_95to100_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 74% 28/38 [00:49<00:16,  1.61s/it]Progress image saved at step 28 (73%): ./outputs/20240109095720_64_95to100_1720500696/20240109095720_64_95to100_normal_stride16_size64_batchsize512_progress_73percent.png\n",
            "100% 38/38 [01:04<00:00,  1.70s/it]\n",
            "set dataset path\n",
            "  0% 0/38 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_95to100_1720500773/20240109095720_64_95to100_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 9/38 [00:16<00:47,  1.62s/it]Progress image saved at step 9 (23%): ./outputs/20240109095720_64_95to100_1720500773/20240109095720_64_95to100_reversed_stride16_size64_batchsize512_progress_23percent.png\n",
            " 50% 19/38 [00:33<00:31,  1.64s/it]Progress image saved at step 19 (50%): ./outputs/20240109095720_64_95to100_1720500773/20240109095720_64_95to100_reversed_stride16_size64_batchsize512_progress_50percent.png\n",
            " 74% 28/38 [00:48<00:16,  1.67s/it]Progress image saved at step 28 (73%): ./outputs/20240109095720_64_95to100_1720500773/20240109095720_64_95to100_reversed_stride16_size64_batchsize512_progress_73percent.png\n",
            "100% 38/38 [01:04<00:00,  1.69s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 095 --end_idx 100 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 095 --end_idx 100 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-VlNCpWzOr9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTTgTOVtm1Wr",
        "outputId": "17e83f14-9214-41f7-f328-1ccbdf6b63a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_110to128_1720497750/20240109095720_64_110to128_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:04<00:18,  2.31s/it]Progress image saved at step 2 (20%): ./outputs/20240109095720_64_110to128_1720497750/20240109095720_64_110to128_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.77s/it]Progress image saved at step 5 (50%): ./outputs/20240109095720_64_110to128_1720497750/20240109095720_64_110to128_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.77s/it]Progress image saved at step 7 (70%): ./outputs/20240109095720_64_110to128_1720497750/20240109095720_64_110to128_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.79s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_110to128_1720497808/20240109095720_64_110to128_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:04<00:18,  2.29s/it]Progress image saved at step 2 (20%): ./outputs/20240109095720_64_110to128_1720497808/20240109095720_64_110to128_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:10<00:09,  1.80s/it]Progress image saved at step 5 (50%): ./outputs/20240109095720_64_110to128_1720497808/20240109095720_64_110to128_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.80s/it]Progress image saved at step 7 (70%): ./outputs/20240109095720_64_110to128_1720497808/20240109095720_64_110to128_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:18<00:00,  1.81s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 110 --end_idx 128 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 110 --end_idx 128 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUD7cE79m1ZP",
        "outputId": "2b754b83-c365-40cc-dfff-0824ea43a133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "Image file not found for index 129\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 697, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 272, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "set dataset path\n",
            "Image file not found for index 129\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 696, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_reversed.py\", line 271, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 128 --end_idx 128 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 128 --end_idx 128 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkQ8QPfam1bk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvr0ZB-Xm1SP"
      },
      "outputs": [],
      "source": [
        "# Play an audio beep. Any audio URL will do.\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwt2Fyaam6b2"
      },
      "source": [
        "#hide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bswKeASYOBFi",
        "outputId": "1886dee9-c19b-4882-c0a4-09e045bff0ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/149 [00:03<08:17,  3.36s/it]Progress image saved at step 1 (0%): ./outputs/20240109095720_64_50to80_1720426093/20240109095720_64_50to80_normal_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 37/149 [00:56<02:44,  1.46s/it]Progress image saved at step 37 (24%): ./outputs/20240109095720_64_50to80_1720426093/20240109095720_64_50to80_normal_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 74/149 [01:52<01:54,  1.53s/it]Progress image saved at step 74 (49%): ./outputs/20240109095720_64_50to80_1720426093/20240109095720_64_50to80_normal_stride8_size64_batchsize512_progress_49percent.png\n",
            " 74% 111/149 [02:49<00:58,  1.53s/it]Progress image saved at step 111 (74%): ./outputs/20240109095720_64_50to80_1720426093/20240109095720_64_50to80_normal_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 149/149 [03:48<00:00,  1.53s/it]\n",
            "set dataset path\n",
            "  1% 1/149 [00:04<10:23,  4.21s/it]Progress image saved at step 1 (0%): ./outputs/20240109095720_64_50to80_1720426388/20240109095720_64_50to80_reversed_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 37/149 [00:59<02:52,  1.54s/it]Progress image saved at step 37 (24%): ./outputs/20240109095720_64_50to80_1720426388/20240109095720_64_50to80_reversed_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 74/149 [01:56<01:55,  1.54s/it]Progress image saved at step 74 (49%): ./outputs/20240109095720_64_50to80_1720426388/20240109095720_64_50to80_reversed_stride8_size64_batchsize512_progress_49percent.png\n",
            " 74% 111/149 [02:54<00:58,  1.53s/it]Progress image saved at step 111 (74%): ./outputs/20240109095720_64_50to80_1720426388/20240109095720_64_50to80_reversed_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 149/149 [03:52<00:00,  1.56s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 050 --end_idx 080 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 050 --end_idx 080 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syMsVg5IOF-b",
        "outputId": "d5d1950e-a465-421c-e4e2-eec2ed7408eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_0to10_1720425193/20240109095720_64_0to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:19,  2.38s/it]Progress image saved at step 2 (20%): ./outputs/20240109095720_64_0to10_1720425193/20240109095720_64_0to10_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.71s/it]Progress image saved at step 5 (50%): ./outputs/20240109095720_64_0to10_1720425193/20240109095720_64_0to10_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.70s/it]Progress image saved at step 7 (70%): ./outputs/20240109095720_64_0to10_1720425193/20240109095720_64_0to10_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.76s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_0to10_1720425224/20240109095720_64_0to10_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:19,  2.42s/it]Progress image saved at step 2 (20%): ./outputs/20240109095720_64_0to10_1720425224/20240109095720_64_0to10_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:10<00:08,  1.73s/it]Progress image saved at step 5 (50%): ./outputs/20240109095720_64_0to10_1720425224/20240109095720_64_0to10_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.71s/it]Progress image saved at step 7 (70%): ./outputs/20240109095720_64_0to10_1720425224/20240109095720_64_0to10_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.78s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 000 --end_idx 010 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 000 --end_idx 010 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyPIuZvTN9jM",
        "outputId": "a77cb578-d25f-4fee-8456-4c45470929d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/38 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_0to0_1720425256/20240109095720_64_0to0_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 9/38 [00:15<00:43,  1.51s/it]Progress image saved at step 9 (23%): ./outputs/20240109095720_64_0to0_1720425256/20240109095720_64_0to0_normal_stride16_size64_batchsize512_progress_23percent.png\n",
            " 50% 19/38 [00:31<00:28,  1.48s/it]Progress image saved at step 19 (50%): ./outputs/20240109095720_64_0to0_1720425256/20240109095720_64_0to0_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 74% 28/38 [00:44<00:14,  1.49s/it]Progress image saved at step 28 (73%): ./outputs/20240109095720_64_0to0_1720425256/20240109095720_64_0to0_normal_stride16_size64_batchsize512_progress_73percent.png\n",
            "100% 38/38 [00:59<00:00,  1.56s/it]\n",
            "set dataset path\n",
            "  0% 0/38 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_64_0to0_1720425330/20240109095720_64_0to0_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 9/38 [00:16<00:45,  1.56s/it]Progress image saved at step 9 (23%): ./outputs/20240109095720_64_0to0_1720425330/20240109095720_64_0to0_reversed_stride16_size64_batchsize512_progress_23percent.png\n",
            " 50% 19/38 [00:32<00:29,  1.53s/it]Progress image saved at step 19 (50%): ./outputs/20240109095720_64_0to0_1720425330/20240109095720_64_0to0_reversed_stride16_size64_batchsize512_progress_50percent.png\n",
            " 74% 28/38 [00:46<00:15,  1.55s/it]Progress image saved at step 28 (73%): ./outputs/20240109095720_64_0to0_1720425330/20240109095720_64_0to0_reversed_stride16_size64_batchsize512_progress_73percent.png\n",
            "100% 38/38 [01:01<00:00,  1.62s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 000 --end_idx 000 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 000 --end_idx 000 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ5BazWrN9lj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi9lgLebN9ny"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtQbmpTVN9qO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4hK7IDHBLbK",
        "outputId": "ac5e38cc-ddc6-4cc5-9717-959f0aaaf440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_48_0to96_1720418272/20240107134630_48_0to96_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:18,  2.37s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_48_0to96_1720418272/20240107134630_48_0to96_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.71s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_48_0to96_1720418272/20240107134630_48_0to96_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.70s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_48_0to96_1720418272/20240107134630_48_0to96_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.78s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_48_0to96_1720418393/20240107134630_48_0to96_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:04<00:18,  2.31s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_48_0to96_1720418393/20240107134630_48_0to96_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.71s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_48_0to96_1720418393/20240107134630_48_0to96_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.71s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_48_0to96_1720418393/20240107134630_48_0to96_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.77s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240107134630_48 --start_idx 00 --end_idx 96 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240107134630_48 --start_idx 00 --end_idx 96 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oEeULHf7w6T",
        "outputId": "ac252e77-7e8b-41b6-aae3-2acba5514012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_48_20to50_1720418676/20240107134630_48_20to50_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:04<00:17,  2.19s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_48_20to50_1720418676/20240107134630_48_20to50_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.70s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_48_20to50_1720418676/20240107134630_48_20to50_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.71s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_48_20to50_1720418676/20240107134630_48_20to50_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.75s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_48_20to50_1720418765/20240107134630_48_20to50_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:19,  2.38s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_48_20to50_1720418765/20240107134630_48_20to50_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:10<00:08,  1.75s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_48_20to50_1720418765/20240107134630_48_20to50_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.74s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_48_20to50_1720418765/20240107134630_48_20to50_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:18<00:00,  1.81s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240107134630_48 --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240107134630_48 --start_idx 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9V0AG4q7w8t"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240107134630_48 --start_idx 0 --end_idx 10 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240107134630_48 --start_idx 00 --end_idx 10 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq6ccxZR7w_C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXgMnRRv7xBh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z34WxgUX59WF",
        "outputId": "4c2bc19a-19aa-4abf-c8d6-063cb408e3ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_48_0to16_1720418425/20240107134630_48_0to16_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:18,  2.35s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_48_0to16_1720418425/20240107134630_48_0to16_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.73s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_48_0to16_1720418425/20240107134630_48_0to16_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.72s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_48_0to16_1720418425/20240107134630_48_0to16_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.79s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_48_0to16_1720418456/20240107134630_48_0to16_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:04<00:18,  2.27s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_48_0to16_1720418456/20240107134630_48_0to16_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.71s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_48_0to16_1720418456/20240107134630_48_0to16_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.72s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_48_0to16_1720418456/20240107134630_48_0to16_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.77s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240107134630_48 --start_idx 00 --end_idx 16 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240107134630_48 --start_idx 00 --end_idx 16 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL1GfiH-59Yi",
        "outputId": "114434fc-6951-4bcc-ddc7-fe262d5ed5b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_48_80to96_1720418555/20240107134630_48_80to96_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:18,  2.32s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_48_80to96_1720418555/20240107134630_48_80to96_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.72s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_48_80to96_1720418555/20240107134630_48_80to96_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.71s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_48_80to96_1720418555/20240107134630_48_80to96_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.78s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_48_80to96_1720418644/20240107134630_48_80to96_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:19,  2.40s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_48_80to96_1720418644/20240107134630_48_80to96_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:10<00:08,  1.75s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_48_80to96_1720418644/20240107134630_48_80to96_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.74s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_48_80to96_1720418644/20240107134630_48_80to96_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:18<00:00,  1.81s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240107134630_48 --start_idx 80 --end_idx 96 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240107134630_48 --start_idx 80 --end_idx 96 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUuHWxql59ax"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiOTEdxdADCr",
        "outputId": "252cffff-b274-4475-e1aa-1ddd78e73fe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_0to20_1720408719/20240116164433_0to20_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.68s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_0to20_1720408719/20240116164433_0to20_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:20,  1.59s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_0to20_1720408719/20240116164433_0to20_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:32<00:11,  1.61s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_0to20_1720408719/20240116164433_0to20_normal_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:43<00:00,  1.74s/it]\n",
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_0to20_1720408778/20240116164433_0to20_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.66s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_0to20_1720408778/20240116164433_0to20_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:20,  1.58s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_0to20_1720408778/20240116164433_0to20_reversed_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:31<00:11,  1.60s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_0to20_1720408778/20240116164433_0to20_reversed_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:43<00:00,  1.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 000 --end_idx 020 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 000 --end_idx 020 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXI3p1eYws5k",
        "outputId": "706dbc28-99c8-427a-a4cb-72733b7bf98a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_64to64_1720408835/20240116164433_64to64_normal_stride16_size128_batchsize512_progress_0percent.png\n",
            " 25% 23/93 [01:55<05:20,  4.58s/it]Progress image saved at step 23 (24%): ./outputs/20240116164433_64to64_1720408835/20240116164433_64to64_normal_stride16_size128_batchsize512_progress_24percent.png\n",
            " 49% 46/93 [03:41<03:35,  4.59s/it]Progress image saved at step 46 (49%): ./outputs/20240116164433_64to64_1720408835/20240116164433_64to64_normal_stride16_size128_batchsize512_progress_49percent.png\n",
            " 74% 69/93 [05:28<01:50,  4.60s/it]Progress image saved at step 69 (74%): ./outputs/20240116164433_64to64_1720408835/20240116164433_64to64_normal_stride16_size128_batchsize512_progress_74percent.png\n",
            "100% 93/93 [07:18<00:00,  4.72s/it]\n",
            "set dataset path\n",
            "  0% 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_64to64_1720409291/20240116164433_64to64_reversed_stride16_size128_batchsize512_progress_0percent.png\n",
            " 25% 23/93 [01:56<05:20,  4.58s/it]Progress image saved at step 23 (24%): ./outputs/20240116164433_64to64_1720409291/20240116164433_64to64_reversed_stride16_size128_batchsize512_progress_24percent.png\n",
            " 49% 46/93 [03:42<03:35,  4.59s/it]Progress image saved at step 46 (49%): ./outputs/20240116164433_64to64_1720409291/20240116164433_64to64_reversed_stride16_size128_batchsize512_progress_49percent.png\n",
            " 74% 69/93 [05:29<01:50,  4.59s/it]Progress image saved at step 69 (74%): ./outputs/20240116164433_64to64_1720409291/20240116164433_64to64_reversed_stride16_size128_batchsize512_progress_74percent.png\n",
            "100% 93/93 [07:19<00:00,  4.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 064 --end_idx 064 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 064 --end_idx 064 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLLzk9vaCYxM",
        "outputId": "24f62f54-37ba-46a7-dfcb-0a481b41a8b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_108to128_1720408551/20240116164433_108to128_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:30,  1.62s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_108to128_1720408551/20240116164433_108to128_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:19,  1.53s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_108to128_1720408551/20240116164433_108to128_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:30<00:10,  1.54s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_108to128_1720408551/20240116164433_108to128_normal_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:41<00:00,  1.68s/it]\n",
            "set dataset path\n",
            "  0% 0/25 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240116164433_108to128_1720408662/20240116164433_108to128_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 6/25 [00:11<00:31,  1.65s/it]Progress image saved at step 6 (24%): ./outputs/20240116164433_108to128_1720408662/20240116164433_108to128_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 48% 12/25 [00:21<00:20,  1.56s/it]Progress image saved at step 12 (48%): ./outputs/20240116164433_108to128_1720408662/20240116164433_108to128_reversed_stride32_size64_batchsize512_progress_48percent.png\n",
            " 72% 18/25 [00:31<00:11,  1.57s/it]Progress image saved at step 18 (72%): ./outputs/20240116164433_108to128_1720408662/20240116164433_108to128_reversed_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 25/25 [00:42<00:00,  1.71s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 108 --end_idx 128 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 108 --end_idx 128 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w5q4J8ECY1y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ql7oPf_CY4E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G04pL0KvZfsd",
        "outputId": "1143e584-dfcf-467a-c556-aeb354ec2c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/21 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240102231959_20to40_1720378040/20240102231959_20to40_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 5/21 [00:10<00:27,  1.71s/it]Progress image saved at step 5 (23%): ./outputs/20240102231959_20to40_1720378040/20240102231959_20to40_normal_stride32_size64_batchsize512_progress_23percent.png\n",
            " 48% 10/21 [00:18<00:17,  1.56s/it]Progress image saved at step 10 (47%): ./outputs/20240102231959_20to40_1720378040/20240102231959_20to40_normal_stride32_size64_batchsize512_progress_47percent.png\n",
            " 71% 15/21 [00:26<00:09,  1.57s/it]Progress image saved at step 15 (71%): ./outputs/20240102231959_20to40_1720378040/20240102231959_20to40_normal_stride32_size64_batchsize512_progress_71percent.png\n",
            "100% 21/21 [00:36<00:00,  1.73s/it]\n",
            "set dataset path\n",
            "  0% 0/21 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240102231959_20to40_1720378090/20240102231959_20to40_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 5/21 [00:10<00:28,  1.76s/it]Progress image saved at step 5 (23%): ./outputs/20240102231959_20to40_1720378090/20240102231959_20to40_reversed_stride32_size64_batchsize512_progress_23percent.png\n",
            " 48% 10/21 [00:18<00:17,  1.60s/it]Progress image saved at step 10 (47%): ./outputs/20240102231959_20to40_1720378090/20240102231959_20to40_reversed_stride32_size64_batchsize512_progress_47percent.png\n",
            " 71% 15/21 [00:27<00:09,  1.60s/it]Progress image saved at step 15 (71%): ./outputs/20240102231959_20to40_1720378090/20240102231959_20to40_reversed_stride32_size64_batchsize512_progress_71percent.png\n",
            "100% 21/21 [00:37<00:00,  1.77s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 20 --end_idx 30 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 20 --end_idx 30 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HZhGTT_N7Ca",
        "outputId": "193785ad-691c-4bba-ee05-5863eb289377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/48 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_0to64_1720376319/20231206155550_0to64_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 12/48 [00:20<00:54,  1.51s/it]Progress image saved at step 12 (25%): ./outputs/20231206155550_0to64_1720376319/20231206155550_0to64_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 24/48 [00:38<00:36,  1.52s/it]Progress image saved at step 24 (50%): ./outputs/20231206155550_0to64_1720376319/20231206155550_0to64_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 36/48 [00:57<00:18,  1.54s/it]Progress image saved at step 36 (75%): ./outputs/20231206155550_0to64_1720376319/20231206155550_0to64_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 48/48 [01:15<00:00,  1.57s/it]\n",
            "set dataset path\n",
            "  0% 0/48 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_0to64_1720376463/20231206155550_0to64_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 12/48 [00:20<00:54,  1.53s/it]Progress image saved at step 12 (25%): ./outputs/20231206155550_0to64_1720376463/20231206155550_0to64_reversed_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 24/48 [00:39<00:36,  1.54s/it]Progress image saved at step 24 (50%): ./outputs/20231206155550_0to64_1720376463/20231206155550_0to64_reversed_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 36/48 [00:58<00:18,  1.53s/it]Progress image saved at step 36 (75%): ./outputs/20231206155550_0to64_1720376463/20231206155550_0to64_reversed_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 48/48 [01:15<00:00,  1.58s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20231206155550 --start_idx 00 --end_idx 64 --stride 16 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20231206155550 --start_idx 00 --end_idx 64 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byuvTzHQZemo",
        "outputId": "1b4a99ee-157b-481b-a2a2-e10152a38b93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/48 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_20to50_1720376926/20231206155550_20to50_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 12/48 [00:20<00:54,  1.52s/it]Progress image saved at step 12 (25%): ./outputs/20231206155550_20to50_1720376926/20231206155550_20to50_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 24/48 [00:39<00:36,  1.53s/it]Progress image saved at step 24 (50%): ./outputs/20231206155550_20to50_1720376926/20231206155550_20to50_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 36/48 [00:58<00:18,  1.53s/it]Progress image saved at step 36 (75%): ./outputs/20231206155550_20to50_1720376926/20231206155550_20to50_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 48/48 [01:15<00:00,  1.58s/it]\n",
            "set dataset path\n",
            "  0% 0/48 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_20to50_1720377067/20231206155550_20to50_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 12/48 [00:20<00:54,  1.52s/it]Progress image saved at step 12 (25%): ./outputs/20231206155550_20to50_1720377067/20231206155550_20to50_reversed_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 24/48 [00:39<00:36,  1.54s/it]Progress image saved at step 24 (50%): ./outputs/20231206155550_20to50_1720377067/20231206155550_20to50_reversed_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 36/48 [00:57<00:18,  1.53s/it]Progress image saved at step 36 (75%): ./outputs/20231206155550_20to50_1720377067/20231206155550_20to50_reversed_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 48/48 [01:15<00:00,  1.57s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20231206155550 --start_idx 20 --end_idx 50 --stride 16 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20231206155550 --start_idx 20 --end_idx 50 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWK-Xv61Zih5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVSosPgQZikN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y4ll8ikZimj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yk5ZaqtM7dg"
      },
      "outputs": [],
      "source": [
        "# Play an audio beep. Any audio URL will do.\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACRLO3wbZipN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcKQkjWuZiud"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCU0nKnWOtIi",
        "outputId": "fe66c465-e834-46d7-9b72-cf8ac6d2b262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240704153520_0to64_1720378392/20240704153520_0to64_normal_stride16_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:20<01:07,  6.12s/it]Progress image saved at step 3 (21%): ./outputs/20240704153520_0to64_1720378392/20240704153520_0to64_normal_stride16_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:39<00:34,  4.98s/it]Progress image saved at step 7 (50%): ./outputs/20240704153520_0to64_1720378392/20240704153520_0to64_normal_stride16_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:53<00:19,  4.83s/it]Progress image saved at step 10 (71%): ./outputs/20240704153520_0to64_1720378392/20240704153520_0to64_normal_stride16_size128_batchsize512_progress_71percent.png\n",
            " 93% 13/14 [01:08<00:04,  4.77s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.22 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.16 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "100% 14/14 [01:12<00:00,  5.19s/it]\n",
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240704153520_0to64_1720378481/20240704153520_0to64_reversed_stride16_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:21<01:09,  6.32s/it]Progress image saved at step 3 (21%): ./outputs/20240704153520_0to64_1720378481/20240704153520_0to64_reversed_stride16_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:40<00:34,  4.95s/it]Progress image saved at step 7 (50%): ./outputs/20240704153520_0to64_1720378481/20240704153520_0to64_reversed_stride16_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:54<00:19,  4.85s/it]Progress image saved at step 10 (71%): ./outputs/20240704153520_0to64_1720378481/20240704153520_0to64_reversed_stride16_size128_batchsize512_progress_71percent.png\n",
            " 93% 13/14 [01:09<00:04,  4.79s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.22 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.16 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "100% 14/14 [01:13<00:00,  5.25s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240704153520 --start_idx 0 --end_idx 64 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240704153520 --start_idx 0 --end_idx 64 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSnX-aD5iJpr",
        "outputId": "3e92ff2c-b1ac-4779-eff7-c9600377f1a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240704153520_20to50_1720378572/20240704153520_20to50_normal_stride16_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:22<01:11,  6.51s/it]Progress image saved at step 3 (21%): ./outputs/20240704153520_20to50_1720378572/20240704153520_20to50_normal_stride16_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:41<00:34,  4.98s/it]Progress image saved at step 7 (50%): ./outputs/20240704153520_20to50_1720378572/20240704153520_20to50_normal_stride16_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:55<00:19,  4.86s/it]Progress image saved at step 10 (71%): ./outputs/20240704153520_20to50_1720378572/20240704153520_20to50_normal_stride16_size128_batchsize512_progress_71percent.png\n",
            " 93% 13/14 [01:10<00:04,  4.79s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.22 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.16 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "100% 14/14 [01:14<00:00,  5.32s/it]\n",
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240704153520_20to50_1720378663/20240704153520_20to50_reversed_stride16_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:21<01:10,  6.44s/it]Progress image saved at step 3 (21%): ./outputs/20240704153520_20to50_1720378663/20240704153520_20to50_reversed_stride16_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:40<00:34,  4.96s/it]Progress image saved at step 7 (50%): ./outputs/20240704153520_20to50_1720378663/20240704153520_20to50_reversed_stride16_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:55<00:19,  4.84s/it]Progress image saved at step 10 (71%): ./outputs/20240704153520_20to50_1720378663/20240704153520_20to50_reversed_stride16_size128_batchsize512_progress_71percent.png\n",
            " 93% 13/14 [01:09<00:04,  4.79s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.22 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.16 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "100% 14/14 [01:14<00:00,  5.29s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240704153520 --start_idx 20 --end_idx 50 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240704153520 --start_idx 20 --end_idx 50 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMN8Mz7OcXqM",
        "outputId": "a34452fe-fcde-48a9-8b7a-f32d4c4b0ebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/5 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240704153520_0to10_1720378236/20240704153520_0to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 1/5 [00:03<00:14,  3.54s/it]Progress image saved at step 1 (20%): ./outputs/20240704153520_0to10_1720378236/20240704153520_0to10_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 40% 2/5 [00:05<00:08,  2.76s/it]Progress image saved at step 2 (40%): ./outputs/20240704153520_0to10_1720378236/20240704153520_0to10_normal_stride32_size64_batchsize512_progress_40percent.png\n",
            " 60% 3/5 [00:08<00:05,  2.54s/it]Progress image saved at step 3 (60%): ./outputs/20240704153520_0to10_1720378236/20240704153520_0to10_normal_stride32_size64_batchsize512_progress_60percent.png\n",
            "100% 5/5 [00:11<00:00,  2.38s/it]\n",
            "set dataset path\n",
            "  0% 0/5 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240704153520_0to10_1720378263/20240704153520_0to10_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 1/5 [00:03<00:14,  3.64s/it]Progress image saved at step 1 (20%): ./outputs/20240704153520_0to10_1720378263/20240704153520_0to10_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 40% 2/5 [00:05<00:08,  2.80s/it]Progress image saved at step 2 (40%): ./outputs/20240704153520_0to10_1720378263/20240704153520_0to10_reversed_stride32_size64_batchsize512_progress_40percent.png\n",
            " 60% 3/5 [00:08<00:05,  2.57s/it]Progress image saved at step 3 (60%): ./outputs/20240704153520_0to10_1720378263/20240704153520_0to10_reversed_stride32_size64_batchsize512_progress_60percent.png\n",
            "100% 5/5 [00:12<00:00,  2.40s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240704153520 --start_idx 48 --end_idx 64 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240704153520 --start_idx 48 --end_idx 64 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9La_8mgcXvQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lsgRXEEcXxk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pi0QkzF5ntn",
        "outputId": "16e7a1bd-db5c-4ad9-9a54-b017287eb3b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/56 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240704153520_0to10_1720381593/20240704153520_0to10_normal_stride8_size128_batchsize512_progress_0percent.png\n",
            " 25% 14/56 [01:10<03:06,  4.44s/it]Progress image saved at step 14 (25%): ./outputs/20240704153520_0to10_1720381593/20240704153520_0to10_normal_stride8_size128_batchsize512_progress_25percent.png\n",
            " 50% 28/56 [02:14<02:04,  4.46s/it]Progress image saved at step 28 (50%): ./outputs/20240704153520_0to10_1720381593/20240704153520_0to10_normal_stride8_size128_batchsize512_progress_50percent.png\n",
            " 75% 42/56 [03:17<01:02,  4.49s/it]Progress image saved at step 42 (75%): ./outputs/20240704153520_0to10_1720381593/20240704153520_0to10_normal_stride8_size128_batchsize512_progress_75percent.png\n",
            "100% 56/56 [04:18<00:00,  4.62s/it]\n",
            "set dataset path\n",
            "  0% 0/56 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240704153520_0to10_1720381872/20240704153520_0to10_reversed_stride8_size128_batchsize512_progress_0percent.png\n",
            " 25% 14/56 [01:13<03:12,  4.57s/it]Progress image saved at step 14 (25%): ./outputs/20240704153520_0to10_1720381872/20240704153520_0to10_reversed_stride8_size128_batchsize512_progress_25percent.png\n",
            " 50% 28/56 [02:18<02:07,  4.56s/it]Progress image saved at step 28 (50%): ./outputs/20240704153520_0to10_1720381872/20240704153520_0to10_reversed_stride8_size128_batchsize512_progress_50percent.png\n",
            " 75% 42/56 [03:22<01:03,  4.53s/it]Progress image saved at step 42 (75%): ./outputs/20240704153520_0to10_1720381872/20240704153520_0to10_reversed_stride8_size128_batchsize512_progress_75percent.png\n",
            "100% 56/56 [04:23<00:00,  4.71s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240704153520 --start_idx 00 --end_idx 10 --stride 8 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240704153520 --start_idx 00 --end_idx 10 --stride 8 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFCsvY1gBLdo"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240626040604 --start_idx 40 --end_idx 64 --stride 4 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240626040604 --start_idx 40 --end_idx 64 --stride 4 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxaA_HqJBLlC"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 20 --end_idx 50 --stride 4 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 20 --end_idx 50 --stride 4 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vk3c9QlOtFb",
        "outputId": "40f8168b-b0d6-4600-9979-cd71cadfc0c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 96/9679 [02:27<4:06:50,  1.55s/it]Progress image saved at step 96 (0%): ./outputs/20240626040604_0to20_1720339012/20240626040604_0to20_normal_stride2_size64_batchsize512_progress_0percent.png\n",
            " 25% 2419/9679 [1:01:58<3:06:20,  1.54s/it]Progress image saved at step 2419 (24%): ./outputs/20240626040604_0to20_1720339012/20240626040604_0to20_normal_stride2_size64_batchsize512_progress_24percent.png\n",
            " 50% 4839/9679 [2:03:58<2:04:01,  1.54s/it]Progress image saved at step 4839 (49%): ./outputs/20240626040604_0to20_1720339012/20240626040604_0to20_normal_stride2_size64_batchsize512_progress_49percent.png\n",
            " 75% 7259/9679 [3:06:00<1:01:56,  1.54s/it]Progress image saved at step 7259 (74%): ./outputs/20240626040604_0to20_1720339012/20240626040604_0to20_normal_stride2_size64_batchsize512_progress_74percent.png\n",
            "100% 9679/9679 [4:08:00<00:00,  1.54s/it]\n",
            "set dataset path\n",
            "  1% 96/9679 [02:28<4:07:50,  1.55s/it]Progress image saved at step 96 (0%): ./outputs/20240626040604_0to20_1720354033/20240626040604_0to20_reversed_stride2_size64_batchsize512_progress_0percent.png\n",
            " 25% 2419/9679 [1:02:00<3:05:49,  1.54s/it]Progress image saved at step 2419 (24%): ./outputs/20240626040604_0to20_1720354033/20240626040604_0to20_reversed_stride2_size64_batchsize512_progress_24percent.png\n",
            " 50% 4839/9679 [2:03:56<2:03:45,  1.53s/it]Progress image saved at step 4839 (49%): ./outputs/20240626040604_0to20_1720354033/20240626040604_0to20_reversed_stride2_size64_batchsize512_progress_49percent.png\n",
            " 75% 7259/9679 [3:05:52<1:01:46,  1.53s/it]Progress image saved at step 7259 (74%): ./outputs/20240626040604_0to20_1720354033/20240626040604_0to20_reversed_stride2_size64_batchsize512_progress_74percent.png\n",
            " 88% 8551/9679 [3:38:58<28:59,  1.54s/it]"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240626040604 --start_idx 00 --end_idx 20 --stride 2 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240626040604 --start_idx 00 --end_idx 20 --stride 2 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUVaKbK-uMjO",
        "outputId": "93d11ab9-4001-4a37-91bb-8dfe21067291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/47 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240701175700_0to64_1719895010/20240701175700_0to64_normal_stride16_size128_batchsize512_progress_0percent.png\n",
            " 23% 11/47 [00:56<02:45,  4.59s/it]Progress image saved at step 11 (23%): ./outputs/20240701175700_0to64_1719895010/20240701175700_0to64_normal_stride16_size128_batchsize512_progress_23percent.png\n",
            " 49% 23/47 [01:53<01:54,  4.78s/it]Progress image saved at step 23 (48%): ./outputs/20240701175700_0to64_1719895010/20240701175700_0to64_normal_stride16_size128_batchsize512_progress_48percent.png\n",
            " 74% 35/47 [02:50<00:56,  4.68s/it]Progress image saved at step 35 (74%): ./outputs/20240701175700_0to64_1719895010/20240701175700_0to64_normal_stride16_size128_batchsize512_progress_74percent.png\n",
            "100% 47/47 [03:46<00:00,  4.81s/it]\n",
            "set dataset path\n",
            "  0% 0/47 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240701175700_0to64_1719895334/20240701175700_0to64_reversed_stride16_size128_batchsize512_progress_0percent.png\n",
            " 23% 11/47 [01:00<02:57,  4.94s/it]Progress image saved at step 11 (23%): ./outputs/20240701175700_0to64_1719895334/20240701175700_0to64_reversed_stride16_size128_batchsize512_progress_23percent.png\n",
            " 49% 23/47 [01:57<01:52,  4.70s/it]Progress image saved at step 23 (48%): ./outputs/20240701175700_0to64_1719895334/20240701175700_0to64_reversed_stride16_size128_batchsize512_progress_48percent.png\n",
            " 74% 35/47 [02:54<00:56,  4.70s/it]Progress image saved at step 35 (74%): ./outputs/20240701175700_0to64_1719895334/20240701175700_0to64_reversed_stride16_size128_batchsize512_progress_74percent.png\n",
            "100% 47/47 [03:50<00:00,  4.90s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 000 --end_idx 064 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 000 --end_idx 064 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8ZrjOwIuMl2",
        "outputId": "bc786e3e-d737-4b9f-cd27-d547f45405b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/47 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240701175700_64to128_1719895580/20240701175700_64to128_normal_stride16_size128_batchsize512_progress_0percent.png\n",
            " 23% 11/47 [01:00<02:57,  4.92s/it]Progress image saved at step 11 (23%): ./outputs/20240701175700_64to128_1719895580/20240701175700_64to128_normal_stride16_size128_batchsize512_progress_23percent.png\n",
            " 49% 23/47 [01:56<01:51,  4.66s/it]Progress image saved at step 23 (48%): ./outputs/20240701175700_64to128_1719895580/20240701175700_64to128_normal_stride16_size128_batchsize512_progress_48percent.png\n",
            " 74% 35/47 [02:54<00:56,  4.71s/it]Progress image saved at step 35 (74%): ./outputs/20240701175700_64to128_1719895580/20240701175700_64to128_normal_stride16_size128_batchsize512_progress_74percent.png\n",
            "100% 47/47 [03:49<00:00,  4.89s/it]\n",
            "set dataset path\n",
            "  0% 0/47 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240701175700_64to128_1719895888/20240701175700_64to128_reversed_stride16_size128_batchsize512_progress_0percent.png\n",
            " 23% 11/47 [01:01<02:56,  4.90s/it]Progress image saved at step 11 (23%): ./outputs/20240701175700_64to128_1719895888/20240701175700_64to128_reversed_stride16_size128_batchsize512_progress_23percent.png\n",
            " 49% 23/47 [01:58<01:52,  4.70s/it]Progress image saved at step 23 (48%): ./outputs/20240701175700_64to128_1719895888/20240701175700_64to128_reversed_stride16_size128_batchsize512_progress_48percent.png\n",
            " 74% 35/47 [02:55<00:56,  4.70s/it]Progress image saved at step 35 (74%): ./outputs/20240701175700_64to128_1719895888/20240701175700_64to128_reversed_stride16_size128_batchsize512_progress_74percent.png\n",
            "100% 47/47 [03:51<00:00,  4.92s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 064 --end_idx 128 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 064 --end_idx 128 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ey-IqW-ug7T",
        "outputId": "d95f6d26-b904-44ca-c479-d0294f45abe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/52 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240701175700_20to50_1719869613/20240701175700_20to50_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 13/52 [00:21<00:57,  1.48s/it]Progress image saved at step 13 (25%): ./outputs/20240701175700_20to50_1719869613/20240701175700_20to50_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 26/52 [00:41<00:38,  1.50s/it]Progress image saved at step 26 (50%): ./outputs/20240701175700_20to50_1719869613/20240701175700_20to50_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 39/52 [01:02<00:19,  1.53s/it]Progress image saved at step 39 (75%): ./outputs/20240701175700_20to50_1719869613/20240701175700_20to50_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 52/52 [01:22<00:00,  1.59s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 020 --end_idx 050 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 020 --end_idx 050 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDhh366oSo19",
        "outputId": "2583252e-10c7-405d-8743-cc47d0303224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/52 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240701175700_60to128_1719871474/20240701175700_60to128_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 13/52 [00:21<00:57,  1.48s/it]Progress image saved at step 13 (25%): ./outputs/20240701175700_60to128_1719871474/20240701175700_60to128_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 26/52 [00:41<00:39,  1.51s/it]Progress image saved at step 26 (50%): ./outputs/20240701175700_60to128_1719871474/20240701175700_60to128_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 39/52 [01:02<00:20,  1.54s/it]Progress image saved at step 39 (75%): ./outputs/20240701175700_60to128_1719871474/20240701175700_60to128_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 52/52 [01:22<00:00,  1.59s/it]\n",
            "set dataset path\n",
            "  0% 0/52 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240701175700_60to128_1719871617/20240701175700_60to128_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 13/52 [00:23<01:03,  1.62s/it]Progress image saved at step 13 (25%): ./outputs/20240701175700_60to128_1719871617/20240701175700_60to128_reversed_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 26/52 [00:45<00:41,  1.60s/it]Progress image saved at step 26 (50%): ./outputs/20240701175700_60to128_1719871617/20240701175700_60to128_reversed_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 39/52 [01:06<00:20,  1.56s/it]Progress image saved at step 39 (75%): ./outputs/20240701175700_60to128_1719871617/20240701175700_60to128_reversed_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 52/52 [01:26<00:00,  1.66s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 060 --end_idx 128 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 060 --end_idx 128 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAL-h5klSo4p",
        "outputId": "54af843d-eada-4f45-f207-2a9be697434f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/13 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240701175700_0to42_1719870987/20240701175700_0to42_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 23% 3/13 [00:06<00:20,  2.04s/it]Progress image saved at step 3 (23%): ./outputs/20240701175700_0to42_1719870987/20240701175700_0to42_normal_stride32_size64_batchsize512_progress_23percent.png\n",
            " 46% 6/13 [00:11<00:12,  1.73s/it]Progress image saved at step 6 (46%): ./outputs/20240701175700_0to42_1719870987/20240701175700_0to42_normal_stride32_size64_batchsize512_progress_46percent.png\n",
            " 69% 9/13 [00:17<00:06,  1.69s/it]Progress image saved at step 9 (69%): ./outputs/20240701175700_0to42_1719870987/20240701175700_0to42_normal_stride32_size64_batchsize512_progress_69percent.png\n",
            "100% 13/13 [00:24<00:00,  1.86s/it]\n",
            "set dataset path\n",
            "  0% 0/13 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240701175700_0to42_1719871026/20240701175700_0to42_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 23% 3/13 [00:07<00:20,  2.07s/it]Progress image saved at step 3 (23%): ./outputs/20240701175700_0to42_1719871026/20240701175700_0to42_reversed_stride32_size64_batchsize512_progress_23percent.png\n",
            " 46% 6/13 [00:12<00:12,  1.76s/it]Progress image saved at step 6 (46%): ./outputs/20240701175700_0to42_1719871026/20240701175700_0to42_reversed_stride32_size64_batchsize512_progress_46percent.png\n",
            " 69% 9/13 [00:17<00:06,  1.71s/it]Progress image saved at step 9 (69%): ./outputs/20240701175700_0to42_1719871026/20240701175700_0to42_reversed_stride32_size64_batchsize512_progress_69percent.png\n",
            "100% 13/13 [00:24<00:00,  1.89s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 000 --end_idx 042 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 000 --end_idx 042 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OR2-F2CCx9L",
        "outputId": "0a8891af-ba57-4c95-c5d9-a79bb89c35a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 2/206 [00:05<08:21,  2.46s/it]Progress image saved at step 2 (0%): ./outputs/20240701175700_0to128_1719876865/20240701175700_0to128_normal_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 51/206 [01:16<03:48,  1.48s/it]Progress image saved at step 51 (24%): ./outputs/20240701175700_0to128_1719876865/20240701175700_0to128_normal_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 103/206 [02:34<02:34,  1.50s/it]Progress image saved at step 103 (50%): ./outputs/20240701175700_0to128_1719876865/20240701175700_0to128_normal_stride8_size64_batchsize512_progress_50percent.png\n",
            " 75% 154/206 [03:51<01:17,  1.49s/it]Progress image saved at step 154 (74%): ./outputs/20240701175700_0to128_1719876865/20240701175700_0to128_normal_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 206/206 [05:09<00:00,  1.50s/it]\n",
            "set dataset path\n",
            "  1% 2/206 [00:05<08:21,  2.46s/it]Progress image saved at step 2 (0%): ./outputs/20240701175700_0to128_1719877272/20240701175700_0to128_reversed_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 51/206 [01:19<03:50,  1.49s/it]Progress image saved at step 51 (24%): ./outputs/20240701175700_0to128_1719877272/20240701175700_0to128_reversed_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 103/206 [02:37<02:33,  1.49s/it]Progress image saved at step 103 (50%): ./outputs/20240701175700_0to128_1719877272/20240701175700_0to128_reversed_stride8_size64_batchsize512_progress_50percent.png\n",
            " 75% 154/206 [03:54<01:17,  1.49s/it]Progress image saved at step 154 (74%): ./outputs/20240701175700_0to128_1719877272/20240701175700_0to128_reversed_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 206/206 [05:13<00:00,  1.52s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 000 --end_idx 128 --stride 08 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 000 --end_idx 128 --stride 08 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsrIGMS1o8Cs",
        "outputId": "6e536479-1deb-4543-9f82-c52b3210f496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/47 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240701175700_0to128_1719877602/20240701175700_0to128_normal_stride16_size128_batchsize512_progress_0percent.png\n",
            " 23% 11/47 [00:57<02:48,  4.68s/it]Progress image saved at step 11 (23%): ./outputs/20240701175700_0to128_1719877602/20240701175700_0to128_normal_stride16_size128_batchsize512_progress_23percent.png\n",
            " 49% 23/47 [01:52<01:47,  4.48s/it]Progress image saved at step 23 (48%): ./outputs/20240701175700_0to128_1719877602/20240701175700_0to128_normal_stride16_size128_batchsize512_progress_48percent.png\n",
            " 74% 35/47 [02:46<00:53,  4.48s/it]Progress image saved at step 35 (74%): ./outputs/20240701175700_0to128_1719877602/20240701175700_0to128_normal_stride16_size128_batchsize512_progress_74percent.png\n",
            "100% 47/47 [03:39<00:00,  4.68s/it]\n",
            "set dataset path\n",
            "  0% 0/47 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240701175700_0to128_1719877839/20240701175700_0to128_reversed_stride16_size128_batchsize512_progress_0percent.png\n",
            " 23% 11/47 [00:59<02:47,  4.64s/it]Progress image saved at step 11 (23%): ./outputs/20240701175700_0to128_1719877839/20240701175700_0to128_reversed_stride16_size128_batchsize512_progress_23percent.png\n",
            " 49% 23/47 [01:54<01:47,  4.48s/it]Progress image saved at step 23 (48%): ./outputs/20240701175700_0to128_1719877839/20240701175700_0to128_reversed_stride16_size128_batchsize512_progress_48percent.png\n",
            " 74% 35/47 [02:48<00:53,  4.49s/it]Progress image saved at step 35 (74%): ./outputs/20240701175700_0to128_1719877839/20240701175700_0to128_reversed_stride16_size128_batchsize512_progress_74percent.png\n",
            "100% 47/47 [03:41<00:00,  4.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 000 --end_idx 128 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 000 --end_idx 128 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-j8U5APuLKu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe2vhYk3uLNj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFINGt2Sug9_"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240627002342 --start_idx 00 --end_idx 64 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240627002342 --start_idx 00 --end_idx 64 --stride 32 --size 128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvfeM3FxuhAQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLIkDBIKuhC2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojmGnWdeN6i5",
        "outputId": "f42aebe6-c665-485d-9e83-6fa47ab4718a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/84 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240626040604_12to62_1719640195/20240626040604_12to62_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 21/84 [00:34<01:34,  1.50s/it]Progress image saved at step 21 (25%): ./outputs/20240626040604_12to62_1719640195/20240626040604_12to62_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 42/84 [01:07<01:04,  1.53s/it]Progress image saved at step 42 (50%): ./outputs/20240626040604_12to62_1719640195/20240626040604_12to62_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 63/84 [01:40<00:32,  1.56s/it]Progress image saved at step 63 (75%): ./outputs/20240626040604_12to62_1719640195/20240626040604_12to62_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 84/84 [02:13<00:00,  1.59s/it]\n",
            "set dataset path\n",
            "  0% 0/84 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240626040604_12to62_1719640419/20240626040604_12to62_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 21/84 [00:35<01:38,  1.56s/it]Progress image saved at step 21 (25%): ./outputs/20240626040604_12to62_1719640419/20240626040604_12to62_reversed_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 42/84 [01:09<01:04,  1.54s/it]Progress image saved at step 42 (50%): ./outputs/20240626040604_12to62_1719640419/20240626040604_12to62_reversed_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 63/84 [01:42<00:32,  1.54s/it]Progress image saved at step 63 (75%): ./outputs/20240626040604_12to62_1719640419/20240626040604_12to62_reversed_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 84/84 [02:15<00:00,  1.61s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240629031634 --start_idx 22 --end_idx 52 --stride 16 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240629031634 --start_idx 22 --end_idx 52 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ovc-rm-N7JS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcvpE5B5780o",
        "outputId": "0f12d6e1-4dbf-4286-c1e0-c03e898cf4c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240626040604_0to64_1719393383/20240626040604_0to64_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 5/20 [00:30<01:20,  5.35s/it]Progress image saved at step 5 (25%): ./outputs/20240626040604_0to64_1719393383/20240626040604_0to64_normal_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 10/20 [00:55<00:48,  4.84s/it]Progress image saved at step 10 (50%): ./outputs/20240626040604_0to64_1719393383/20240626040604_0to64_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 15/20 [01:18<00:23,  4.68s/it]Progress image saved at step 15 (75%): ./outputs/20240626040604_0to64_1719393383/20240626040604_0to64_normal_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 20/20 [01:40<00:00,  5.04s/it]\n",
            "set dataset path\n",
            "  0% 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240626040604_0to64_1719393500/20240626040604_0to64_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 25% 5/20 [00:31<01:21,  5.46s/it]Progress image saved at step 5 (25%): ./outputs/20240626040604_0to64_1719393500/20240626040604_0to64_reversed_stride32_size128_batchsize512_progress_25percent.png\n",
            " 50% 10/20 [00:55<00:48,  4.83s/it]Progress image saved at step 10 (50%): ./outputs/20240626040604_0to64_1719393500/20240626040604_0to64_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 75% 15/20 [01:19<00:23,  4.66s/it]Progress image saved at step 15 (75%): ./outputs/20240626040604_0to64_1719393500/20240626040604_0to64_reversed_stride32_size128_batchsize512_progress_75percent.png\n",
            "100% 20/20 [01:41<00:00,  5.07s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240626040604 --start_idx 00 --end_idx 64 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240626040604 --start_idx 00 --end_idx 64 --stride 32 --size 128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPCyoXE1CyZD",
        "outputId": "6c2f27b3-8a63-4e14-aaa8-998f86a6a822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 3/333 [00:06<10:09,  1.85s/it]Progress image saved at step 3 (0%): ./outputs/20240626040604_20to50_1719393617/20240626040604_20to50_normal_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 83/333 [02:08<06:20,  1.52s/it]Progress image saved at step 83 (24%): ./outputs/20240626040604_20to50_1719393617/20240626040604_20to50_normal_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 166/333 [04:14<04:13,  1.52s/it]Progress image saved at step 166 (49%): ./outputs/20240626040604_20to50_1719393617/20240626040604_20to50_normal_stride8_size64_batchsize512_progress_49percent.png\n",
            " 75% 249/333 [06:21<02:07,  1.52s/it]Progress image saved at step 249 (74%): ./outputs/20240626040604_20to50_1719393617/20240626040604_20to50_normal_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 333/333 [08:30<00:00,  1.53s/it]\n",
            "set dataset path\n",
            "  1% 3/333 [00:06<10:18,  1.87s/it]Progress image saved at step 3 (0%): ./outputs/20240626040604_20to50_1719394184/20240626040604_20to50_reversed_stride8_size64_batchsize512_progress_0percent.png\n",
            " 25% 83/333 [02:08<06:20,  1.52s/it]Progress image saved at step 83 (24%): ./outputs/20240626040604_20to50_1719394184/20240626040604_20to50_reversed_stride8_size64_batchsize512_progress_24percent.png\n",
            " 50% 166/333 [04:15<04:13,  1.52s/it]Progress image saved at step 166 (49%): ./outputs/20240626040604_20to50_1719394184/20240626040604_20to50_reversed_stride8_size64_batchsize512_progress_49percent.png\n",
            " 75% 249/333 [06:22<02:07,  1.52s/it]Progress image saved at step 249 (74%): ./outputs/20240626040604_20to50_1719394184/20240626040604_20to50_reversed_stride8_size64_batchsize512_progress_74percent.png\n",
            "100% 333/333 [08:30<00:00,  1.53s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240626040604 --start_idx 20 --end_idx 50 --stride 08 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240626040604 --start_idx 20 --end_idx 50 --stride 08 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qchjfUgK_qSY",
        "outputId": "914e0a1d-9268-4868-a814-a3bbada68b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/21 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240626040604_0to20_1719394712/20240626040604_0to20_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 5/21 [00:10<00:27,  1.75s/it]Progress image saved at step 5 (23%): ./outputs/20240626040604_0to20_1719394712/20240626040604_0to20_normal_stride32_size64_batchsize512_progress_23percent.png\n",
            " 48% 10/21 [00:18<00:17,  1.62s/it]Progress image saved at step 10 (47%): ./outputs/20240626040604_0to20_1719394712/20240626040604_0to20_normal_stride32_size64_batchsize512_progress_47percent.png\n",
            " 71% 15/21 [00:27<00:09,  1.63s/it]Progress image saved at step 15 (71%): ./outputs/20240626040604_0to20_1719394712/20240626040604_0to20_normal_stride32_size64_batchsize512_progress_71percent.png\n",
            "100% 21/21 [00:37<00:00,  1.79s/it]\n",
            "set dataset path\n",
            "  0% 0/21 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240626040604_0to20_1719394764/20240626040604_0to20_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 5/21 [00:10<00:27,  1.73s/it]Progress image saved at step 5 (23%): ./outputs/20240626040604_0to20_1719394764/20240626040604_0to20_reversed_stride32_size64_batchsize512_progress_23percent.png\n",
            " 48% 10/21 [00:18<00:17,  1.61s/it]Progress image saved at step 10 (47%): ./outputs/20240626040604_0to20_1719394764/20240626040604_0to20_reversed_stride32_size64_batchsize512_progress_47percent.png\n",
            " 71% 15/21 [00:27<00:09,  1.63s/it]Progress image saved at step 15 (71%): ./outputs/20240626040604_0to20_1719394764/20240626040604_0to20_reversed_stride32_size64_batchsize512_progress_71percent.png\n",
            "100% 21/21 [00:37<00:00,  1.78s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240626040604 --start_idx 0 --end_idx 20 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240626040604 --start_idx 0 --end_idx 20 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD0qp7Gl783J",
        "outputId": "de22081c-a15a-4716-db20-c3b1bde1fc89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/21 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240626040604_48to58_1719394815/20240626040604_48to58_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 5/21 [00:10<00:27,  1.73s/it]Progress image saved at step 5 (23%): ./outputs/20240626040604_48to58_1719394815/20240626040604_48to58_normal_stride32_size64_batchsize512_progress_23percent.png\n",
            " 48% 10/21 [00:18<00:17,  1.60s/it]Progress image saved at step 10 (47%): ./outputs/20240626040604_48to58_1719394815/20240626040604_48to58_normal_stride32_size64_batchsize512_progress_47percent.png\n",
            " 71% 15/21 [00:26<00:09,  1.60s/it]Progress image saved at step 15 (71%): ./outputs/20240626040604_48to58_1719394815/20240626040604_48to58_normal_stride32_size64_batchsize512_progress_71percent.png\n",
            "100% 21/21 [00:37<00:00,  1.76s/it]\n",
            "set dataset path\n",
            "  0% 0/21 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240626040604_48to58_1719394923/20240626040604_48to58_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 5/21 [00:10<00:28,  1.76s/it]Progress image saved at step 5 (23%): ./outputs/20240626040604_48to58_1719394923/20240626040604_48to58_reversed_stride32_size64_batchsize512_progress_23percent.png\n",
            " 48% 10/21 [00:18<00:17,  1.63s/it]Progress image saved at step 10 (47%): ./outputs/20240626040604_48to58_1719394923/20240626040604_48to58_reversed_stride32_size64_batchsize512_progress_47percent.png\n",
            " 71% 15/21 [00:27<00:09,  1.64s/it]Progress image saved at step 15 (71%): ./outputs/20240626040604_48to58_1719394923/20240626040604_48to58_reversed_stride32_size64_batchsize512_progress_71percent.png\n",
            "100% 21/21 [00:37<00:00,  1.78s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240626040604 --start_idx 48 --end_idx 58 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240626040604 --start_idx 48 --end_idx 58 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV1b7UnyjQRD"
      },
      "source": [
        "#632"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCB78Di4WEil",
        "outputId": "edecd5ac-a166-4e4f-8c7d-fe2619928186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "[ WARN:0@23.855] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20240624014055/layers/23.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "set dataset path\n",
            "[ WARN:0@3.402] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20240624014055/layers/23.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240625010632 --start_idx 10 --end_idx 20 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240625010632 --start_idx 10 --end_idx 20 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WsDm2-0Dk4W",
        "outputId": "43dde7d2-ee19-414c-ab0d-ea4f1e73440d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/17 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240625010632_25to35_1719355182/20240625010632_25to35_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 24% 4/17 [00:25<01:13,  5.62s/it]Progress image saved at step 4 (23%): ./outputs/20240625010632_25to35_1719355182/20240625010632_25to35_normal_stride32_size128_batchsize512_progress_23percent.png\n",
            " 47% 8/17 [00:44<00:42,  4.71s/it]Progress image saved at step 8 (47%): ./outputs/20240625010632_25to35_1719355182/20240625010632_25to35_normal_stride32_size128_batchsize512_progress_47percent.png\n",
            " 71% 12/17 [01:02<00:23,  4.63s/it]Progress image saved at step 12 (70%): ./outputs/20240625010632_25to35_1719355182/20240625010632_25to35_normal_stride32_size128_batchsize512_progress_70percent.png\n",
            "100% 17/17 [01:23<00:00,  4.92s/it]\n",
            "set dataset path\n",
            "  0% 0/17 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240625010632_25to35_1719355334/20240625010632_25to35_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 24% 4/17 [00:28<01:19,  6.13s/it]Progress image saved at step 4 (23%): ./outputs/20240625010632_25to35_1719355334/20240625010632_25to35_reversed_stride32_size128_batchsize512_progress_23percent.png\n",
            " 47% 8/17 [00:48<00:47,  5.24s/it]Progress image saved at step 8 (47%): ./outputs/20240625010632_25to35_1719355334/20240625010632_25to35_reversed_stride32_size128_batchsize512_progress_47percent.png\n",
            " 71% 12/17 [01:09<00:25,  5.10s/it]Progress image saved at step 12 (70%): ./outputs/20240625010632_25to35_1719355334/20240625010632_25to35_reversed_stride32_size128_batchsize512_progress_70percent.png\n",
            "100% 17/17 [01:31<00:00,  5.37s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240625010632 --start_idx 25 --end_idx 35 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240625010632 --start_idx 25 --end_idx 35 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwFy7fhYCybq",
        "outputId": "66149fe8-fb84-4efc-b5bc-f26b70ec3f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/12 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240623200654_40to50_1719196131/20240623200654_40to50_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 3/12 [00:06<00:18,  2.02s/it]Progress image saved at step 3 (25%): ./outputs/20240623200654_40to50_1719196131/20240623200654_40to50_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 6/12 [00:11<00:10,  1.72s/it]Progress image saved at step 6 (50%): ./outputs/20240623200654_40to50_1719196131/20240623200654_40to50_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 9/12 [00:17<00:05,  1.68s/it]Progress image saved at step 9 (75%): ./outputs/20240623200654_40to50_1719196131/20240623200654_40to50_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 12/12 [00:22<00:00,  1.85s/it]\n",
            "set dataset path\n",
            "  0% 0/12 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240623200654_40to50_1719196179/20240623200654_40to50_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 3/12 [00:06<00:17,  1.98s/it]Progress image saved at step 3 (25%): ./outputs/20240623200654_40to50_1719196179/20240623200654_40to50_reversed_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 6/12 [00:11<00:10,  1.73s/it]Progress image saved at step 6 (50%): ./outputs/20240623200654_40to50_1719196179/20240623200654_40to50_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 9/12 [00:16<00:05,  1.70s/it]Progress image saved at step 9 (75%): ./outputs/20240623200654_40to50_1719196179/20240623200654_40to50_reversed_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 12/12 [00:22<00:00,  1.85s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240625010632 --start_idx 40 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240625010632 --start_idx 40 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsbDPeL2Dk6-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9dbUhtuDk9o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRyW6eM3CyeQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmnGOnpA786D",
        "outputId": "a1d9b02d-bfa1-45cf-960e-653cf11bbbcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "[ WARN:0@4.453] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20240623200654/layers/65.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "set dataset path\n",
            "[ WARN:0@4.506] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20240623200654/layers/65.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240624014055 --start_idx 50 --end_idx 59 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240624014055 --start_idx 50 --end_idx 59 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgoGdKMK8bqz",
        "outputId": "562e13ed-a6a4-4eeb-a29e-ea9f08bee442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "[ WARN:0@3.091] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20240624014055/layers/23.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "python3: can't open file '/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_nreversed.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240624014055 --start_idx 20 --end_idx 30 --stride 32 --size 64\n",
        "!python inference_v23_nreversed.py --reverse 1 --segment_id 20240624014055 --start_idx 20 --end_idx 30 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5lXWZCe8abF"
      },
      "source": [
        "#ARCHIVE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRJhxpt578-_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SG4SWRs79Db"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsODmYix2-wU",
        "outputId": "f53cc93f-63d1-44d6-963b-1281aeedabda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/12 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240623200654_20to50_1719192630/20240623200654_20to50_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 3/12 [00:06<00:16,  1.89s/it]Progress image saved at step 3 (25%): ./outputs/20240623200654_20to50_1719192630/20240623200654_20to50_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 6/12 [00:11<00:09,  1.66s/it]Progress image saved at step 6 (50%): ./outputs/20240623200654_20to50_1719192630/20240623200654_20to50_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 9/12 [00:16<00:04,  1.63s/it]Progress image saved at step 9 (75%): ./outputs/20240623200654_20to50_1719192630/20240623200654_20to50_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 12/12 [00:21<00:00,  1.78s/it]\n",
            "set dataset path\n",
            "  0% 0/12 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240623200654_20to50_1719192716/20240623200654_20to50_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 3/12 [00:06<00:18,  2.01s/it]Progress image saved at step 3 (25%): ./outputs/20240623200654_20to50_1719192716/20240623200654_20to50_normal_stride32_size64_batchsize512_progress_25percent.png\n",
            " 50% 6/12 [00:11<00:10,  1.70s/it]Progress image saved at step 6 (50%): ./outputs/20240623200654_20to50_1719192716/20240623200654_20to50_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 9/12 [00:16<00:04,  1.65s/it]Progress image saved at step 9 (75%): ./outputs/20240623200654_20to50_1719192716/20240623200654_20to50_normal_stride32_size64_batchsize512_progress_75percent.png\n",
            "100% 12/12 [00:22<00:00,  1.84s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240623200654 --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v23_normal.py --reverse 1 --segment_id 20240623200654 --start_idx 20 --end_idx 50 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6utH8jdWElW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjCq1_BYWEnv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnnfuveFWEp9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEfZGW2LWEsl"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240619064521 --start_idx 30 --end_idx 40 --stride 32 --size 64\n",
        "!python inference_v23_normal.py --reverse 1 --segment_id 20240619064521 --start_idx 30 --end_idx 40 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQVNJhUH1B3_",
        "outputId": "024c8ba5-24b3-4702-9a97-7bbe86fe0d21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/1 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240617235910_20to50_1718766007/20240617235910_20to50_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            "100% 1/1 [00:00<00:00,  1.04it/s]\n",
            "set dataset path\n",
            "  0% 0/1 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240617235910_20to50_1718766071/20240617235910_20to50_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            "100% 1/1 [00:00<00:00,  1.61it/s]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240617235910 --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240617235910 --start_idx 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA2fIBNN1B6Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-JlWNxR1B85"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eZisq_YwSXC"
      },
      "source": [
        "#959"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jObadyN5vpqN",
        "outputId": "807afce3-5920-4c03-f160-fec58f0f7041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_10to16_1718469583/20240102231959_10to16_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:20<01:06,  6.08s/it]Progress image saved at step 3 (21%): ./outputs/20240102231959_10to16_1718469583/20240102231959_10to16_normal_stride32_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:38<00:33,  4.77s/it]Progress image saved at step 7 (50%): ./outputs/20240102231959_10to16_1718469583/20240102231959_10to16_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:53<00:18,  4.68s/it]Progress image saved at step 10 (71%): ./outputs/20240102231959_10to16_1718469583/20240102231959_10to16_normal_stride32_size128_batchsize512_progress_71percent.png\n",
            "100% 14/14 [01:07<00:00,  4.83s/it]\n",
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_10to16_1718469774/20240102231959_10to16_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:21<01:10,  6.43s/it]Progress image saved at step 3 (21%): ./outputs/20240102231959_10to16_1718469774/20240102231959_10to16_reversed_stride32_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:40<00:34,  4.92s/it]Progress image saved at step 7 (50%): ./outputs/20240102231959_10to16_1718469774/20240102231959_10to16_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:55<00:19,  4.84s/it]Progress image saved at step 10 (71%): ./outputs/20240102231959_10to16_1718469774/20240102231959_10to16_reversed_stride32_size128_batchsize512_progress_71percent.png\n",
            "100% 14/14 [01:10<00:00,  5.02s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 10 --end_idx 16 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 10 --end_idx 16 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4vjoGa7wQeZ",
        "outputId": "5b9919ed-4fa4-4a56-baf3-98cf7fed07e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_20to26_1718469861/20240102231959_20to26_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:21<01:10,  6.38s/it]Progress image saved at step 3 (21%): ./outputs/20240102231959_20to26_1718469861/20240102231959_20to26_normal_stride32_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:40<00:34,  4.91s/it]Progress image saved at step 7 (50%): ./outputs/20240102231959_20to26_1718469861/20240102231959_20to26_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:54<00:19,  4.79s/it]Progress image saved at step 10 (71%): ./outputs/20240102231959_20to26_1718469861/20240102231959_20to26_normal_stride32_size128_batchsize512_progress_71percent.png\n",
            "100% 14/14 [01:09<00:00,  4.98s/it]\n",
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_20to26_1718469997/20240102231959_20to26_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:22<01:12,  6.62s/it]Progress image saved at step 3 (21%): ./outputs/20240102231959_20to26_1718469997/20240102231959_20to26_reversed_stride32_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:41<00:35,  5.03s/it]Progress image saved at step 7 (50%): ./outputs/20240102231959_20to26_1718469997/20240102231959_20to26_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:56<00:19,  4.93s/it]Progress image saved at step 10 (71%): ./outputs/20240102231959_20to26_1718469997/20240102231959_20to26_reversed_stride32_size128_batchsize512_progress_71percent.png\n",
            "100% 14/14 [01:12<00:00,  5.16s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 20 --end_idx 26 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 20 --end_idx 26 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htznIeZEwkZB",
        "outputId": "59eb5c63-0b22-4e8f-ec6d-0e1dc9e08fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_30to36_1718470085/20240102231959_30to36_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:22<01:11,  6.46s/it]Progress image saved at step 3 (21%): ./outputs/20240102231959_30to36_1718470085/20240102231959_30to36_normal_stride32_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:40<00:34,  4.94s/it]Progress image saved at step 7 (50%): ./outputs/20240102231959_30to36_1718470085/20240102231959_30to36_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:55<00:19,  4.84s/it]Progress image saved at step 10 (71%): ./outputs/20240102231959_30to36_1718470085/20240102231959_30to36_normal_stride32_size128_batchsize512_progress_71percent.png\n",
            "100% 14/14 [01:10<00:00,  5.05s/it]\n",
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_30to36_1718470223/20240102231959_30to36_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:20<01:09,  6.35s/it]Progress image saved at step 3 (21%): ./outputs/20240102231959_30to36_1718470223/20240102231959_30to36_reversed_stride32_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:40<00:35,  5.03s/it]Progress image saved at step 7 (50%): ./outputs/20240102231959_30to36_1718470223/20240102231959_30to36_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:55<00:19,  4.88s/it]Progress image saved at step 10 (71%): ./outputs/20240102231959_30to36_1718470223/20240102231959_30to36_reversed_stride32_size128_batchsize512_progress_71percent.png\n",
            "100% 14/14 [01:10<00:00,  5.02s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 30 --end_idx 36 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 30 --end_idx 36 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2NuJ8mOwuvC",
        "outputId": "ba72770d-4e92-4c89-a7cb-6fcc4fcc96a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/53 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_30to40_1718470574/20240102231959_30to40_normal_stride16_size128_batchsize512_progress_0percent.png\n",
            " 25% 13/53 [01:09<03:04,  4.61s/it]Progress image saved at step 13 (24%): ./outputs/20240102231959_30to40_1718470574/20240102231959_30to40_normal_stride16_size128_batchsize512_progress_24percent.png\n",
            " 49% 26/53 [02:12<02:10,  4.83s/it]Progress image saved at step 26 (49%): ./outputs/20240102231959_30to40_1718470574/20240102231959_30to40_normal_stride16_size128_batchsize512_progress_49percent.png\n",
            " 74% 39/53 [03:14<01:07,  4.79s/it]Progress image saved at step 39 (73%): ./outputs/20240102231959_30to40_1718470574/20240102231959_30to40_normal_stride16_size128_batchsize512_progress_73percent.png\n",
            "100% 53/53 [04:18<00:00,  4.88s/it]\n",
            "set dataset path\n",
            "  0% 0/53 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_30to40_1718470849/20240102231959_30to40_reversed_stride16_size128_batchsize512_progress_0percent.png\n",
            " 25% 13/53 [01:13<03:14,  4.87s/it]Progress image saved at step 13 (24%): ./outputs/20240102231959_30to40_1718470849/20240102231959_30to40_reversed_stride16_size128_batchsize512_progress_24percent.png\n",
            " 49% 26/53 [02:15<02:09,  4.79s/it]Progress image saved at step 26 (49%): ./outputs/20240102231959_30to40_1718470849/20240102231959_30to40_reversed_stride16_size128_batchsize512_progress_49percent.png\n",
            " 74% 39/53 [03:19<01:07,  4.80s/it]Progress image saved at step 39 (73%): ./outputs/20240102231959_30to40_1718470849/20240102231959_30to40_reversed_stride16_size128_batchsize512_progress_73percent.png\n",
            "100% 53/53 [04:22<00:00,  4.96s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 30 --end_idx 40 --stride 16 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 30 --end_idx 40 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL4VSudewkbc",
        "outputId": "af6082fc-503a-412b-c5f6-1c31dccaad2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_40to46_1718470309/20240102231959_40to46_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:21<01:10,  6.45s/it]Progress image saved at step 3 (21%): ./outputs/20240102231959_40to46_1718470309/20240102231959_40to46_normal_stride32_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:40<00:34,  4.97s/it]Progress image saved at step 7 (50%): ./outputs/20240102231959_40to46_1718470309/20240102231959_40to46_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:55<00:19,  4.85s/it]Progress image saved at step 10 (71%): ./outputs/20240102231959_40to46_1718470309/20240102231959_40to46_normal_stride32_size128_batchsize512_progress_71percent.png\n",
            "100% 14/14 [01:10<00:00,  5.03s/it]\n",
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_40to46_1718470434/20240102231959_40to46_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:20<01:10,  6.37s/it]Progress image saved at step 3 (21%): ./outputs/20240102231959_40to46_1718470434/20240102231959_40to46_reversed_stride32_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:40<00:35,  5.02s/it]Progress image saved at step 7 (50%): ./outputs/20240102231959_40to46_1718470434/20240102231959_40to46_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:54<00:19,  4.88s/it]Progress image saved at step 10 (71%): ./outputs/20240102231959_40to46_1718470434/20240102231959_40to46_reversed_stride32_size128_batchsize512_progress_71percent.png\n",
            "100% 14/14 [01:10<00:00,  5.00s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 40 --end_idx 46 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 40 --end_idx 46 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peB5IP6I788Y",
        "outputId": "7fd8c1a4-f072-4627-e66f-1e021a3a156f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/5 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240624014055_40to50_1719206574/20240624014055_40to50_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 1/5 [00:02<00:10,  2.70s/it]Progress image saved at step 1 (20%): ./outputs/20240624014055_40to50_1719206574/20240624014055_40to50_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 40% 2/5 [00:04<00:06,  2.12s/it]Progress image saved at step 2 (40%): ./outputs/20240624014055_40to50_1719206574/20240624014055_40to50_normal_stride32_size64_batchsize512_progress_40percent.png\n",
            " 60% 3/5 [00:06<00:03,  1.96s/it]Progress image saved at step 3 (60%): ./outputs/20240624014055_40to50_1719206574/20240624014055_40to50_normal_stride32_size64_batchsize512_progress_60percent.png\n",
            "100% 5/5 [00:08<00:00,  1.70s/it]\n",
            "set dataset path\n",
            "  0% 0/5 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240624014055_40to50_1719206605/20240624014055_40to50_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 1/5 [00:02<00:11,  2.97s/it]Progress image saved at step 1 (20%): ./outputs/20240624014055_40to50_1719206605/20240624014055_40to50_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 40% 2/5 [00:04<00:06,  2.23s/it]Progress image saved at step 2 (40%): ./outputs/20240624014055_40to50_1719206605/20240624014055_40to50_reversed_stride32_size64_batchsize512_progress_40percent.png\n",
            " 60% 3/5 [00:06<00:04,  2.03s/it]Progress image saved at step 3 (60%): ./outputs/20240624014055_40to50_1719206605/20240624014055_40to50_reversed_stride32_size64_batchsize512_progress_60percent.png\n",
            "100% 5/5 [00:08<00:00,  1.76s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240624014055 --start_idx 40 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240624014055 --start_idx 40 --end_idx 50 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PlOfxGXwkdy",
        "outputId": "8978dcb8-9694-411d-87df-3e1e50d65d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "[ WARN:0@38.967] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20240102231959/layers/65.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "set dataset path\n",
            "[ WARN:0@5.105] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20240102231959/layers/65.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 50 --end_idx 56 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 50 --end_idx 56 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxuVSDFW5OND"
      },
      "source": [
        "#OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "XDVinXGL5PZ7",
        "outputId": "aa822efe-9f51-4fde-dfb1-2c885d2505bf"
      },
      "outputs": [
        {
          "ename": "TesseractNotFoundError",
          "evalue": "tesseract is not installed or it's not in your PATH. See README file for more information.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msubprocess_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    972\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1862\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tesseract'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTesseractNotFoundError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-56707bc47b18>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Perform OCR on the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     return {\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     }[output_type]()\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    286\u001b[0m         }\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{kwargs['output_filename_base']}{extsep}{extension}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTesseractNotFoundError\u001b[0m: tesseract is not installed or it's not in your PATH. See README file for more information."
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "# Load the image from the provided path\n",
        "image_path = \"/content/philodemus_title (3).PNG\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Perform OCR on the image\n",
        "text = pytesseract.image_to_string(image, lang='grc')\n",
        "text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXgmMJxW5Pcj",
        "outputId": "4bdcecfd-5845-4791-cf3e-258c4db24156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ],
      "source": [
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "tFAEF8Rv5PfM",
        "outputId": "b94c7d1a-3556-4d2d-cca8-c7f266cfced4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pytesseract' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-c66065498513>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Perform OCR on the image using the default language (English) to see if any readable text is captured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pytesseract' is not defined"
          ]
        }
      ],
      "source": [
        "# Perform OCR on the image using the default language (English) to see if any readable text is captured\n",
        "text = pytesseract.image_to_string(image)\n",
        "text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJB8bCfsjf97"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggdb5sRmIuEC"
      },
      "source": [
        "#220"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSn4uoI46drG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RUIitRFIvwX"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 30 --end_idx 34--stride 8 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 30 --end_idx 34 --stride 8 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpR_X3K4Ix1F",
        "outputId": "0d6dae11-5c69-46f4-c1b2-73e0482a006c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: inference_v23_normal.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                               [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                               [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                               [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v23_normal.py: error: argument --end_idx: invalid int value: '64--stride'\n",
            "set dataset path\n",
            "  0% 0/94 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240101215220_40to64_1718231370/20240101215220_40to64_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 23/94 [00:37<01:44,  1.48s/it]Progress image saved at step 23 (24%): ./outputs/20240101215220_40to64_1718231370/20240101215220_40to64_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 47/94 [01:16<01:11,  1.52s/it]Progress image saved at step 47 (50%): ./outputs/20240101215220_40to64_1718231370/20240101215220_40to64_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 74% 70/94 [01:56<00:37,  1.57s/it]Progress image saved at step 70 (74%): ./outputs/20240101215220_40to64_1718231370/20240101215220_40to64_reversed_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 94/94 [02:38<00:00,  1.69s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 40 --end_idx 64--stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 40 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-SCnWRtnVuv"
      },
      "source": [
        "#reversed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9G60G-BnKcc",
        "outputId": "5d363214-1c7a-4ef3-ad24-f948a6a44dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: inference_v23_normal.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                               [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                               [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                               [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v23_normal.py: error: argument --end_idx: invalid int value: '01--stride'\n",
            "set dataset path\n",
            "[ WARN:0@3.961] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20240101215220_reversed/layers/00.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220_reversed --start_idx 00 --end_idx 01--stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220_reversed --start_idx 00 --end_idx 01 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HZDjHUznaIz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xBpDpbznaLV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUiIP7rlnad_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7XNsjk-kirF",
        "outputId": "92a2d98b-cce7-4214-ce0c-d05b814f150f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: inference_v23_normal.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                               [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                               [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                               [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v23_normal.py: error: argument --end_idx: invalid int value: '64--stride'\n",
            "set dataset path\n",
            "[ WARN:0@6.814] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20240101215220/layers/65.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 60 --end_idx 64--stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 60 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PpGlUOEkitc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7kbPNWGkiwM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8PHohzbkd_M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcxUodDikeIZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uT7yItuIx3_",
        "outputId": "1173b55b-530e-4760-ad9b-58706bad1390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: inference_v23_normal.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                               [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                               [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                               [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v23_normal.py: error: argument --end_idx: invalid int value: '50--stride'\n",
            "set dataset path\n",
            "  0% 0/94 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240101215220_30to50_1718227277/20240101215220_30to50_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 23/94 [00:39<01:48,  1.53s/it]Progress image saved at step 23 (24%): ./outputs/20240101215220_30to50_1718227277/20240101215220_30to50_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 47/94 [01:19<01:13,  1.57s/it]Progress image saved at step 47 (50%): ./outputs/20240101215220_30to50_1718227277/20240101215220_30to50_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 74% 70/94 [01:59<00:36,  1.54s/it]Progress image saved at step 70 (74%): ./outputs/20240101215220_30to50_1718227277/20240101215220_30to50_reversed_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 94/94 [02:40<00:00,  1.71s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 30 --end_idx 50--stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 30 --end_idx 50 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF3lnS7IIx6U",
        "outputId": "19837c7d-a156-4329-9f09-ca505f49e7a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: inference_v23_normal.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                               [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                               [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                               [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v23_normal.py: error: argument --end_idx: invalid int value: '40--stride'\n",
            "set dataset path\n",
            "  0% 0/362 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "  1% 3/362 [00:23<41:08,  6.88s/it]Progress image saved at step 3 (0%): ./outputs/20240101215220_30to40_1718225382/20240101215220_30to40_reversed_stride16_size128_batchsize512_progress_0percent.png\n",
            " 25% 90/362 [07:25<20:53,  4.61s/it]Progress image saved at step 90 (24%): ./outputs/20240101215220_30to40_1718225382/20240101215220_30to40_reversed_stride16_size128_batchsize512_progress_24percent.png\n",
            " 50% 181/362 [14:40<13:54,  4.61s/it]Progress image saved at step 181 (50%): ./outputs/20240101215220_30to40_1718225382/20240101215220_30to40_reversed_stride16_size128_batchsize512_progress_50percent.png\n",
            " 75% 271/362 [21:45<06:59,  4.60s/it]Progress image saved at step 271 (74%): ./outputs/20240101215220_30to40_1718225382/20240101215220_30to40_reversed_stride16_size128_batchsize512_progress_74percent.png\n",
            "100% 361/362 [28:45<00:04,  4.61s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.70 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.32 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "100% 362/362 [28:50<00:00,  4.78s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 30 --end_idx 40--stride 16 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 30 --end_idx 40 --stride 16 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ULxz0KfLlHo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWvMkUswLlKN",
        "outputId": "aaf31fcc-a72d-4636-8fba-b5dabe82cb10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: inference_v23_normal.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                               [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                               [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                               [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v23_normal.py: error: argument --end_idx: invalid int value: '54--stride'\n",
            "usage: inference_v23_reversed.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                                 [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                                 [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                                 [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v23_reversed.py: error: argument --end_idx: invalid int value: '54--stride'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 40 --end_idx 54--stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 40 --end_idx 54--stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWi6avj-LlNG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrhgwsXpCeZp"
      },
      "source": [
        "#end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV0cNmF0CjEC",
        "outputId": "e253ead7-3fc5-4701-9ec0-40e5143ba774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/A_Scroll/inkception-3d\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX-T53N016L5"
      },
      "outputs": [],
      "source": [
        "20240101215220"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbmEvwSK18lw",
        "outputId": "63983eb5-5743-42dc-8995-9b8fac34f3ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/55 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240101215220_0to64_1718220254/20240101215220_0to64_normal_stride42_size64_batchsize512_progress_0percent.png\n",
            " 24% 13/55 [00:22<01:02,  1.48s/it]Progress image saved at step 13 (23%): ./outputs/20240101215220_0to64_1718220254/20240101215220_0to64_normal_stride42_size64_batchsize512_progress_23percent.png\n",
            " 49% 27/55 [00:46<00:41,  1.48s/it]Progress image saved at step 27 (49%): ./outputs/20240101215220_0to64_1718220254/20240101215220_0to64_normal_stride42_size64_batchsize512_progress_49percent.png\n",
            " 75% 41/55 [01:11<00:20,  1.49s/it]Progress image saved at step 41 (74%): ./outputs/20240101215220_0to64_1718220254/20240101215220_0to64_normal_stride42_size64_batchsize512_progress_74percent.png\n",
            "100% 55/55 [01:36<00:00,  1.76s/it]\n",
            "set dataset path\n",
            "  0% 0/55 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240101215220_0to64_1718220467/20240101215220_0to64_reversed_stride42_size64_batchsize512_progress_0percent.png\n",
            " 24% 13/55 [00:23<01:02,  1.50s/it]Progress image saved at step 13 (23%): ./outputs/20240101215220_0to64_1718220467/20240101215220_0to64_reversed_stride42_size64_batchsize512_progress_23percent.png\n",
            " 49% 27/55 [00:47<00:41,  1.50s/it]Progress image saved at step 27 (49%): ./outputs/20240101215220_0to64_1718220467/20240101215220_0to64_reversed_stride42_size64_batchsize512_progress_49percent.png\n",
            " 75% 41/55 [01:12<00:21,  1.51s/it]Progress image saved at step 41 (74%): ./outputs/20240101215220_0to64_1718220467/20240101215220_0to64_reversed_stride42_size64_batchsize512_progress_74percent.png\n",
            "100% 55/55 [01:37<00:00,  1.78s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 0 --end_idx 64 --stride 42 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 0 --end_idx 64 --stride 42 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iOzJ2f718od",
        "outputId": "949042b1-342f-48b2-9483-fe1d15d2b14e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/55 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240101215220_0to20_1718220600/20240101215220_0to20_normal_stride42_size64_batchsize512_progress_0percent.png\n",
            " 24% 13/55 [00:23<01:03,  1.51s/it]Progress image saved at step 13 (23%): ./outputs/20240101215220_0to20_1718220600/20240101215220_0to20_normal_stride42_size64_batchsize512_progress_23percent.png\n",
            " 49% 27/55 [00:47<00:42,  1.51s/it]Progress image saved at step 27 (49%): ./outputs/20240101215220_0to20_1718220600/20240101215220_0to20_normal_stride42_size64_batchsize512_progress_49percent.png\n",
            " 75% 41/55 [01:12<00:21,  1.52s/it]Progress image saved at step 41 (74%): ./outputs/20240101215220_0to20_1718220600/20240101215220_0to20_normal_stride42_size64_batchsize512_progress_74percent.png\n",
            "100% 55/55 [01:37<00:00,  1.78s/it]\n",
            "set dataset path\n",
            "  0% 0/55 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240101215220_0to20_1718220737/20240101215220_0to20_reversed_stride42_size64_batchsize512_progress_0percent.png\n",
            " 24% 13/55 [00:23<01:03,  1.51s/it]Progress image saved at step 13 (23%): ./outputs/20240101215220_0to20_1718220737/20240101215220_0to20_reversed_stride42_size64_batchsize512_progress_23percent.png\n",
            " 49% 27/55 [00:47<00:42,  1.51s/it]Progress image saved at step 27 (49%): ./outputs/20240101215220_0to20_1718220737/20240101215220_0to20_reversed_stride42_size64_batchsize512_progress_49percent.png\n",
            " 75% 41/55 [01:12<00:21,  1.51s/it]Progress image saved at step 41 (74%): ./outputs/20240101215220_0to20_1718220737/20240101215220_0to20_reversed_stride42_size64_batchsize512_progress_74percent.png\n",
            "100% 55/55 [01:38<00:00,  1.78s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 0 --end_idx 20 --stride 42 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 0 --end_idx 20 --stride 42 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAuSPvp42OCa",
        "outputId": "5e671a9a-a6e9-4968-9d58-a13884163b47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 9/955 [00:15<23:41,  1.50s/it]Progress image saved at step 9 (0%): ./outputs/20240101215220_0to0_1718221085/20240101215220_0to0_normal_stride10_size64_batchsize512_progress_0percent.png\n",
            " 25% 238/955 [06:03<18:07,  1.52s/it]Progress image saved at step 238 (24%): ./outputs/20240101215220_0to0_1718221085/20240101215220_0to0_normal_stride10_size64_batchsize512_progress_24percent.png\n",
            " 50% 477/955 [12:15<12:13,  1.53s/it]Progress image saved at step 477 (49%): ./outputs/20240101215220_0to0_1718221085/20240101215220_0to0_normal_stride10_size64_batchsize512_progress_49percent.png\n",
            " 75% 716/955 [18:26<06:07,  1.54s/it]Progress image saved at step 716 (74%): ./outputs/20240101215220_0to0_1718221085/20240101215220_0to0_normal_stride10_size64_batchsize512_progress_74percent.png\n",
            "100% 955/955 [24:36<00:00,  1.55s/it]\n",
            "set dataset path\n",
            "  1% 9/955 [00:15<24:39,  1.56s/it]Progress image saved at step 9 (0%): ./outputs/20240101215220_0to0_1718222610/20240101215220_0to0_reversed_stride10_size64_batchsize512_progress_0percent.png\n",
            " 25% 238/955 [06:09<18:23,  1.54s/it]Progress image saved at step 238 (24%): ./outputs/20240101215220_0to0_1718222610/20240101215220_0to0_reversed_stride10_size64_batchsize512_progress_24percent.png\n",
            " 50% 477/955 [12:19<12:14,  1.54s/it]Progress image saved at step 477 (49%): ./outputs/20240101215220_0to0_1718222610/20240101215220_0to0_reversed_stride10_size64_batchsize512_progress_49percent.png\n",
            " 75% 716/955 [18:30<06:08,  1.54s/it]Progress image saved at step 716 (74%): ./outputs/20240101215220_0to0_1718222610/20240101215220_0to0_reversed_stride10_size64_batchsize512_progress_74percent.png\n",
            "100% 955/955 [24:44<00:00,  1.55s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo9vfe2i2GtN",
        "outputId": "8d056ccc-37e8-4689-827b-7d3cfcf0d4f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/39 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240101215220_0to20_1718220874/20240101215220_0to20_normal_stride50_size64_batchsize512_progress_0percent.png\n",
            " 23% 9/39 [00:17<00:47,  1.57s/it]Progress image saved at step 9 (23%): ./outputs/20240101215220_0to20_1718220874/20240101215220_0to20_normal_stride50_size64_batchsize512_progress_23percent.png\n",
            " 49% 19/39 [00:35<00:30,  1.54s/it]Progress image saved at step 19 (48%): ./outputs/20240101215220_0to20_1718220874/20240101215220_0to20_normal_stride50_size64_batchsize512_progress_48percent.png\n",
            " 74% 29/39 [00:55<00:15,  1.56s/it]Progress image saved at step 29 (74%): ./outputs/20240101215220_0to20_1718220874/20240101215220_0to20_normal_stride50_size64_batchsize512_progress_74percent.png\n",
            "100% 39/39 [01:14<00:00,  1.92s/it]\n",
            "set dataset path\n",
            "  0% 0/39 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240101215220_0to20_1718220979/20240101215220_0to20_reversed_stride50_size64_batchsize512_progress_0percent.png\n",
            " 23% 9/39 [00:17<00:47,  1.57s/it]Progress image saved at step 9 (23%): ./outputs/20240101215220_0to20_1718220979/20240101215220_0to20_reversed_stride50_size64_batchsize512_progress_23percent.png\n",
            " 49% 19/39 [00:35<00:30,  1.54s/it]Progress image saved at step 19 (48%): ./outputs/20240101215220_0to20_1718220979/20240101215220_0to20_reversed_stride50_size64_batchsize512_progress_48percent.png\n",
            " 74% 29/39 [00:55<00:15,  1.57s/it]Progress image saved at step 29 (74%): ./outputs/20240101215220_0to20_1718220979/20240101215220_0to20_reversed_stride50_size64_batchsize512_progress_74percent.png\n",
            "100% 39/39 [01:14<00:00,  1.92s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 0 --end_idx 20 --stride 50 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 0 --end_idx 20 --stride 50 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99QuMkR92G1P",
        "outputId": "edd0aa71-649e-4cd9-c8f5-f3a92489ce28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240101215220_28to40_1718224133/20240101215220_28to40_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 24% 22/91 [01:54<05:17,  4.60s/it]Progress image saved at step 22 (24%): ./outputs/20240101215220_28to40_1718224133/20240101215220_28to40_normal_stride32_size128_batchsize512_progress_24percent.png\n",
            " 49% 45/91 [03:47<03:31,  4.60s/it]Progress image saved at step 45 (49%): ./outputs/20240101215220_28to40_1718224133/20240101215220_28to40_normal_stride32_size128_batchsize512_progress_49percent.png\n",
            " 75% 68/91 [05:40<01:46,  4.62s/it]Progress image saved at step 68 (74%): ./outputs/20240101215220_28to40_1718224133/20240101215220_28to40_normal_stride32_size128_batchsize512_progress_74percent.png\n",
            "100% 91/91 [07:30<00:00,  4.95s/it]\n",
            "set dataset path\n",
            "  0% 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240101215220_28to40_1718224699/20240101215220_28to40_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 24% 22/91 [01:55<05:21,  4.65s/it]Progress image saved at step 22 (24%): ./outputs/20240101215220_28to40_1718224699/20240101215220_28to40_reversed_stride32_size128_batchsize512_progress_24percent.png\n",
            " 49% 45/91 [03:48<03:33,  4.63s/it]Progress image saved at step 45 (49%): ./outputs/20240101215220_28to40_1718224699/20240101215220_28to40_reversed_stride32_size128_batchsize512_progress_49percent.png\n",
            " 75% 68/91 [05:40<01:46,  4.62s/it]Progress image saved at step 68 (74%): ./outputs/20240101215220_28to40_1718224699/20240101215220_28to40_reversed_stride32_size128_batchsize512_progress_74percent.png\n",
            "100% 91/91 [07:29<00:00,  4.94s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 28 --end_idx 40 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 28 --end_idx 40 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIu3-Qq72G9p"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 28 --end_idx 40 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 28 --end_idx 40 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUmAYkUFsyjd"
      },
      "source": [
        "#630"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-80rQsQyCeuK",
        "outputId": "31476454-34ad-424a-c713-dda64f2ad49e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_0to10_1718576318/20240107134630_0to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:18,  2.36s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_0to10_1718576318/20240107134630_0to10_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.71s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_0to10_1718576318/20240107134630_0to10_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.69s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_0to10_1718576318/20240107134630_0to10_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.77s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_0to10_1718576441/20240107134630_0to10_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:18,  2.37s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_0to10_1718576441/20240107134630_0to10_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.72s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_0to10_1718576441/20240107134630_0to10_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.70s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_0to10_1718576441/20240107134630_0to10_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.78s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240107134630 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240107134630 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Z8Qy-qHcp4",
        "outputId": "4f7460eb-ddb6-4bdf-862f-4eed95bd656d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240107134630_0to10_1718576471/20240107134630_0to10_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:15<00:50,  7.23s/it]Progress image saved at step 2 (22%): ./outputs/20240107134630_0to10_1718576471/20240107134630_0to10_normal_stride32_size128_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:25<00:27,  5.55s/it]Progress image saved at step 4 (44%): ./outputs/20240107134630_0to10_1718576471/20240107134630_0to10_normal_stride32_size128_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:34<00:15,  5.11s/it]Progress image saved at step 6 (66%): ./outputs/20240107134630_0to10_1718576471/20240107134630_0to10_normal_stride32_size128_batchsize512_progress_66percent.png\n",
            " 89% 8/9 [00:44<00:05,  5.00s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 5.68 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "100% 9/9 [00:48<00:00,  5.40s/it]\n",
            "set dataset path\n",
            "  0% 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240107134630_0to10_1718576533/20240107134630_0to10_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:16<00:52,  7.48s/it]Progress image saved at step 2 (22%): ./outputs/20240107134630_0to10_1718576533/20240107134630_0to10_reversed_stride32_size128_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:26<00:29,  5.81s/it]Progress image saved at step 4 (44%): ./outputs/20240107134630_0to10_1718576533/20240107134630_0to10_reversed_stride32_size128_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:36<00:16,  5.39s/it]Progress image saved at step 6 (66%): ./outputs/20240107134630_0to10_1718576533/20240107134630_0to10_reversed_stride32_size128_batchsize512_progress_66percent.png\n",
            " 89% 8/9 [00:46<00:05,  5.26s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 5.68 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "100% 9/9 [00:50<00:00,  5.65s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240107134630 --start_idx 0 --end_idx 10 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240107134630 --start_idx 0 --end_idx 10 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQRSa7sHHcsM"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240107134630 --start_idx 10 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240107134630 --start_idx 10 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XZwoOgWHcvJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys_fpqudNytq",
        "outputId": "7eb24c89-29e0-496b-a3ce-4d51df55e1f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_40to64_1718519160/20240107134630_40to64_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:04<00:18,  2.27s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_40to64_1718519160/20240107134630_40to64_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.70s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_40to64_1718519160/20240107134630_40to64_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.69s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_40to64_1718519160/20240107134630_40to64_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.75s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_40to64_1718519230/20240107134630_40to64_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:04<00:18,  2.31s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_40to64_1718519230/20240107134630_40to64_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.72s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_40to64_1718519230/20240107134630_40to64_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.70s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_40to64_1718519230/20240107134630_40to64_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.77s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240107134630 --start_idx 20 --end_idx 34 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240107134630 --start_idx 20 --end_idx 34 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W36hy3X61qFH",
        "outputId": "01605d1c-12aa-448d-c889-28716a1f9977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "[ WARN:0@36.007] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20240107134630/layers/65.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "set dataset path\n",
            "[ WARN:0@3.908] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20240107134630/layers/65.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240107134630 --start_idx 50 --end_idx 58 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240107134630 --start_idx 50 --end_idx 58 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JYoWKZkt3AS",
        "outputId": "69907b08-54c2-4860-bb86-64e6c1a6c569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_0to20_1718519310/20240107134630_0to20_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:19,  2.39s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_0to20_1718519310/20240107134630_0to20_normal_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.72s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_0to20_1718519310/20240107134630_0to20_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.70s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_0to20_1718519310/20240107134630_0to20_normal_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.78s/it]\n",
            "set dataset path\n",
            "  0% 0/10 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240107134630_0to20_1718519401/20240107134630_0to20_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 20% 2/10 [00:05<00:19,  2.39s/it]Progress image saved at step 2 (20%): ./outputs/20240107134630_0to20_1718519401/20240107134630_0to20_reversed_stride32_size64_batchsize512_progress_20percent.png\n",
            " 50% 5/10 [00:09<00:08,  1.73s/it]Progress image saved at step 5 (50%): ./outputs/20240107134630_0to20_1718519401/20240107134630_0to20_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 70% 7/10 [00:13<00:05,  1.71s/it]Progress image saved at step 7 (70%): ./outputs/20240107134630_0to20_1718519401/20240107134630_0to20_reversed_stride32_size64_batchsize512_progress_70percent.png\n",
            "100% 10/10 [00:17<00:00,  1.79s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240107134630 --start_idx 0 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240107134630 --start_idx 0 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3OVF3Qit3DB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikT5_yKGt3F8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6hUTjW-H0Iu"
      },
      "source": [
        "#gp model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-ZQr5SOH1QS",
        "outputId": "3335757a-efd0-43a7-c7eb-84576288cd6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py:191: Found keys that are in the model state dict but not in the checkpoint: ['backbone.logits.conv3d.weight', 'backbone.logits.conv3d.bias', 'backbone.Conv3d_1a_7x7.conv3d.weight', 'backbone.Conv3d_1a_7x7.bn.weight', 'backbone.Conv3d_1a_7x7.bn.bias', 'backbone.Conv3d_1a_7x7.bn.running_mean', 'backbone.Conv3d_1a_7x7.bn.running_var', 'backbone.Conv3d_2b_1x1.conv3d.weight', 'backbone.Conv3d_2b_1x1.bn.weight', 'backbone.Conv3d_2b_1x1.bn.bias', 'backbone.Conv3d_2b_1x1.bn.running_mean', 'backbone.Conv3d_2b_1x1.bn.running_var', 'backbone.Conv3d_2c_3x3.conv3d.weight', 'backbone.Conv3d_2c_3x3.bn.weight', 'backbone.Conv3d_2c_3x3.bn.bias', 'backbone.Conv3d_2c_3x3.bn.running_mean', 'backbone.Conv3d_2c_3x3.bn.running_var', 'backbone.Mixed_3b.b0.conv3d.weight', 'backbone.Mixed_3b.b0.bn.weight', 'backbone.Mixed_3b.b0.bn.bias', 'backbone.Mixed_3b.b0.bn.running_mean', 'backbone.Mixed_3b.b0.bn.running_var', 'backbone.Mixed_3b.b1a.conv3d.weight', 'backbone.Mixed_3b.b1a.bn.weight', 'backbone.Mixed_3b.b1a.bn.bias', 'backbone.Mixed_3b.b1a.bn.running_mean', 'backbone.Mixed_3b.b1a.bn.running_var', 'backbone.Mixed_3b.b1b.conv3d.weight', 'backbone.Mixed_3b.b1b.bn.weight', 'backbone.Mixed_3b.b1b.bn.bias', 'backbone.Mixed_3b.b1b.bn.running_mean', 'backbone.Mixed_3b.b1b.bn.running_var', 'backbone.Mixed_3b.b2a.conv3d.weight', 'backbone.Mixed_3b.b2a.bn.weight', 'backbone.Mixed_3b.b2a.bn.bias', 'backbone.Mixed_3b.b2a.bn.running_mean', 'backbone.Mixed_3b.b2a.bn.running_var', 'backbone.Mixed_3b.b2b.conv3d.weight', 'backbone.Mixed_3b.b2b.bn.weight', 'backbone.Mixed_3b.b2b.bn.bias', 'backbone.Mixed_3b.b2b.bn.running_mean', 'backbone.Mixed_3b.b2b.bn.running_var', 'backbone.Mixed_3b.b3b.conv3d.weight', 'backbone.Mixed_3b.b3b.bn.weight', 'backbone.Mixed_3b.b3b.bn.bias', 'backbone.Mixed_3b.b3b.bn.running_mean', 'backbone.Mixed_3b.b3b.bn.running_var', 'backbone.Mixed_3c.b0.conv3d.weight', 'backbone.Mixed_3c.b0.bn.weight', 'backbone.Mixed_3c.b0.bn.bias', 'backbone.Mixed_3c.b0.bn.running_mean', 'backbone.Mixed_3c.b0.bn.running_var', 'backbone.Mixed_3c.b1a.conv3d.weight', 'backbone.Mixed_3c.b1a.bn.weight', 'backbone.Mixed_3c.b1a.bn.bias', 'backbone.Mixed_3c.b1a.bn.running_mean', 'backbone.Mixed_3c.b1a.bn.running_var', 'backbone.Mixed_3c.b1b.conv3d.weight', 'backbone.Mixed_3c.b1b.bn.weight', 'backbone.Mixed_3c.b1b.bn.bias', 'backbone.Mixed_3c.b1b.bn.running_mean', 'backbone.Mixed_3c.b1b.bn.running_var', 'backbone.Mixed_3c.b2a.conv3d.weight', 'backbone.Mixed_3c.b2a.bn.weight', 'backbone.Mixed_3c.b2a.bn.bias', 'backbone.Mixed_3c.b2a.bn.running_mean', 'backbone.Mixed_3c.b2a.bn.running_var', 'backbone.Mixed_3c.b2b.conv3d.weight', 'backbone.Mixed_3c.b2b.bn.weight', 'backbone.Mixed_3c.b2b.bn.bias', 'backbone.Mixed_3c.b2b.bn.running_mean', 'backbone.Mixed_3c.b2b.bn.running_var', 'backbone.Mixed_3c.b3b.conv3d.weight', 'backbone.Mixed_3c.b3b.bn.weight', 'backbone.Mixed_3c.b3b.bn.bias', 'backbone.Mixed_3c.b3b.bn.running_mean', 'backbone.Mixed_3c.b3b.bn.running_var', 'backbone.Mixed_4b.b0.conv3d.weight', 'backbone.Mixed_4b.b0.bn.weight', 'backbone.Mixed_4b.b0.bn.bias', 'backbone.Mixed_4b.b0.bn.running_mean', 'backbone.Mixed_4b.b0.bn.running_var', 'backbone.Mixed_4b.b1a.conv3d.weight', 'backbone.Mixed_4b.b1a.bn.weight', 'backbone.Mixed_4b.b1a.bn.bias', 'backbone.Mixed_4b.b1a.bn.running_mean', 'backbone.Mixed_4b.b1a.bn.running_var', 'backbone.Mixed_4b.b1b.conv3d.weight', 'backbone.Mixed_4b.b1b.bn.weight', 'backbone.Mixed_4b.b1b.bn.bias', 'backbone.Mixed_4b.b1b.bn.running_mean', 'backbone.Mixed_4b.b1b.bn.running_var', 'backbone.Mixed_4b.b2a.conv3d.weight', 'backbone.Mixed_4b.b2a.bn.weight', 'backbone.Mixed_4b.b2a.bn.bias', 'backbone.Mixed_4b.b2a.bn.running_mean', 'backbone.Mixed_4b.b2a.bn.running_var', 'backbone.Mixed_4b.b2b.conv3d.weight', 'backbone.Mixed_4b.b2b.bn.weight', 'backbone.Mixed_4b.b2b.bn.bias', 'backbone.Mixed_4b.b2b.bn.running_mean', 'backbone.Mixed_4b.b2b.bn.running_var', 'backbone.Mixed_4b.b3b.conv3d.weight', 'backbone.Mixed_4b.b3b.bn.weight', 'backbone.Mixed_4b.b3b.bn.bias', 'backbone.Mixed_4b.b3b.bn.running_mean', 'backbone.Mixed_4b.b3b.bn.running_var', 'backbone.Mixed_4c.b0.conv3d.weight', 'backbone.Mixed_4c.b0.bn.weight', 'backbone.Mixed_4c.b0.bn.bias', 'backbone.Mixed_4c.b0.bn.running_mean', 'backbone.Mixed_4c.b0.bn.running_var', 'backbone.Mixed_4c.b1a.conv3d.weight', 'backbone.Mixed_4c.b1a.bn.weight', 'backbone.Mixed_4c.b1a.bn.bias', 'backbone.Mixed_4c.b1a.bn.running_mean', 'backbone.Mixed_4c.b1a.bn.running_var', 'backbone.Mixed_4c.b1b.conv3d.weight', 'backbone.Mixed_4c.b1b.bn.weight', 'backbone.Mixed_4c.b1b.bn.bias', 'backbone.Mixed_4c.b1b.bn.running_mean', 'backbone.Mixed_4c.b1b.bn.running_var', 'backbone.Mixed_4c.b2a.conv3d.weight', 'backbone.Mixed_4c.b2a.bn.weight', 'backbone.Mixed_4c.b2a.bn.bias', 'backbone.Mixed_4c.b2a.bn.running_mean', 'backbone.Mixed_4c.b2a.bn.running_var', 'backbone.Mixed_4c.b2b.conv3d.weight', 'backbone.Mixed_4c.b2b.bn.weight', 'backbone.Mixed_4c.b2b.bn.bias', 'backbone.Mixed_4c.b2b.bn.running_mean', 'backbone.Mixed_4c.b2b.bn.running_var', 'backbone.Mixed_4c.b3b.conv3d.weight', 'backbone.Mixed_4c.b3b.bn.weight', 'backbone.Mixed_4c.b3b.bn.bias', 'backbone.Mixed_4c.b3b.bn.running_mean', 'backbone.Mixed_4c.b3b.bn.running_var', 'backbone.Mixed_4d.b0.conv3d.weight', 'backbone.Mixed_4d.b0.bn.weight', 'backbone.Mixed_4d.b0.bn.bias', 'backbone.Mixed_4d.b0.bn.running_mean', 'backbone.Mixed_4d.b0.bn.running_var', 'backbone.Mixed_4d.b1a.conv3d.weight', 'backbone.Mixed_4d.b1a.bn.weight', 'backbone.Mixed_4d.b1a.bn.bias', 'backbone.Mixed_4d.b1a.bn.running_mean', 'backbone.Mixed_4d.b1a.bn.running_var', 'backbone.Mixed_4d.b1b.conv3d.weight', 'backbone.Mixed_4d.b1b.bn.weight', 'backbone.Mixed_4d.b1b.bn.bias', 'backbone.Mixed_4d.b1b.bn.running_mean', 'backbone.Mixed_4d.b1b.bn.running_var', 'backbone.Mixed_4d.b2a.conv3d.weight', 'backbone.Mixed_4d.b2a.bn.weight', 'backbone.Mixed_4d.b2a.bn.bias', 'backbone.Mixed_4d.b2a.bn.running_mean', 'backbone.Mixed_4d.b2a.bn.running_var', 'backbone.Mixed_4d.b2b.conv3d.weight', 'backbone.Mixed_4d.b2b.bn.weight', 'backbone.Mixed_4d.b2b.bn.bias', 'backbone.Mixed_4d.b2b.bn.running_mean', 'backbone.Mixed_4d.b2b.bn.running_var', 'backbone.Mixed_4d.b3b.conv3d.weight', 'backbone.Mixed_4d.b3b.bn.weight', 'backbone.Mixed_4d.b3b.bn.bias', 'backbone.Mixed_4d.b3b.bn.running_mean', 'backbone.Mixed_4d.b3b.bn.running_var', 'backbone.Mixed_4e.b0.conv3d.weight', 'backbone.Mixed_4e.b0.bn.weight', 'backbone.Mixed_4e.b0.bn.bias', 'backbone.Mixed_4e.b0.bn.running_mean', 'backbone.Mixed_4e.b0.bn.running_var', 'backbone.Mixed_4e.b1a.conv3d.weight', 'backbone.Mixed_4e.b1a.bn.weight', 'backbone.Mixed_4e.b1a.bn.bias', 'backbone.Mixed_4e.b1a.bn.running_mean', 'backbone.Mixed_4e.b1a.bn.running_var', 'backbone.Mixed_4e.b1b.conv3d.weight', 'backbone.Mixed_4e.b1b.bn.weight', 'backbone.Mixed_4e.b1b.bn.bias', 'backbone.Mixed_4e.b1b.bn.running_mean', 'backbone.Mixed_4e.b1b.bn.running_var', 'backbone.Mixed_4e.b2a.conv3d.weight', 'backbone.Mixed_4e.b2a.bn.weight', 'backbone.Mixed_4e.b2a.bn.bias', 'backbone.Mixed_4e.b2a.bn.running_mean', 'backbone.Mixed_4e.b2a.bn.running_var', 'backbone.Mixed_4e.b2b.conv3d.weight', 'backbone.Mixed_4e.b2b.bn.weight', 'backbone.Mixed_4e.b2b.bn.bias', 'backbone.Mixed_4e.b2b.bn.running_mean', 'backbone.Mixed_4e.b2b.bn.running_var', 'backbone.Mixed_4e.b3b.conv3d.weight', 'backbone.Mixed_4e.b3b.bn.weight', 'backbone.Mixed_4e.b3b.bn.bias', 'backbone.Mixed_4e.b3b.bn.running_mean', 'backbone.Mixed_4e.b3b.bn.running_var', 'backbone.Mixed_4f.b0.conv3d.weight', 'backbone.Mixed_4f.b0.bn.weight', 'backbone.Mixed_4f.b0.bn.bias', 'backbone.Mixed_4f.b0.bn.running_mean', 'backbone.Mixed_4f.b0.bn.running_var', 'backbone.Mixed_4f.b1a.conv3d.weight', 'backbone.Mixed_4f.b1a.bn.weight', 'backbone.Mixed_4f.b1a.bn.bias', 'backbone.Mixed_4f.b1a.bn.running_mean', 'backbone.Mixed_4f.b1a.bn.running_var', 'backbone.Mixed_4f.b1b.conv3d.weight', 'backbone.Mixed_4f.b1b.bn.weight', 'backbone.Mixed_4f.b1b.bn.bias', 'backbone.Mixed_4f.b1b.bn.running_mean', 'backbone.Mixed_4f.b1b.bn.running_var', 'backbone.Mixed_4f.b2a.conv3d.weight', 'backbone.Mixed_4f.b2a.bn.weight', 'backbone.Mixed_4f.b2a.bn.bias', 'backbone.Mixed_4f.b2a.bn.running_mean', 'backbone.Mixed_4f.b2a.bn.running_var', 'backbone.Mixed_4f.b2b.conv3d.weight', 'backbone.Mixed_4f.b2b.bn.weight', 'backbone.Mixed_4f.b2b.bn.bias', 'backbone.Mixed_4f.b2b.bn.running_mean', 'backbone.Mixed_4f.b2b.bn.running_var', 'backbone.Mixed_4f.b3b.conv3d.weight', 'backbone.Mixed_4f.b3b.bn.weight', 'backbone.Mixed_4f.b3b.bn.bias', 'backbone.Mixed_4f.b3b.bn.running_mean', 'backbone.Mixed_4f.b3b.bn.running_var', 'backbone.Mixed_5b.b0.conv3d.weight', 'backbone.Mixed_5b.b0.bn.weight', 'backbone.Mixed_5b.b0.bn.bias', 'backbone.Mixed_5b.b0.bn.running_mean', 'backbone.Mixed_5b.b0.bn.running_var', 'backbone.Mixed_5b.b1a.conv3d.weight', 'backbone.Mixed_5b.b1a.bn.weight', 'backbone.Mixed_5b.b1a.bn.bias', 'backbone.Mixed_5b.b1a.bn.running_mean', 'backbone.Mixed_5b.b1a.bn.running_var', 'backbone.Mixed_5b.b1b.conv3d.weight', 'backbone.Mixed_5b.b1b.bn.weight', 'backbone.Mixed_5b.b1b.bn.bias', 'backbone.Mixed_5b.b1b.bn.running_mean', 'backbone.Mixed_5b.b1b.bn.running_var', 'backbone.Mixed_5b.b2a.conv3d.weight', 'backbone.Mixed_5b.b2a.bn.weight', 'backbone.Mixed_5b.b2a.bn.bias', 'backbone.Mixed_5b.b2a.bn.running_mean', 'backbone.Mixed_5b.b2a.bn.running_var', 'backbone.Mixed_5b.b2b.conv3d.weight', 'backbone.Mixed_5b.b2b.bn.weight', 'backbone.Mixed_5b.b2b.bn.bias', 'backbone.Mixed_5b.b2b.bn.running_mean', 'backbone.Mixed_5b.b2b.bn.running_var', 'backbone.Mixed_5b.b3b.conv3d.weight', 'backbone.Mixed_5b.b3b.bn.weight', 'backbone.Mixed_5b.b3b.bn.bias', 'backbone.Mixed_5b.b3b.bn.running_mean', 'backbone.Mixed_5b.b3b.bn.running_var', 'backbone.Mixed_5c.b0.conv3d.weight', 'backbone.Mixed_5c.b0.bn.weight', 'backbone.Mixed_5c.b0.bn.bias', 'backbone.Mixed_5c.b0.bn.running_mean', 'backbone.Mixed_5c.b0.bn.running_var', 'backbone.Mixed_5c.b1a.conv3d.weight', 'backbone.Mixed_5c.b1a.bn.weight', 'backbone.Mixed_5c.b1a.bn.bias', 'backbone.Mixed_5c.b1a.bn.running_mean', 'backbone.Mixed_5c.b1a.bn.running_var', 'backbone.Mixed_5c.b1b.conv3d.weight', 'backbone.Mixed_5c.b1b.bn.weight', 'backbone.Mixed_5c.b1b.bn.bias', 'backbone.Mixed_5c.b1b.bn.running_mean', 'backbone.Mixed_5c.b1b.bn.running_var', 'backbone.Mixed_5c.b2a.conv3d.weight', 'backbone.Mixed_5c.b2a.bn.weight', 'backbone.Mixed_5c.b2a.bn.bias', 'backbone.Mixed_5c.b2a.bn.running_mean', 'backbone.Mixed_5c.b2a.bn.running_var', 'backbone.Mixed_5c.b2b.conv3d.weight', 'backbone.Mixed_5c.b2b.bn.weight', 'backbone.Mixed_5c.b2b.bn.bias', 'backbone.Mixed_5c.b2b.bn.running_mean', 'backbone.Mixed_5c.b2b.bn.running_var', 'backbone.Mixed_5c.b3b.conv3d.weight', 'backbone.Mixed_5c.b3b.bn.weight', 'backbone.Mixed_5c.b3b.bn.bias', 'backbone.Mixed_5c.b3b.bn.running_mean', 'backbone.Mixed_5c.b3b.bn.running_var', 'decoder.convs.0.0.weight', 'decoder.convs.0.1.weight', 'decoder.convs.0.1.bias', 'decoder.convs.0.1.running_mean', 'decoder.convs.0.1.running_var', 'decoder.convs.1.0.weight', 'decoder.convs.1.1.weight', 'decoder.convs.1.1.bias', 'decoder.convs.1.1.running_mean', 'decoder.convs.1.1.running_var', 'decoder.convs.2.0.weight', 'decoder.convs.2.1.weight', 'decoder.convs.2.1.bias', 'decoder.convs.2.1.running_mean', 'decoder.convs.2.1.running_var', 'decoder.logit.weight', 'decoder.logit.bias']\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['backbone.cls_token', 'backbone.to_patch_embedding.weight', 'backbone.to_patch_embedding.bias', 'backbone.frame_rot_emb.inv_freqs', 'backbone.image_rot_emb.scales', 'backbone.layers.0.0.fn.to_qkv.weight', 'backbone.layers.0.0.fn.to_out.0.weight', 'backbone.layers.0.0.fn.to_out.0.bias', 'backbone.layers.0.0.norm.weight', 'backbone.layers.0.0.norm.bias', 'backbone.layers.0.1.fn.to_qkv.weight', 'backbone.layers.0.1.fn.to_out.0.weight', 'backbone.layers.0.1.fn.to_out.0.bias', 'backbone.layers.0.1.norm.weight', 'backbone.layers.0.1.norm.bias', 'backbone.layers.0.2.fn.net.0.weight', 'backbone.layers.0.2.fn.net.0.bias', 'backbone.layers.0.2.fn.net.3.weight', 'backbone.layers.0.2.fn.net.3.bias', 'backbone.layers.0.2.norm.weight', 'backbone.layers.0.2.norm.bias', 'backbone.layers.1.0.fn.to_qkv.weight', 'backbone.layers.1.0.fn.to_out.0.weight', 'backbone.layers.1.0.fn.to_out.0.bias', 'backbone.layers.1.0.norm.weight', 'backbone.layers.1.0.norm.bias', 'backbone.layers.1.1.fn.to_qkv.weight', 'backbone.layers.1.1.fn.to_out.0.weight', 'backbone.layers.1.1.fn.to_out.0.bias', 'backbone.layers.1.1.norm.weight', 'backbone.layers.1.1.norm.bias', 'backbone.layers.1.2.fn.net.0.weight', 'backbone.layers.1.2.fn.net.0.bias', 'backbone.layers.1.2.fn.net.3.weight', 'backbone.layers.1.2.fn.net.3.bias', 'backbone.layers.1.2.norm.weight', 'backbone.layers.1.2.norm.bias', 'backbone.layers.2.0.fn.to_qkv.weight', 'backbone.layers.2.0.fn.to_out.0.weight', 'backbone.layers.2.0.fn.to_out.0.bias', 'backbone.layers.2.0.norm.weight', 'backbone.layers.2.0.norm.bias', 'backbone.layers.2.1.fn.to_qkv.weight', 'backbone.layers.2.1.fn.to_out.0.weight', 'backbone.layers.2.1.fn.to_out.0.bias', 'backbone.layers.2.1.norm.weight', 'backbone.layers.2.1.norm.bias', 'backbone.layers.2.2.fn.net.0.weight', 'backbone.layers.2.2.fn.net.0.bias', 'backbone.layers.2.2.fn.net.3.weight', 'backbone.layers.2.2.fn.net.3.bias', 'backbone.layers.2.2.norm.weight', 'backbone.layers.2.2.norm.bias', 'backbone.layers.3.0.fn.to_qkv.weight', 'backbone.layers.3.0.fn.to_out.0.weight', 'backbone.layers.3.0.fn.to_out.0.bias', 'backbone.layers.3.0.norm.weight', 'backbone.layers.3.0.norm.bias', 'backbone.layers.3.1.fn.to_qkv.weight', 'backbone.layers.3.1.fn.to_out.0.weight', 'backbone.layers.3.1.fn.to_out.0.bias', 'backbone.layers.3.1.norm.weight', 'backbone.layers.3.1.norm.bias', 'backbone.layers.3.2.fn.net.0.weight', 'backbone.layers.3.2.fn.net.0.bias', 'backbone.layers.3.2.fn.net.3.weight', 'backbone.layers.3.2.fn.net.3.bias', 'backbone.layers.3.2.norm.weight', 'backbone.layers.3.2.norm.bias', 'backbone.layers.4.0.fn.to_qkv.weight', 'backbone.layers.4.0.fn.to_out.0.weight', 'backbone.layers.4.0.fn.to_out.0.bias', 'backbone.layers.4.0.norm.weight', 'backbone.layers.4.0.norm.bias', 'backbone.layers.4.1.fn.to_qkv.weight', 'backbone.layers.4.1.fn.to_out.0.weight', 'backbone.layers.4.1.fn.to_out.0.bias', 'backbone.layers.4.1.norm.weight', 'backbone.layers.4.1.norm.bias', 'backbone.layers.4.2.fn.net.0.weight', 'backbone.layers.4.2.fn.net.0.bias', 'backbone.layers.4.2.fn.net.3.weight', 'backbone.layers.4.2.fn.net.3.bias', 'backbone.layers.4.2.norm.weight', 'backbone.layers.4.2.norm.bias', 'backbone.layers.5.0.fn.to_qkv.weight', 'backbone.layers.5.0.fn.to_out.0.weight', 'backbone.layers.5.0.fn.to_out.0.bias', 'backbone.layers.5.0.norm.weight', 'backbone.layers.5.0.norm.bias', 'backbone.layers.5.1.fn.to_qkv.weight', 'backbone.layers.5.1.fn.to_out.0.weight', 'backbone.layers.5.1.fn.to_out.0.bias', 'backbone.layers.5.1.norm.weight', 'backbone.layers.5.1.norm.bias', 'backbone.layers.5.2.fn.net.0.weight', 'backbone.layers.5.2.fn.net.0.bias', 'backbone.layers.5.2.fn.net.3.weight', 'backbone.layers.5.2.fn.net.3.bias', 'backbone.layers.5.2.norm.weight', 'backbone.layers.5.2.norm.bias', 'backbone.layers.6.0.fn.to_qkv.weight', 'backbone.layers.6.0.fn.to_out.0.weight', 'backbone.layers.6.0.fn.to_out.0.bias', 'backbone.layers.6.0.norm.weight', 'backbone.layers.6.0.norm.bias', 'backbone.layers.6.1.fn.to_qkv.weight', 'backbone.layers.6.1.fn.to_out.0.weight', 'backbone.layers.6.1.fn.to_out.0.bias', 'backbone.layers.6.1.norm.weight', 'backbone.layers.6.1.norm.bias', 'backbone.layers.6.2.fn.net.0.weight', 'backbone.layers.6.2.fn.net.0.bias', 'backbone.layers.6.2.fn.net.3.weight', 'backbone.layers.6.2.fn.net.3.bias', 'backbone.layers.6.2.norm.weight', 'backbone.layers.6.2.norm.bias', 'backbone.layers.7.0.fn.to_qkv.weight', 'backbone.layers.7.0.fn.to_out.0.weight', 'backbone.layers.7.0.fn.to_out.0.bias', 'backbone.layers.7.0.norm.weight', 'backbone.layers.7.0.norm.bias', 'backbone.layers.7.1.fn.to_qkv.weight', 'backbone.layers.7.1.fn.to_out.0.weight', 'backbone.layers.7.1.fn.to_out.0.bias', 'backbone.layers.7.1.norm.weight', 'backbone.layers.7.1.norm.bias', 'backbone.layers.7.2.fn.net.0.weight', 'backbone.layers.7.2.fn.net.0.bias', 'backbone.layers.7.2.fn.net.3.weight', 'backbone.layers.7.2.fn.net.3.bias', 'backbone.layers.7.2.norm.weight', 'backbone.layers.7.2.norm.bias', 'backbone.to_out.0.weight', 'backbone.to_out.0.bias', 'backbone.to_out.1.weight', 'backbone.to_out.1.bias']\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_0to10_1718576599/20240109095720_0to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:04<00:15,  2.18s/it]Progress image saved at step 2 (22%): ./outputs/20240109095720_0to10_1718576599/20240109095720_0to10_normal_stride32_size64_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:07<00:09,  1.80s/it]Progress image saved at step 4 (44%): ./outputs/20240109095720_0to10_1718576599/20240109095720_0to10_normal_stride32_size64_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:11<00:05,  1.70s/it]Progress image saved at step 6 (66%): ./outputs/20240109095720_0to10_1718576599/20240109095720_0to10_normal_stride32_size64_batchsize512_progress_66percent.png\n",
            "100% 9/9 [00:14<00:00,  1.66s/it]\n",
            "set dataset path\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py:191: Found keys that are in the model state dict but not in the checkpoint: ['backbone.logits.conv3d.weight', 'backbone.logits.conv3d.bias', 'backbone.Conv3d_1a_7x7.conv3d.weight', 'backbone.Conv3d_1a_7x7.bn.weight', 'backbone.Conv3d_1a_7x7.bn.bias', 'backbone.Conv3d_1a_7x7.bn.running_mean', 'backbone.Conv3d_1a_7x7.bn.running_var', 'backbone.Conv3d_2b_1x1.conv3d.weight', 'backbone.Conv3d_2b_1x1.bn.weight', 'backbone.Conv3d_2b_1x1.bn.bias', 'backbone.Conv3d_2b_1x1.bn.running_mean', 'backbone.Conv3d_2b_1x1.bn.running_var', 'backbone.Conv3d_2c_3x3.conv3d.weight', 'backbone.Conv3d_2c_3x3.bn.weight', 'backbone.Conv3d_2c_3x3.bn.bias', 'backbone.Conv3d_2c_3x3.bn.running_mean', 'backbone.Conv3d_2c_3x3.bn.running_var', 'backbone.Mixed_3b.b0.conv3d.weight', 'backbone.Mixed_3b.b0.bn.weight', 'backbone.Mixed_3b.b0.bn.bias', 'backbone.Mixed_3b.b0.bn.running_mean', 'backbone.Mixed_3b.b0.bn.running_var', 'backbone.Mixed_3b.b1a.conv3d.weight', 'backbone.Mixed_3b.b1a.bn.weight', 'backbone.Mixed_3b.b1a.bn.bias', 'backbone.Mixed_3b.b1a.bn.running_mean', 'backbone.Mixed_3b.b1a.bn.running_var', 'backbone.Mixed_3b.b1b.conv3d.weight', 'backbone.Mixed_3b.b1b.bn.weight', 'backbone.Mixed_3b.b1b.bn.bias', 'backbone.Mixed_3b.b1b.bn.running_mean', 'backbone.Mixed_3b.b1b.bn.running_var', 'backbone.Mixed_3b.b2a.conv3d.weight', 'backbone.Mixed_3b.b2a.bn.weight', 'backbone.Mixed_3b.b2a.bn.bias', 'backbone.Mixed_3b.b2a.bn.running_mean', 'backbone.Mixed_3b.b2a.bn.running_var', 'backbone.Mixed_3b.b2b.conv3d.weight', 'backbone.Mixed_3b.b2b.bn.weight', 'backbone.Mixed_3b.b2b.bn.bias', 'backbone.Mixed_3b.b2b.bn.running_mean', 'backbone.Mixed_3b.b2b.bn.running_var', 'backbone.Mixed_3b.b3b.conv3d.weight', 'backbone.Mixed_3b.b3b.bn.weight', 'backbone.Mixed_3b.b3b.bn.bias', 'backbone.Mixed_3b.b3b.bn.running_mean', 'backbone.Mixed_3b.b3b.bn.running_var', 'backbone.Mixed_3c.b0.conv3d.weight', 'backbone.Mixed_3c.b0.bn.weight', 'backbone.Mixed_3c.b0.bn.bias', 'backbone.Mixed_3c.b0.bn.running_mean', 'backbone.Mixed_3c.b0.bn.running_var', 'backbone.Mixed_3c.b1a.conv3d.weight', 'backbone.Mixed_3c.b1a.bn.weight', 'backbone.Mixed_3c.b1a.bn.bias', 'backbone.Mixed_3c.b1a.bn.running_mean', 'backbone.Mixed_3c.b1a.bn.running_var', 'backbone.Mixed_3c.b1b.conv3d.weight', 'backbone.Mixed_3c.b1b.bn.weight', 'backbone.Mixed_3c.b1b.bn.bias', 'backbone.Mixed_3c.b1b.bn.running_mean', 'backbone.Mixed_3c.b1b.bn.running_var', 'backbone.Mixed_3c.b2a.conv3d.weight', 'backbone.Mixed_3c.b2a.bn.weight', 'backbone.Mixed_3c.b2a.bn.bias', 'backbone.Mixed_3c.b2a.bn.running_mean', 'backbone.Mixed_3c.b2a.bn.running_var', 'backbone.Mixed_3c.b2b.conv3d.weight', 'backbone.Mixed_3c.b2b.bn.weight', 'backbone.Mixed_3c.b2b.bn.bias', 'backbone.Mixed_3c.b2b.bn.running_mean', 'backbone.Mixed_3c.b2b.bn.running_var', 'backbone.Mixed_3c.b3b.conv3d.weight', 'backbone.Mixed_3c.b3b.bn.weight', 'backbone.Mixed_3c.b3b.bn.bias', 'backbone.Mixed_3c.b3b.bn.running_mean', 'backbone.Mixed_3c.b3b.bn.running_var', 'backbone.Mixed_4b.b0.conv3d.weight', 'backbone.Mixed_4b.b0.bn.weight', 'backbone.Mixed_4b.b0.bn.bias', 'backbone.Mixed_4b.b0.bn.running_mean', 'backbone.Mixed_4b.b0.bn.running_var', 'backbone.Mixed_4b.b1a.conv3d.weight', 'backbone.Mixed_4b.b1a.bn.weight', 'backbone.Mixed_4b.b1a.bn.bias', 'backbone.Mixed_4b.b1a.bn.running_mean', 'backbone.Mixed_4b.b1a.bn.running_var', 'backbone.Mixed_4b.b1b.conv3d.weight', 'backbone.Mixed_4b.b1b.bn.weight', 'backbone.Mixed_4b.b1b.bn.bias', 'backbone.Mixed_4b.b1b.bn.running_mean', 'backbone.Mixed_4b.b1b.bn.running_var', 'backbone.Mixed_4b.b2a.conv3d.weight', 'backbone.Mixed_4b.b2a.bn.weight', 'backbone.Mixed_4b.b2a.bn.bias', 'backbone.Mixed_4b.b2a.bn.running_mean', 'backbone.Mixed_4b.b2a.bn.running_var', 'backbone.Mixed_4b.b2b.conv3d.weight', 'backbone.Mixed_4b.b2b.bn.weight', 'backbone.Mixed_4b.b2b.bn.bias', 'backbone.Mixed_4b.b2b.bn.running_mean', 'backbone.Mixed_4b.b2b.bn.running_var', 'backbone.Mixed_4b.b3b.conv3d.weight', 'backbone.Mixed_4b.b3b.bn.weight', 'backbone.Mixed_4b.b3b.bn.bias', 'backbone.Mixed_4b.b3b.bn.running_mean', 'backbone.Mixed_4b.b3b.bn.running_var', 'backbone.Mixed_4c.b0.conv3d.weight', 'backbone.Mixed_4c.b0.bn.weight', 'backbone.Mixed_4c.b0.bn.bias', 'backbone.Mixed_4c.b0.bn.running_mean', 'backbone.Mixed_4c.b0.bn.running_var', 'backbone.Mixed_4c.b1a.conv3d.weight', 'backbone.Mixed_4c.b1a.bn.weight', 'backbone.Mixed_4c.b1a.bn.bias', 'backbone.Mixed_4c.b1a.bn.running_mean', 'backbone.Mixed_4c.b1a.bn.running_var', 'backbone.Mixed_4c.b1b.conv3d.weight', 'backbone.Mixed_4c.b1b.bn.weight', 'backbone.Mixed_4c.b1b.bn.bias', 'backbone.Mixed_4c.b1b.bn.running_mean', 'backbone.Mixed_4c.b1b.bn.running_var', 'backbone.Mixed_4c.b2a.conv3d.weight', 'backbone.Mixed_4c.b2a.bn.weight', 'backbone.Mixed_4c.b2a.bn.bias', 'backbone.Mixed_4c.b2a.bn.running_mean', 'backbone.Mixed_4c.b2a.bn.running_var', 'backbone.Mixed_4c.b2b.conv3d.weight', 'backbone.Mixed_4c.b2b.bn.weight', 'backbone.Mixed_4c.b2b.bn.bias', 'backbone.Mixed_4c.b2b.bn.running_mean', 'backbone.Mixed_4c.b2b.bn.running_var', 'backbone.Mixed_4c.b3b.conv3d.weight', 'backbone.Mixed_4c.b3b.bn.weight', 'backbone.Mixed_4c.b3b.bn.bias', 'backbone.Mixed_4c.b3b.bn.running_mean', 'backbone.Mixed_4c.b3b.bn.running_var', 'backbone.Mixed_4d.b0.conv3d.weight', 'backbone.Mixed_4d.b0.bn.weight', 'backbone.Mixed_4d.b0.bn.bias', 'backbone.Mixed_4d.b0.bn.running_mean', 'backbone.Mixed_4d.b0.bn.running_var', 'backbone.Mixed_4d.b1a.conv3d.weight', 'backbone.Mixed_4d.b1a.bn.weight', 'backbone.Mixed_4d.b1a.bn.bias', 'backbone.Mixed_4d.b1a.bn.running_mean', 'backbone.Mixed_4d.b1a.bn.running_var', 'backbone.Mixed_4d.b1b.conv3d.weight', 'backbone.Mixed_4d.b1b.bn.weight', 'backbone.Mixed_4d.b1b.bn.bias', 'backbone.Mixed_4d.b1b.bn.running_mean', 'backbone.Mixed_4d.b1b.bn.running_var', 'backbone.Mixed_4d.b2a.conv3d.weight', 'backbone.Mixed_4d.b2a.bn.weight', 'backbone.Mixed_4d.b2a.bn.bias', 'backbone.Mixed_4d.b2a.bn.running_mean', 'backbone.Mixed_4d.b2a.bn.running_var', 'backbone.Mixed_4d.b2b.conv3d.weight', 'backbone.Mixed_4d.b2b.bn.weight', 'backbone.Mixed_4d.b2b.bn.bias', 'backbone.Mixed_4d.b2b.bn.running_mean', 'backbone.Mixed_4d.b2b.bn.running_var', 'backbone.Mixed_4d.b3b.conv3d.weight', 'backbone.Mixed_4d.b3b.bn.weight', 'backbone.Mixed_4d.b3b.bn.bias', 'backbone.Mixed_4d.b3b.bn.running_mean', 'backbone.Mixed_4d.b3b.bn.running_var', 'backbone.Mixed_4e.b0.conv3d.weight', 'backbone.Mixed_4e.b0.bn.weight', 'backbone.Mixed_4e.b0.bn.bias', 'backbone.Mixed_4e.b0.bn.running_mean', 'backbone.Mixed_4e.b0.bn.running_var', 'backbone.Mixed_4e.b1a.conv3d.weight', 'backbone.Mixed_4e.b1a.bn.weight', 'backbone.Mixed_4e.b1a.bn.bias', 'backbone.Mixed_4e.b1a.bn.running_mean', 'backbone.Mixed_4e.b1a.bn.running_var', 'backbone.Mixed_4e.b1b.conv3d.weight', 'backbone.Mixed_4e.b1b.bn.weight', 'backbone.Mixed_4e.b1b.bn.bias', 'backbone.Mixed_4e.b1b.bn.running_mean', 'backbone.Mixed_4e.b1b.bn.running_var', 'backbone.Mixed_4e.b2a.conv3d.weight', 'backbone.Mixed_4e.b2a.bn.weight', 'backbone.Mixed_4e.b2a.bn.bias', 'backbone.Mixed_4e.b2a.bn.running_mean', 'backbone.Mixed_4e.b2a.bn.running_var', 'backbone.Mixed_4e.b2b.conv3d.weight', 'backbone.Mixed_4e.b2b.bn.weight', 'backbone.Mixed_4e.b2b.bn.bias', 'backbone.Mixed_4e.b2b.bn.running_mean', 'backbone.Mixed_4e.b2b.bn.running_var', 'backbone.Mixed_4e.b3b.conv3d.weight', 'backbone.Mixed_4e.b3b.bn.weight', 'backbone.Mixed_4e.b3b.bn.bias', 'backbone.Mixed_4e.b3b.bn.running_mean', 'backbone.Mixed_4e.b3b.bn.running_var', 'backbone.Mixed_4f.b0.conv3d.weight', 'backbone.Mixed_4f.b0.bn.weight', 'backbone.Mixed_4f.b0.bn.bias', 'backbone.Mixed_4f.b0.bn.running_mean', 'backbone.Mixed_4f.b0.bn.running_var', 'backbone.Mixed_4f.b1a.conv3d.weight', 'backbone.Mixed_4f.b1a.bn.weight', 'backbone.Mixed_4f.b1a.bn.bias', 'backbone.Mixed_4f.b1a.bn.running_mean', 'backbone.Mixed_4f.b1a.bn.running_var', 'backbone.Mixed_4f.b1b.conv3d.weight', 'backbone.Mixed_4f.b1b.bn.weight', 'backbone.Mixed_4f.b1b.bn.bias', 'backbone.Mixed_4f.b1b.bn.running_mean', 'backbone.Mixed_4f.b1b.bn.running_var', 'backbone.Mixed_4f.b2a.conv3d.weight', 'backbone.Mixed_4f.b2a.bn.weight', 'backbone.Mixed_4f.b2a.bn.bias', 'backbone.Mixed_4f.b2a.bn.running_mean', 'backbone.Mixed_4f.b2a.bn.running_var', 'backbone.Mixed_4f.b2b.conv3d.weight', 'backbone.Mixed_4f.b2b.bn.weight', 'backbone.Mixed_4f.b2b.bn.bias', 'backbone.Mixed_4f.b2b.bn.running_mean', 'backbone.Mixed_4f.b2b.bn.running_var', 'backbone.Mixed_4f.b3b.conv3d.weight', 'backbone.Mixed_4f.b3b.bn.weight', 'backbone.Mixed_4f.b3b.bn.bias', 'backbone.Mixed_4f.b3b.bn.running_mean', 'backbone.Mixed_4f.b3b.bn.running_var', 'backbone.Mixed_5b.b0.conv3d.weight', 'backbone.Mixed_5b.b0.bn.weight', 'backbone.Mixed_5b.b0.bn.bias', 'backbone.Mixed_5b.b0.bn.running_mean', 'backbone.Mixed_5b.b0.bn.running_var', 'backbone.Mixed_5b.b1a.conv3d.weight', 'backbone.Mixed_5b.b1a.bn.weight', 'backbone.Mixed_5b.b1a.bn.bias', 'backbone.Mixed_5b.b1a.bn.running_mean', 'backbone.Mixed_5b.b1a.bn.running_var', 'backbone.Mixed_5b.b1b.conv3d.weight', 'backbone.Mixed_5b.b1b.bn.weight', 'backbone.Mixed_5b.b1b.bn.bias', 'backbone.Mixed_5b.b1b.bn.running_mean', 'backbone.Mixed_5b.b1b.bn.running_var', 'backbone.Mixed_5b.b2a.conv3d.weight', 'backbone.Mixed_5b.b2a.bn.weight', 'backbone.Mixed_5b.b2a.bn.bias', 'backbone.Mixed_5b.b2a.bn.running_mean', 'backbone.Mixed_5b.b2a.bn.running_var', 'backbone.Mixed_5b.b2b.conv3d.weight', 'backbone.Mixed_5b.b2b.bn.weight', 'backbone.Mixed_5b.b2b.bn.bias', 'backbone.Mixed_5b.b2b.bn.running_mean', 'backbone.Mixed_5b.b2b.bn.running_var', 'backbone.Mixed_5b.b3b.conv3d.weight', 'backbone.Mixed_5b.b3b.bn.weight', 'backbone.Mixed_5b.b3b.bn.bias', 'backbone.Mixed_5b.b3b.bn.running_mean', 'backbone.Mixed_5b.b3b.bn.running_var', 'backbone.Mixed_5c.b0.conv3d.weight', 'backbone.Mixed_5c.b0.bn.weight', 'backbone.Mixed_5c.b0.bn.bias', 'backbone.Mixed_5c.b0.bn.running_mean', 'backbone.Mixed_5c.b0.bn.running_var', 'backbone.Mixed_5c.b1a.conv3d.weight', 'backbone.Mixed_5c.b1a.bn.weight', 'backbone.Mixed_5c.b1a.bn.bias', 'backbone.Mixed_5c.b1a.bn.running_mean', 'backbone.Mixed_5c.b1a.bn.running_var', 'backbone.Mixed_5c.b1b.conv3d.weight', 'backbone.Mixed_5c.b1b.bn.weight', 'backbone.Mixed_5c.b1b.bn.bias', 'backbone.Mixed_5c.b1b.bn.running_mean', 'backbone.Mixed_5c.b1b.bn.running_var', 'backbone.Mixed_5c.b2a.conv3d.weight', 'backbone.Mixed_5c.b2a.bn.weight', 'backbone.Mixed_5c.b2a.bn.bias', 'backbone.Mixed_5c.b2a.bn.running_mean', 'backbone.Mixed_5c.b2a.bn.running_var', 'backbone.Mixed_5c.b2b.conv3d.weight', 'backbone.Mixed_5c.b2b.bn.weight', 'backbone.Mixed_5c.b2b.bn.bias', 'backbone.Mixed_5c.b2b.bn.running_mean', 'backbone.Mixed_5c.b2b.bn.running_var', 'backbone.Mixed_5c.b3b.conv3d.weight', 'backbone.Mixed_5c.b3b.bn.weight', 'backbone.Mixed_5c.b3b.bn.bias', 'backbone.Mixed_5c.b3b.bn.running_mean', 'backbone.Mixed_5c.b3b.bn.running_var', 'decoder.convs.0.0.weight', 'decoder.convs.0.1.weight', 'decoder.convs.0.1.bias', 'decoder.convs.0.1.running_mean', 'decoder.convs.0.1.running_var', 'decoder.convs.1.0.weight', 'decoder.convs.1.1.weight', 'decoder.convs.1.1.bias', 'decoder.convs.1.1.running_mean', 'decoder.convs.1.1.running_var', 'decoder.convs.2.0.weight', 'decoder.convs.2.1.weight', 'decoder.convs.2.1.bias', 'decoder.convs.2.1.running_mean', 'decoder.convs.2.1.running_var', 'decoder.logit.weight', 'decoder.logit.bias']\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['backbone.cls_token', 'backbone.to_patch_embedding.weight', 'backbone.to_patch_embedding.bias', 'backbone.frame_rot_emb.inv_freqs', 'backbone.image_rot_emb.scales', 'backbone.layers.0.0.fn.to_qkv.weight', 'backbone.layers.0.0.fn.to_out.0.weight', 'backbone.layers.0.0.fn.to_out.0.bias', 'backbone.layers.0.0.norm.weight', 'backbone.layers.0.0.norm.bias', 'backbone.layers.0.1.fn.to_qkv.weight', 'backbone.layers.0.1.fn.to_out.0.weight', 'backbone.layers.0.1.fn.to_out.0.bias', 'backbone.layers.0.1.norm.weight', 'backbone.layers.0.1.norm.bias', 'backbone.layers.0.2.fn.net.0.weight', 'backbone.layers.0.2.fn.net.0.bias', 'backbone.layers.0.2.fn.net.3.weight', 'backbone.layers.0.2.fn.net.3.bias', 'backbone.layers.0.2.norm.weight', 'backbone.layers.0.2.norm.bias', 'backbone.layers.1.0.fn.to_qkv.weight', 'backbone.layers.1.0.fn.to_out.0.weight', 'backbone.layers.1.0.fn.to_out.0.bias', 'backbone.layers.1.0.norm.weight', 'backbone.layers.1.0.norm.bias', 'backbone.layers.1.1.fn.to_qkv.weight', 'backbone.layers.1.1.fn.to_out.0.weight', 'backbone.layers.1.1.fn.to_out.0.bias', 'backbone.layers.1.1.norm.weight', 'backbone.layers.1.1.norm.bias', 'backbone.layers.1.2.fn.net.0.weight', 'backbone.layers.1.2.fn.net.0.bias', 'backbone.layers.1.2.fn.net.3.weight', 'backbone.layers.1.2.fn.net.3.bias', 'backbone.layers.1.2.norm.weight', 'backbone.layers.1.2.norm.bias', 'backbone.layers.2.0.fn.to_qkv.weight', 'backbone.layers.2.0.fn.to_out.0.weight', 'backbone.layers.2.0.fn.to_out.0.bias', 'backbone.layers.2.0.norm.weight', 'backbone.layers.2.0.norm.bias', 'backbone.layers.2.1.fn.to_qkv.weight', 'backbone.layers.2.1.fn.to_out.0.weight', 'backbone.layers.2.1.fn.to_out.0.bias', 'backbone.layers.2.1.norm.weight', 'backbone.layers.2.1.norm.bias', 'backbone.layers.2.2.fn.net.0.weight', 'backbone.layers.2.2.fn.net.0.bias', 'backbone.layers.2.2.fn.net.3.weight', 'backbone.layers.2.2.fn.net.3.bias', 'backbone.layers.2.2.norm.weight', 'backbone.layers.2.2.norm.bias', 'backbone.layers.3.0.fn.to_qkv.weight', 'backbone.layers.3.0.fn.to_out.0.weight', 'backbone.layers.3.0.fn.to_out.0.bias', 'backbone.layers.3.0.norm.weight', 'backbone.layers.3.0.norm.bias', 'backbone.layers.3.1.fn.to_qkv.weight', 'backbone.layers.3.1.fn.to_out.0.weight', 'backbone.layers.3.1.fn.to_out.0.bias', 'backbone.layers.3.1.norm.weight', 'backbone.layers.3.1.norm.bias', 'backbone.layers.3.2.fn.net.0.weight', 'backbone.layers.3.2.fn.net.0.bias', 'backbone.layers.3.2.fn.net.3.weight', 'backbone.layers.3.2.fn.net.3.bias', 'backbone.layers.3.2.norm.weight', 'backbone.layers.3.2.norm.bias', 'backbone.layers.4.0.fn.to_qkv.weight', 'backbone.layers.4.0.fn.to_out.0.weight', 'backbone.layers.4.0.fn.to_out.0.bias', 'backbone.layers.4.0.norm.weight', 'backbone.layers.4.0.norm.bias', 'backbone.layers.4.1.fn.to_qkv.weight', 'backbone.layers.4.1.fn.to_out.0.weight', 'backbone.layers.4.1.fn.to_out.0.bias', 'backbone.layers.4.1.norm.weight', 'backbone.layers.4.1.norm.bias', 'backbone.layers.4.2.fn.net.0.weight', 'backbone.layers.4.2.fn.net.0.bias', 'backbone.layers.4.2.fn.net.3.weight', 'backbone.layers.4.2.fn.net.3.bias', 'backbone.layers.4.2.norm.weight', 'backbone.layers.4.2.norm.bias', 'backbone.layers.5.0.fn.to_qkv.weight', 'backbone.layers.5.0.fn.to_out.0.weight', 'backbone.layers.5.0.fn.to_out.0.bias', 'backbone.layers.5.0.norm.weight', 'backbone.layers.5.0.norm.bias', 'backbone.layers.5.1.fn.to_qkv.weight', 'backbone.layers.5.1.fn.to_out.0.weight', 'backbone.layers.5.1.fn.to_out.0.bias', 'backbone.layers.5.1.norm.weight', 'backbone.layers.5.1.norm.bias', 'backbone.layers.5.2.fn.net.0.weight', 'backbone.layers.5.2.fn.net.0.bias', 'backbone.layers.5.2.fn.net.3.weight', 'backbone.layers.5.2.fn.net.3.bias', 'backbone.layers.5.2.norm.weight', 'backbone.layers.5.2.norm.bias', 'backbone.layers.6.0.fn.to_qkv.weight', 'backbone.layers.6.0.fn.to_out.0.weight', 'backbone.layers.6.0.fn.to_out.0.bias', 'backbone.layers.6.0.norm.weight', 'backbone.layers.6.0.norm.bias', 'backbone.layers.6.1.fn.to_qkv.weight', 'backbone.layers.6.1.fn.to_out.0.weight', 'backbone.layers.6.1.fn.to_out.0.bias', 'backbone.layers.6.1.norm.weight', 'backbone.layers.6.1.norm.bias', 'backbone.layers.6.2.fn.net.0.weight', 'backbone.layers.6.2.fn.net.0.bias', 'backbone.layers.6.2.fn.net.3.weight', 'backbone.layers.6.2.fn.net.3.bias', 'backbone.layers.6.2.norm.weight', 'backbone.layers.6.2.norm.bias', 'backbone.layers.7.0.fn.to_qkv.weight', 'backbone.layers.7.0.fn.to_out.0.weight', 'backbone.layers.7.0.fn.to_out.0.bias', 'backbone.layers.7.0.norm.weight', 'backbone.layers.7.0.norm.bias', 'backbone.layers.7.1.fn.to_qkv.weight', 'backbone.layers.7.1.fn.to_out.0.weight', 'backbone.layers.7.1.fn.to_out.0.bias', 'backbone.layers.7.1.norm.weight', 'backbone.layers.7.1.norm.bias', 'backbone.layers.7.2.fn.net.0.weight', 'backbone.layers.7.2.fn.net.0.bias', 'backbone.layers.7.2.fn.net.3.weight', 'backbone.layers.7.2.fn.net.3.bias', 'backbone.layers.7.2.norm.weight', 'backbone.layers.7.2.norm.bias', 'backbone.to_out.0.weight', 'backbone.to_out.0.bias', 'backbone.to_out.1.weight', 'backbone.to_out.1.bias']\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_0to10_1718576695/20240109095720_0to10_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:04<00:16,  2.32s/it]Progress image saved at step 2 (22%): ./outputs/20240109095720_0to10_1718576695/20240109095720_0to10_reversed_stride32_size64_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:08<00:09,  1.87s/it]Progress image saved at step 4 (44%): ./outputs/20240109095720_0to10_1718576695/20240109095720_0to10_reversed_stride32_size64_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:11<00:05,  1.75s/it]Progress image saved at step 6 (66%): ./outputs/20240109095720_0to10_1718576695/20240109095720_0to10_reversed_stride32_size64_batchsize512_progress_66percent.png\n",
            "100% 9/9 [00:15<00:00,  1.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2rBwwxOH1Si"
      },
      "outputs": [],
      "source": [
        "!python inference_v24_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt\n",
        "!python inference_v24_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03THT9uOH1Uj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeOxoizEH1W0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mhCkCfis95E"
      },
      "source": [
        "#1002"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV1AOUmRCewx",
        "outputId": "19d7b80a-a53c-45f2-8def-3f45b9e1489d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 2/254 [00:05<10:06,  2.41s/it]Progress image saved at step 2 (0%): ./outputs/20231016151002_0to60_1718218325/20231016151002_0to60_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 63/254 [01:39<04:43,  1.48s/it]Progress image saved at step 63 (24%): ./outputs/20231016151002_0to60_1718218325/20231016151002_0to60_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 127/254 [03:22<03:11,  1.50s/it]Progress image saved at step 127 (50%): ./outputs/20231016151002_0to60_1718218325/20231016151002_0to60_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 190/254 [05:08<01:37,  1.52s/it]Progress image saved at step 190 (74%): ./outputs/20231016151002_0to60_1718218325/20231016151002_0to60_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 254/254 [06:58<00:00,  1.65s/it]\n",
            "set dataset path\n",
            "  1% 2/254 [00:04<09:26,  2.25s/it]Progress image saved at step 2 (0%): ./outputs/20231016151002_0to20_1718218966/20231016151002_0to20_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 63/254 [01:40<04:47,  1.51s/it]Progress image saved at step 63 (24%): ./outputs/20231016151002_0to20_1718218966/20231016151002_0to20_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 127/254 [03:24<03:12,  1.52s/it]Progress image saved at step 127 (50%): ./outputs/20231016151002_0to20_1718218966/20231016151002_0to20_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 190/254 [05:10<01:37,  1.53s/it]Progress image saved at step 190 (74%): ./outputs/20231016151002_0to20_1718218966/20231016151002_0to20_reversed_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 254/254 [07:01<00:00,  1.66s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20231016151002 --start_idx 0 --end_idx 60 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20231016151002 --start_idx 0 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf00PuCRCezX",
        "outputId": "81d86bcb-32a9-422e-9258-c34b7ab28b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "[ WARN:0@193.125] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20231016151002/layers/65.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "set dataset path\n",
            "[ WARN:0@24.216] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20231016151002/layers/65.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_reversed.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 50 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 50 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtGh6zTNCe3B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxonSavFZSSN"
      },
      "source": [
        "#title\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzCz4x9vTG83",
        "outputId": "70de7c39-b996-4c87-d64d-a29224547b80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/A_Scroll/inkception-3d\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aFWA-2IMKiO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5Edq1p7dq6i",
        "outputId": "89798bf6-5b51-4421-c21f-52b72888d496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_16to20_1718591238/20240102231959_16to20_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:21<01:10,  6.39s/it]Progress image saved at step 3 (21%): ./outputs/20240102231959_16to20_1718591238/20240102231959_16to20_normal_stride32_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:40<00:35,  5.02s/it]Progress image saved at step 7 (50%): ./outputs/20240102231959_16to20_1718591238/20240102231959_16to20_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:55<00:19,  4.91s/it]Progress image saved at step 10 (71%): ./outputs/20240102231959_16to20_1718591238/20240102231959_16to20_normal_stride32_size128_batchsize512_progress_71percent.png\n",
            "100% 14/14 [01:10<00:00,  5.05s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 16 --end_idx 20 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAnH68ng9QZO",
        "outputId": "97b911c3-781f-4b32-8de8-9b777854dda3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/53 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_20to22_1718590972/20240102231959_20to22_normal_stride16_size128_batchsize512_progress_0percent.png\n",
            " 25% 13/53 [01:08<03:04,  4.62s/it]Progress image saved at step 13 (24%): ./outputs/20240102231959_20to22_1718590972/20240102231959_20to22_normal_stride16_size128_batchsize512_progress_24percent.png\n",
            " 49% 26/53 [02:08<02:02,  4.53s/it]Progress image saved at step 26 (49%): ./outputs/20240102231959_20to22_1718590972/20240102231959_20to22_normal_stride16_size128_batchsize512_progress_49percent.png\n",
            " 74% 39/53 [03:08<01:04,  4.58s/it]Progress image saved at step 39 (73%): ./outputs/20240102231959_20to22_1718590972/20240102231959_20to22_normal_stride16_size128_batchsize512_progress_73percent.png\n",
            "100% 53/53 [04:09<00:00,  4.70s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 20 --end_idx 22 --stride 16 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJodCKwjnKAw",
        "outputId": "6b77994b-0c92-48d7-a1e0-b287a57b3492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_20to22_1718590755/20240102231959_20to22_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            " 21% 3/14 [00:21<01:09,  6.32s/it]Progress image saved at step 3 (21%): ./outputs/20240102231959_20to22_1718590755/20240102231959_20to22_normal_stride32_size128_batchsize512_progress_21percent.png\n",
            " 50% 7/14 [00:40<00:34,  4.92s/it]Progress image saved at step 7 (50%): ./outputs/20240102231959_20to22_1718590755/20240102231959_20to22_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 71% 10/14 [00:54<00:19,  4.85s/it]Progress image saved at step 10 (71%): ./outputs/20240102231959_20to22_1718590755/20240102231959_20to22_normal_stride32_size128_batchsize512_progress_71percent.png\n",
            "100% 14/14 [01:10<00:00,  5.01s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 20 --end_idx 22 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFtrErU89YIX",
        "outputId": "7c759108-8d75-414c-8edf-d6820f0d4eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/53 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240102231959_26to32_1718590350/20240102231959_26to32_normal_stride16_size128_batchsize512_progress_0percent.png\n",
            " 25% 13/53 [01:09<03:06,  4.67s/it]Progress image saved at step 13 (24%): ./outputs/20240102231959_26to32_1718590350/20240102231959_26to32_normal_stride16_size128_batchsize512_progress_24percent.png\n",
            " 49% 26/53 [02:08<02:03,  4.58s/it]Progress image saved at step 26 (49%): ./outputs/20240102231959_26to32_1718590350/20240102231959_26to32_normal_stride16_size128_batchsize512_progress_49percent.png\n",
            " 74% 39/53 [03:09<01:03,  4.56s/it]Progress image saved at step 39 (73%): ./outputs/20240102231959_26to32_1718590350/20240102231959_26to32_normal_stride16_size128_batchsize512_progress_73percent.png\n",
            "100% 53/53 [04:10<00:00,  4.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 26 --end_idx 32 --stride 16 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfIozmn5wZj5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzerNc6RnKDK",
        "outputId": "559c42ce-5999-4026-da6b-050807c99400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "[ WARN:0@46.021] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20240102231959/layers/65.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v23_normal.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 50 --end_idx 60 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwYZ4UlXnKF8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhnSPkJKnKIZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfwr4BZZnKKo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nReh1n8rm9JI",
        "outputId": "7ed532bc-f015-4690-8959-54790f58f8de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_0to6_1718148154/20240109095720_0to6_normal_stride32_size32_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:02<00:07,  1.01s/it]Progress image saved at step 2 (22%): ./outputs/20240109095720_0to6_1718148154/20240109095720_0to6_normal_stride32_size32_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:03<00:04,  1.20it/s]Progress image saved at step 4 (44%): ./outputs/20240109095720_0to6_1718148154/20240109095720_0to6_normal_stride32_size32_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:05<00:02,  1.23it/s]Progress image saved at step 6 (66%): ./outputs/20240109095720_0to6_1718148154/20240109095720_0to6_normal_stride32_size32_batchsize512_progress_66percent.png\n",
            "100% 9/9 [00:07<00:00,  1.17it/s]\n",
            "set dataset path\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_0to6_1718148173/20240109095720_0to6_reversed_stride32_size32_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:02<00:07,  1.06s/it]Progress image saved at step 2 (22%): ./outputs/20240109095720_0to6_1718148173/20240109095720_0to6_reversed_stride32_size32_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:03<00:04,  1.17it/s]Progress image saved at step 4 (44%): ./outputs/20240109095720_0to6_1718148173/20240109095720_0to6_reversed_stride32_size32_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:05<00:02,  1.22it/s]Progress image saved at step 6 (66%): ./outputs/20240109095720_0to6_1718148173/20240109095720_0to6_reversed_stride32_size32_batchsize512_progress_66percent.png\n",
            "100% 9/9 [00:07<00:00,  1.16it/s]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 00 --end_idx 06 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 00 --end_idx 06 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5SIjcMum9MA",
        "outputId": "5a762adf-37c4-4773-a472-d9a0ba68923f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/33 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_11to16_1718148193/20240109095720_11to16_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 8/33 [00:13<00:37,  1.51s/it]Progress image saved at step 8 (24%): ./outputs/20240109095720_11to16_1718148193/20240109095720_11to16_normal_stride16_size64_batchsize512_progress_24percent.png\n",
            " 48% 16/33 [00:25<00:25,  1.47s/it]Progress image saved at step 16 (48%): ./outputs/20240109095720_11to16_1718148193/20240109095720_11to16_normal_stride16_size64_batchsize512_progress_48percent.png\n",
            " 73% 24/33 [00:37<00:13,  1.48s/it]Progress image saved at step 24 (72%): ./outputs/20240109095720_11to16_1718148193/20240109095720_11to16_normal_stride16_size64_batchsize512_progress_72percent.png\n",
            "100% 33/33 [00:51<00:00,  1.56s/it]\n",
            "set dataset path\n",
            "  0% 0/33 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_11to16_1718148300/20240109095720_11to16_reversed_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 8/33 [00:14<00:38,  1.53s/it]Progress image saved at step 8 (24%): ./outputs/20240109095720_11to16_1718148300/20240109095720_11to16_reversed_stride16_size64_batchsize512_progress_24percent.png\n",
            " 48% 16/33 [00:26<00:25,  1.48s/it]Progress image saved at step 16 (48%): ./outputs/20240109095720_11to16_1718148300/20240109095720_11to16_reversed_stride16_size64_batchsize512_progress_48percent.png\n",
            " 73% 24/33 [00:38<00:13,  1.49s/it]Progress image saved at step 24 (72%): ./outputs/20240109095720_11to16_1718148300/20240109095720_11to16_reversed_stride16_size64_batchsize512_progress_72percent.png\n",
            "100% 33/33 [00:51<00:00,  1.58s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 11 --end_idx 16 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 11 --end_idx 16 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Bfw1VqQm9Rv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNkvaoT3m9UX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxhmOpShm9XB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3BQYONlUwQB",
        "outputId": "e32b0496-8695-45b0-b28d-167d53e4fa47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/59 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240102231959_32to46_1718147979/20240102231959_32to46_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 24% 14/59 [00:22<01:05,  1.46s/it]Progress image saved at step 14 (23%): ./outputs/20240102231959_32to46_1718147979/20240102231959_32to46_normal_stride16_size64_batchsize512_progress_23percent.png\n",
            " 49% 29/59 [00:45<00:43,  1.46s/it]Progress image saved at step 29 (49%): ./outputs/20240102231959_32to46_1718147979/20240102231959_32to46_normal_stride16_size64_batchsize512_progress_49percent.png\n",
            " 75% 44/59 [01:08<00:21,  1.46s/it]Progress image saved at step 44 (74%): ./outputs/20240102231959_32to46_1718147979/20240102231959_32to46_normal_stride16_size64_batchsize512_progress_74percent.png\n",
            "100% 59/59 [01:29<00:00,  1.52s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 32 --end_idx 46 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYFs1hfRUwSR",
        "outputId": "5e09c1cf-4740-4c11-b145-ed113d0b265f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/16 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240102231959_40to50_1718148084/20240102231959_40to50_normal_stride32_size32_batchsize512_progress_0percent.png\n",
            " 25% 4/16 [00:03<00:09,  1.24it/s]Progress image saved at step 4 (25%): ./outputs/20240102231959_40to50_1718148084/20240102231959_40to50_normal_stride32_size32_batchsize512_progress_25percent.png\n",
            " 50% 8/16 [00:07<00:05,  1.38it/s]Progress image saved at step 8 (50%): ./outputs/20240102231959_40to50_1718148084/20240102231959_40to50_normal_stride32_size32_batchsize512_progress_50percent.png\n",
            " 75% 12/16 [00:10<00:02,  1.34it/s]Progress image saved at step 12 (75%): ./outputs/20240102231959_40to50_1718148084/20240102231959_40to50_normal_stride32_size32_batchsize512_progress_75percent.png\n",
            "100% 16/16 [00:13<00:00,  1.16it/s]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 40 --end_idx 50 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgZsSNlBUwUd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH9NWuTwMMtV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F06XkBtlMJRn",
        "outputId": "2cf0c0c2-6ec8-4a6b-ac66-4872fc70f152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/1 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240610063907_0to64_1718077998/20240610063907_0to64_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            "100% 1/1 [00:00<00:00,  1.55it/s]\n",
            "set dataset path\n",
            "  0% 0/1 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240610063907_0to64_1718078034/20240610063907_0to64_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            "100% 1/1 [00:00<00:00,  2.28it/s]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240610063907 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240610063907 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaekvFvyjXav"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240610063907 --start_idx 20 --end_idx 50 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240610063907 --start_idx 20 --end_idx 50 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wad1DOdDjXdm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOowjVsim5f4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HHtkWZtdq9P"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 30 --end_idx 40 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 30 --end_idx 40 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoTS7Uwpdq_W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bHIh5gXdrGQ",
        "outputId": "f57efdaf-ebf1-4e29-ac91-162f02e4d6e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/94 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240101215220_0to64_1718143794/20240101215220_0to64_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 23/94 [00:37<01:44,  1.47s/it]Progress image saved at step 23 (24%): ./outputs/20240101215220_0to64_1718143794/20240101215220_0to64_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 47/94 [01:16<01:09,  1.48s/it]Progress image saved at step 47 (50%): ./outputs/20240101215220_0to64_1718143794/20240101215220_0to64_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 74% 70/94 [01:54<00:35,  1.49s/it]Progress image saved at step 70 (74%): ./outputs/20240101215220_0to64_1718143794/20240101215220_0to64_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 94/94 [02:34<00:00,  1.65s/it]\n",
            "set dataset path\n",
            "  0% 0/94 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240101215220_0to64_1718144081/20240101215220_0to64_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 23/94 [00:38<01:45,  1.48s/it]Progress image saved at step 23 (24%): ./outputs/20240101215220_0to64_1718144081/20240101215220_0to64_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 47/94 [01:17<01:10,  1.50s/it]Progress image saved at step 47 (50%): ./outputs/20240101215220_0to64_1718144081/20240101215220_0to64_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 74% 70/94 [01:55<00:36,  1.51s/it]Progress image saved at step 70 (74%): ./outputs/20240101215220_0to64_1718144081/20240101215220_0to64_reversed_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 94/94 [02:36<00:00,  1.66s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXktZihZXZyb"
      },
      "outputs": [],
      "source": [
        "20231206155550"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5frJKjrYGSL"
      },
      "outputs": [],
      "source": [
        "20240101215220"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_PN1vNyTcMZ",
        "outputId": "8f0a49c2-7235-483f-f74a-0a8920331a93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_40to64_1718219447/20240109095720_40to64_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:04<00:16,  2.32s/it]Progress image saved at step 2 (22%): ./outputs/20240109095720_40to64_1718219447/20240109095720_40to64_normal_stride32_size64_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:08<00:09,  1.84s/it]Progress image saved at step 4 (44%): ./outputs/20240109095720_40to64_1718219447/20240109095720_40to64_normal_stride32_size64_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:11<00:05,  1.73s/it]Progress image saved at step 6 (66%): ./outputs/20240109095720_40to64_1718219447/20240109095720_40to64_normal_stride32_size64_batchsize512_progress_66percent.png\n",
            "100% 9/9 [00:15<00:00,  1.72s/it]\n",
            "set dataset path\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240109095720_40to64_1718219535/20240109095720_40to64_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 22% 2/9 [00:04<00:15,  2.22s/it]Progress image saved at step 2 (22%): ./outputs/20240109095720_40to64_1718219535/20240109095720_40to64_reversed_stride32_size64_batchsize512_progress_22percent.png\n",
            " 44% 4/9 [00:08<00:09,  1.81s/it]Progress image saved at step 4 (44%): ./outputs/20240109095720_40to64_1718219535/20240109095720_40to64_reversed_stride32_size64_batchsize512_progress_44percent.png\n",
            " 67% 6/9 [00:11<00:05,  1.72s/it]Progress image saved at step 6 (66%): ./outputs/20240109095720_40to64_1718219535/20240109095720_40to64_reversed_stride32_size64_batchsize512_progress_66percent.png\n",
            "100% 9/9 [00:15<00:00,  1.70s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 40 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 40 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6TkEX-IdrIx",
        "outputId": "144104af-58ac-4a55-db05-af01f8943a98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_0percent.png\n",
            "  4% 1/24 [00:16<06:30, 16.99s/it]Progress image saved at step 1 (4%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_4percent.png\n",
            "  8% 2/24 [00:32<05:55, 16.15s/it]Progress image saved at step 2 (8%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_8percent.png\n",
            " 12% 3/24 [00:38<04:05, 11.71s/it]Progress image saved at step 3 (12%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_12percent.png\n",
            " 17% 4/24 [00:44<03:05,  9.28s/it]Progress image saved at step 4 (16%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_16percent.png\n",
            " 25% 6/24 [00:54<01:59,  6.64s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_25percent.png\n",
            " 29% 7/24 [00:59<01:44,  6.16s/it]Progress image saved at step 7 (29%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_29percent.png\n",
            " 33% 8/24 [01:04<01:33,  5.87s/it]Progress image saved at step 8 (33%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_33percent.png\n",
            " 38% 9/24 [01:10<01:26,  5.74s/it]Progress image saved at step 9 (37%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_37percent.png\n",
            " 42% 10/24 [01:15<01:18,  5.61s/it]Progress image saved at step 10 (41%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_41percent.png\n",
            " 50% 12/24 [01:25<01:02,  5.19s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_50percent.png\n",
            " 54% 13/24 [01:30<00:58,  5.28s/it]Progress image saved at step 13 (54%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_54percent.png\n",
            " 58% 14/24 [01:36<00:54,  5.41s/it]Progress image saved at step 14 (58%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_58percent.png\n",
            " 62% 15/24 [01:42<00:49,  5.51s/it]Progress image saved at step 15 (62%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_62percent.png\n",
            " 67% 16/24 [01:47<00:44,  5.59s/it]Progress image saved at step 16 (66%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_66percent.png\n",
            " 75% 18/24 [01:58<00:31,  5.30s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_75percent.png\n",
            " 79% 19/24 [02:03<00:27,  5.45s/it]Progress image saved at step 19 (79%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_79percent.png\n",
            " 83% 20/24 [02:09<00:22,  5.57s/it]Progress image saved at step 20 (83%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_83percent.png\n",
            " 88% 21/24 [02:16<00:17,  5.78s/it]Progress image saved at step 21 (87%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_87percent.png\n",
            " 92% 22/24 [02:22<00:11,  5.90s/it]Progress image saved at step 22 (91%): ./outputs/20240116164433_20to50_1718219564/20240116164433_20to50_normal_stride32_size128_batchsize512_progress_91percent.png\n",
            "100% 24/24 [02:29<00:00,  6.23s/it]\n",
            "set dataset path\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv3d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 3.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Progress image saved at step 0 (0%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_0percent.png\n",
            "  4% 1/24 [00:11<04:17, 11.19s/it]Progress image saved at step 1 (4%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_4percent.png\n",
            "  8% 2/24 [00:16<02:54,  7.92s/it]Progress image saved at step 2 (8%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_8percent.png\n",
            " 12% 3/24 [00:22<02:27,  7.04s/it]Progress image saved at step 3 (12%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_12percent.png\n",
            " 17% 4/24 [00:28<02:12,  6.63s/it]Progress image saved at step 4 (16%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_16percent.png\n",
            " 25% 6/24 [00:38<01:39,  5.52s/it]Progress image saved at step 6 (25%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_25percent.png\n",
            " 29% 7/24 [00:43<01:32,  5.41s/it]Progress image saved at step 7 (29%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_29percent.png\n",
            " 33% 8/24 [00:48<01:25,  5.37s/it]Progress image saved at step 8 (33%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_33percent.png\n",
            " 38% 9/24 [00:55<01:27,  5.81s/it]Progress image saved at step 9 (37%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_37percent.png\n",
            " 42% 10/24 [01:01<01:20,  5.75s/it]Progress image saved at step 10 (41%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_41percent.png\n",
            " 50% 12/24 [01:11<01:03,  5.27s/it]Progress image saved at step 12 (50%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_50percent.png\n",
            " 54% 13/24 [01:16<00:59,  5.37s/it]Progress image saved at step 13 (54%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_54percent.png\n",
            " 58% 14/24 [01:22<00:54,  5.42s/it]Progress image saved at step 14 (58%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_58percent.png\n",
            " 62% 15/24 [01:27<00:49,  5.48s/it]Progress image saved at step 15 (62%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_62percent.png\n",
            " 67% 16/24 [01:33<00:44,  5.57s/it]Progress image saved at step 16 (66%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_66percent.png\n",
            " 75% 18/24 [01:43<00:31,  5.31s/it]Progress image saved at step 18 (75%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_75percent.png\n",
            " 79% 19/24 [01:49<00:27,  5.51s/it]Progress image saved at step 19 (79%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_79percent.png\n",
            " 83% 20/24 [01:55<00:22,  5.63s/it]Progress image saved at step 20 (83%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_83percent.png\n",
            " 88% 21/24 [02:01<00:17,  5.77s/it]Progress image saved at step 21 (87%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_87percent.png\n",
            " 92% 22/24 [02:07<00:11,  5.83s/it]Progress image saved at step 22 (91%): ./outputs/20240116164433_20to50_1718219800/20240116164433_20to50_reversed_stride32_size128_batchsize512_progress_91percent.png\n",
            "100% 24/24 [02:15<00:00,  5.64s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 20 --end_idx 50 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 20 --end_idx 50 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjdq-hkZdrLp"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvVIZMMFw9SK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HSOJiqDw9U7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8kC296mw9W4"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 32 --end_idx 36 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 32 --end_idx 36 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlwc6-yqZ7Nt"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 20 --end_idx 50 --stride 16 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 20 --end_idx 50 --stride 16 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxnttUGMZyFb"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 28 --end_idx 38 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 28 --end_idx 38 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP45gW1ZUmLZ"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ0KOGlTZ4Ni"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 10 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 10 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "076C-G4yZ9L_"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 50 --end_idx 60 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 50 --end_idx 60 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmO5USXSUmN1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlE1_5qNUmQW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3JdLlIKUmS6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puFca7Lrmxm0"
      },
      "source": [
        "#seg 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kTtSeSQO7Oib",
        "outputId": "b2cdc61b-2e54-4fbc-b348-7fabdc517648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/112 [00:03<05:53,  3.19s/it]Progress image saved at step 1 (0%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            "  4% 5/112 [00:09<03:02,  1.71s/it]Progress image saved at step 5 (4%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_4percent.png\n",
            " 10% 11/112 [00:19<02:31,  1.50s/it]Progress image saved at step 11 (9%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_9percent.png\n",
            " 14% 16/112 [00:26<02:23,  1.50s/it]Progress image saved at step 16 (14%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_14percent.png\n",
            " 20% 22/112 [00:36<02:14,  1.49s/it]Progress image saved at step 22 (19%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_19percent.png\n",
            " 25% 28/112 [00:45<02:05,  1.50s/it]Progress image saved at step 28 (25%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 29% 33/112 [00:53<02:00,  1.53s/it]Progress image saved at step 33 (29%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_29percent.png\n",
            " 35% 39/112 [01:03<01:50,  1.51s/it]Progress image saved at step 39 (34%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_34percent.png\n",
            " 39% 44/112 [01:11<01:45,  1.55s/it]Progress image saved at step 44 (39%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_39percent.png\n",
            " 45% 50/112 [01:21<01:35,  1.53s/it]Progress image saved at step 50 (44%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_44percent.png\n",
            " 50% 56/112 [01:31<01:26,  1.54s/it]Progress image saved at step 56 (50%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 54% 61/112 [01:40<01:20,  1.57s/it]Progress image saved at step 61 (54%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_54percent.png\n",
            " 60% 67/112 [01:50<01:09,  1.55s/it]Progress image saved at step 67 (59%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_59percent.png\n",
            " 64% 72/112 [01:59<01:03,  1.59s/it]Progress image saved at step 72 (64%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_64percent.png\n",
            " 70% 78/112 [02:09<00:53,  1.56s/it]Progress image saved at step 78 (69%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_69percent.png\n",
            " 75% 84/112 [02:20<00:43,  1.57s/it]Progress image saved at step 84 (75%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            " 79% 89/112 [02:29<00:37,  1.61s/it]Progress image saved at step 89 (79%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_79percent.png\n",
            " 85% 95/112 [02:39<00:26,  1.58s/it]Progress image saved at step 95 (84%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_84percent.png\n",
            " 89% 100/112 [02:48<00:19,  1.64s/it]Progress image saved at step 100 (89%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_89percent.png\n",
            " 95% 106/112 [02:59<00:09,  1.61s/it]Progress image saved at step 106 (94%): ./outputs/20231205141500_8to8_1705830063/20231205141500_8to8_normal_stride16_size64_batchsize512_progress_94percent.png\n",
            "100% 112/112 [03:10<00:00,  1.70s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 8 --end_idx 8 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q24IMXrQZQYP"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 8 --end_idx 8 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9012qV3ZQZ-"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 24 --end_idx 24 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGkYLfkAZQil"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 26 --end_idx 26 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Wc0hmUi7OlI",
        "outputId": "e900d2ba-be81-4889-f698-5108d5039d28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: inference_v22_normal.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                               [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                               [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                               [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v22_normal.py: error: unrecognized arguments: -size 128\n"
          ]
        }
      ],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 50 --end_idx 50 --stride 8 -size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uyc90nbLTOOU"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 42 --end_idx 54 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0Vocc6wO7CQ"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 28 --end_idx 30 --stride 8 --size 64\n",
        "#!python inference_v22_reversed.py --reverse 1 --segment_id 20231205141500 --start_idx 00 --end_idx 00 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Brdu2OgHO7Er",
        "outputId": "b2858f09-5f4b-42b5-ce7a-02793b1792af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/112 [00:03<06:03,  3.28s/it]Progress image saved at step 1 (0%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            "  4% 5/112 [00:10<03:08,  1.76s/it]Progress image saved at step 5 (4%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_4percent.png\n",
            " 10% 11/112 [00:19<02:37,  1.56s/it]Progress image saved at step 11 (9%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_9percent.png\n",
            " 14% 16/112 [00:27<02:30,  1.57s/it]Progress image saved at step 16 (14%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_14percent.png\n",
            " 20% 22/112 [00:37<02:20,  1.56s/it]Progress image saved at step 22 (19%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_19percent.png\n",
            " 25% 28/112 [00:47<02:12,  1.58s/it]Progress image saved at step 28 (25%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 29% 33/112 [00:55<02:05,  1.59s/it]Progress image saved at step 33 (29%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_29percent.png\n",
            " 35% 39/112 [01:05<01:54,  1.57s/it]Progress image saved at step 39 (34%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_34percent.png\n",
            " 39% 44/112 [01:14<01:48,  1.59s/it]Progress image saved at step 44 (39%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_39percent.png\n",
            " 45% 50/112 [01:24<01:37,  1.58s/it]Progress image saved at step 50 (44%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_44percent.png\n",
            " 50% 56/112 [01:34<01:28,  1.58s/it]Progress image saved at step 56 (50%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 54% 61/112 [01:43<01:21,  1.60s/it]Progress image saved at step 61 (54%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_54percent.png\n",
            " 60% 67/112 [01:53<01:11,  1.58s/it]Progress image saved at step 67 (59%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_59percent.png\n",
            " 64% 72/112 [02:02<01:04,  1.62s/it]Progress image saved at step 72 (64%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_64percent.png\n",
            " 70% 78/112 [02:12<00:54,  1.59s/it]Progress image saved at step 78 (69%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_69percent.png\n",
            " 75% 84/112 [02:23<00:44,  1.61s/it]Progress image saved at step 84 (75%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            " 79% 89/112 [02:32<00:37,  1.64s/it]Progress image saved at step 89 (79%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_79percent.png\n",
            " 85% 95/112 [02:42<00:27,  1.61s/it]Progress image saved at step 95 (84%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_84percent.png\n",
            " 89% 100/112 [02:51<00:19,  1.65s/it]Progress image saved at step 100 (89%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_89percent.png\n",
            " 95% 106/112 [03:02<00:09,  1.62s/it]Progress image saved at step 106 (94%): ./outputs/20231205141500_42to44_1705748263/20231205141500_42to44_normal_stride16_size64_batchsize512_progress_94percent.png\n",
            "100% 112/112 [03:12<00:00,  1.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 42 --end_idx 44 --stride 16 --size 64\n",
        "#!python inference_v22_reversed.py --reverse 1 --segment_id 20231205141500 --start_idx 00 --end_idx 00 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cJCLZtVO7G7",
        "outputId": "6e6775f2-dff7-4338-b62e-f1e54f0d29f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/112 [00:02<05:21,  2.89s/it]Progress image saved at step 1 (0%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            "  4% 5/112 [00:09<03:05,  1.74s/it]Progress image saved at step 5 (4%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_4percent.png\n",
            " 10% 11/112 [00:19<02:37,  1.56s/it]Progress image saved at step 11 (9%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_9percent.png\n",
            " 14% 16/112 [00:27<02:29,  1.56s/it]Progress image saved at step 16 (14%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_14percent.png\n",
            " 20% 22/112 [00:37<02:20,  1.56s/it]Progress image saved at step 22 (19%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_19percent.png\n",
            " 25% 28/112 [00:47<02:11,  1.57s/it]Progress image saved at step 28 (25%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 29% 33/112 [00:55<02:05,  1.59s/it]Progress image saved at step 33 (29%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_29percent.png\n",
            " 35% 39/112 [01:05<01:54,  1.57s/it]Progress image saved at step 39 (34%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_34percent.png\n",
            " 39% 44/112 [01:14<01:48,  1.60s/it]Progress image saved at step 44 (39%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_39percent.png\n",
            " 45% 50/112 [01:24<01:38,  1.59s/it]Progress image saved at step 50 (44%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_44percent.png\n",
            " 50% 56/112 [01:34<01:28,  1.58s/it]Progress image saved at step 56 (50%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 54% 61/112 [01:43<01:21,  1.61s/it]Progress image saved at step 61 (54%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_54percent.png\n",
            " 60% 67/112 [01:53<01:11,  1.59s/it]Progress image saved at step 67 (59%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_59percent.png\n",
            " 64% 72/112 [02:02<01:04,  1.62s/it]Progress image saved at step 72 (64%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_64percent.png\n",
            " 70% 78/112 [02:12<00:54,  1.60s/it]Progress image saved at step 78 (69%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_69percent.png\n",
            " 75% 84/112 [02:23<00:44,  1.60s/it]Progress image saved at step 84 (75%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            " 79% 89/112 [02:32<00:37,  1.64s/it]Progress image saved at step 89 (79%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_79percent.png\n",
            " 85% 95/112 [02:42<00:27,  1.61s/it]Progress image saved at step 95 (84%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_84percent.png\n",
            " 89% 100/112 [02:51<00:19,  1.64s/it]Progress image saved at step 100 (89%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_89percent.png\n",
            " 95% 106/112 [03:02<00:09,  1.61s/it]Progress image saved at step 106 (94%): ./outputs/20231205141500_8to11_1705748473/20231205141500_8to11_normal_stride16_size64_batchsize512_progress_94percent.png\n",
            "100% 112/112 [03:12<00:00,  1.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 8 --end_idx 11 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QPEfgq4_wbw",
        "outputId": "3ddbd353-2129-4dd9-d4a6-b618ad8cbe6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/112 [00:03<06:26,  3.48s/it]Progress image saved at step 1 (0%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            "  4% 5/112 [00:10<03:10,  1.78s/it]Progress image saved at step 5 (4%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_4percent.png\n",
            " 10% 11/112 [00:19<02:38,  1.57s/it]Progress image saved at step 11 (9%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_9percent.png\n",
            " 14% 16/112 [00:28<02:30,  1.57s/it]Progress image saved at step 16 (14%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_14percent.png\n",
            " 20% 22/112 [00:37<02:21,  1.57s/it]Progress image saved at step 22 (19%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_19percent.png\n",
            " 25% 28/112 [00:47<02:12,  1.58s/it]Progress image saved at step 28 (25%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 29% 33/112 [00:56<02:05,  1.59s/it]Progress image saved at step 33 (29%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_29percent.png\n",
            " 35% 39/112 [01:06<01:54,  1.57s/it]Progress image saved at step 39 (34%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_34percent.png\n",
            " 39% 44/112 [01:14<01:48,  1.59s/it]Progress image saved at step 44 (39%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_39percent.png\n",
            " 45% 50/112 [01:24<01:37,  1.57s/it]Progress image saved at step 50 (44%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_44percent.png\n",
            " 50% 56/112 [01:34<01:28,  1.58s/it]Progress image saved at step 56 (50%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 54% 61/112 [01:43<01:21,  1.60s/it]Progress image saved at step 61 (54%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_54percent.png\n",
            " 60% 67/112 [01:53<01:11,  1.59s/it]Progress image saved at step 67 (59%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_59percent.png\n",
            " 64% 72/112 [02:02<01:05,  1.63s/it]Progress image saved at step 72 (64%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_64percent.png\n",
            " 70% 78/112 [02:13<00:54,  1.60s/it]Progress image saved at step 78 (69%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_69percent.png\n",
            " 75% 84/112 [02:23<00:44,  1.60s/it]Progress image saved at step 84 (75%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            " 79% 89/112 [02:32<00:37,  1.64s/it]Progress image saved at step 89 (79%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_79percent.png\n",
            " 85% 95/112 [02:43<00:27,  1.61s/it]Progress image saved at step 95 (84%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_84percent.png\n",
            " 89% 100/112 [02:52<00:19,  1.65s/it]Progress image saved at step 100 (89%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_89percent.png\n",
            " 95% 106/112 [03:03<00:09,  1.61s/it]Progress image saved at step 106 (94%): ./outputs/20231205141500_4to10_1705748699/20231205141500_4to10_normal_stride16_size64_batchsize512_progress_94percent.png\n",
            "100% 112/112 [03:13<00:00,  1.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 4 --end_idx 10 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkjYA4lH_wek",
        "outputId": "cd46e1bf-a221-41d0-f05f-e3e7e18939da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/112 [00:03<06:18,  3.41s/it]Progress image saved at step 1 (0%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            "  4% 5/112 [00:10<03:19,  1.87s/it]Progress image saved at step 5 (4%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_4percent.png\n",
            " 10% 11/112 [00:20<02:48,  1.67s/it]Progress image saved at step 11 (9%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_9percent.png\n",
            " 14% 16/112 [00:29<02:41,  1.68s/it]Progress image saved at step 16 (14%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_14percent.png\n",
            " 20% 22/112 [00:40<02:30,  1.68s/it]Progress image saved at step 22 (19%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_19percent.png\n",
            " 25% 28/112 [00:50<02:19,  1.67s/it]Progress image saved at step 28 (25%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 29% 33/112 [00:59<02:11,  1.67s/it]Progress image saved at step 33 (29%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_29percent.png\n",
            " 35% 39/112 [01:09<02:00,  1.64s/it]Progress image saved at step 39 (34%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_34percent.png\n",
            " 39% 44/112 [01:18<01:53,  1.67s/it]Progress image saved at step 44 (39%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_39percent.png\n",
            " 45% 50/112 [01:29<01:42,  1.65s/it]Progress image saved at step 50 (44%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_44percent.png\n",
            " 50% 56/112 [01:39<01:33,  1.66s/it]Progress image saved at step 56 (50%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 54% 61/112 [01:49<01:26,  1.70s/it]Progress image saved at step 61 (54%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_54percent.png\n",
            " 60% 67/112 [02:00<01:15,  1.69s/it]Progress image saved at step 67 (59%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_59percent.png\n",
            " 64% 72/112 [02:09<01:08,  1.72s/it]Progress image saved at step 72 (64%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_64percent.png\n",
            " 70% 78/112 [02:20<00:57,  1.68s/it]Progress image saved at step 78 (69%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_69percent.png\n",
            " 75% 84/112 [02:31<00:46,  1.68s/it]Progress image saved at step 84 (75%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            " 79% 89/112 [02:40<00:39,  1.72s/it]Progress image saved at step 89 (79%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_79percent.png\n",
            " 85% 95/112 [02:52<00:28,  1.69s/it]Progress image saved at step 95 (84%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_84percent.png\n",
            " 89% 100/112 [03:01<00:20,  1.73s/it]Progress image saved at step 100 (89%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_89percent.png\n",
            " 95% 106/112 [03:13<00:10,  1.70s/it]Progress image saved at step 106 (94%): ./outputs/20231205141500_18to22_1705673057/20231205141500_18to22_normal_stride16_size64_batchsize512_progress_94percent.png\n",
            "100% 112/112 [03:23<00:00,  1.82s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 18 --end_idx 22 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y13PUBUF_whY",
        "outputId": "a66ee9ae-71c9-489d-ff17-de043a143ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/112 [00:03<06:23,  3.46s/it]Progress image saved at step 1 (0%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            "  4% 5/112 [00:10<03:18,  1.86s/it]Progress image saved at step 5 (4%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_4percent.png\n",
            " 10% 11/112 [00:20<02:47,  1.66s/it]Progress image saved at step 11 (9%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_9percent.png\n",
            " 14% 16/112 [00:29<02:41,  1.69s/it]Progress image saved at step 16 (14%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_14percent.png\n",
            " 20% 22/112 [00:40<02:31,  1.68s/it]Progress image saved at step 22 (19%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_19percent.png\n",
            " 25% 28/112 [00:50<02:20,  1.67s/it]Progress image saved at step 28 (25%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 29% 33/112 [00:59<02:12,  1.68s/it]Progress image saved at step 33 (29%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_29percent.png\n",
            " 35% 39/112 [01:10<02:00,  1.65s/it]Progress image saved at step 39 (34%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_34percent.png\n",
            " 39% 44/112 [01:18<01:53,  1.66s/it]Progress image saved at step 44 (39%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_39percent.png\n",
            " 45% 50/112 [01:29<01:42,  1.66s/it]Progress image saved at step 50 (44%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_44percent.png\n",
            " 50% 56/112 [01:40<01:32,  1.66s/it]Progress image saved at step 56 (50%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 54% 61/112 [01:49<01:26,  1.70s/it]Progress image saved at step 61 (54%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_54percent.png\n",
            " 60% 67/112 [02:00<01:15,  1.68s/it]Progress image saved at step 67 (59%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_59percent.png\n",
            " 64% 72/112 [02:09<01:08,  1.71s/it]Progress image saved at step 72 (64%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_64percent.png\n",
            " 70% 78/112 [02:20<00:57,  1.68s/it]Progress image saved at step 78 (69%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_69percent.png\n",
            " 75% 84/112 [02:31<00:47,  1.68s/it]Progress image saved at step 84 (75%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            " 79% 89/112 [02:41<00:39,  1.72s/it]Progress image saved at step 89 (79%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_79percent.png\n",
            " 85% 95/112 [02:52<00:28,  1.69s/it]Progress image saved at step 95 (84%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_84percent.png\n",
            " 89% 100/112 [03:01<00:20,  1.73s/it]Progress image saved at step 100 (89%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_89percent.png\n",
            " 95% 106/112 [03:13<00:10,  1.70s/it]Progress image saved at step 106 (94%): ./outputs/20231205141500_38to44_1705673278/20231205141500_38to44_normal_stride16_size64_batchsize512_progress_94percent.png\n",
            "100% 112/112 [03:23<00:00,  1.82s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 38 --end_idx 44 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htzoOYaU_wj0",
        "outputId": "ed300385-158c-4343-d2db-b367ffecaccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/112 [00:03<06:03,  3.27s/it]Progress image saved at step 1 (0%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            "  4% 5/112 [00:10<03:18,  1.86s/it]Progress image saved at step 5 (4%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_4percent.png\n",
            " 10% 11/112 [00:20<02:47,  1.66s/it]Progress image saved at step 11 (9%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_9percent.png\n",
            " 14% 16/112 [00:29<02:40,  1.67s/it]Progress image saved at step 16 (14%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_14percent.png\n",
            " 20% 22/112 [00:40<02:31,  1.68s/it]Progress image saved at step 22 (19%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_19percent.png\n",
            " 25% 28/112 [00:50<02:19,  1.67s/it]Progress image saved at step 28 (25%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 29% 33/112 [00:59<02:12,  1.67s/it]Progress image saved at step 33 (29%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_29percent.png\n",
            " 35% 39/112 [01:09<02:00,  1.65s/it]Progress image saved at step 39 (34%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_34percent.png\n",
            " 39% 44/112 [01:18<01:53,  1.66s/it]Progress image saved at step 44 (39%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_39percent.png\n",
            " 45% 50/112 [01:29<01:42,  1.65s/it]Progress image saved at step 50 (44%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_44percent.png\n",
            " 50% 56/112 [01:39<01:33,  1.67s/it]Progress image saved at step 56 (50%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 54% 61/112 [01:49<01:27,  1.71s/it]Progress image saved at step 61 (54%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_54percent.png\n",
            " 60% 67/112 [02:00<01:15,  1.69s/it]Progress image saved at step 67 (59%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_59percent.png\n",
            " 64% 72/112 [02:09<01:08,  1.72s/it]Progress image saved at step 72 (64%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_64percent.png\n",
            " 70% 78/112 [02:20<00:57,  1.69s/it]Progress image saved at step 78 (69%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_69percent.png\n",
            " 75% 84/112 [02:31<00:47,  1.69s/it]Progress image saved at step 84 (75%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            " 79% 89/112 [02:41<00:39,  1.72s/it]Progress image saved at step 89 (79%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_79percent.png\n",
            " 85% 95/112 [02:52<00:28,  1.69s/it]Progress image saved at step 95 (84%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_84percent.png\n",
            " 89% 100/112 [03:01<00:20,  1.73s/it]Progress image saved at step 100 (89%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_89percent.png\n",
            " 95% 106/112 [03:13<00:10,  1.70s/it]Progress image saved at step 106 (94%): ./outputs/20231205141500_44to48_1705673499/20231205141500_44to48_normal_stride16_size64_batchsize512_progress_94percent.png\n",
            "100% 112/112 [03:23<00:00,  1.82s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 44 --end_idx 48 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktBZBEf7_9ou",
        "outputId": "93cf020f-4c60-464b-9b91-bf6075597521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 1/112 [00:03<06:53,  3.72s/it]Progress image saved at step 1 (0%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            "  4% 5/112 [00:10<03:20,  1.88s/it]Progress image saved at step 5 (4%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_4percent.png\n",
            " 10% 11/112 [00:21<02:48,  1.67s/it]Progress image saved at step 11 (9%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_9percent.png\n",
            " 14% 16/112 [00:29<02:41,  1.68s/it]Progress image saved at step 16 (14%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_14percent.png\n",
            " 20% 22/112 [00:40<02:30,  1.67s/it]Progress image saved at step 22 (19%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_19percent.png\n",
            " 25% 28/112 [00:50<02:18,  1.65s/it]Progress image saved at step 28 (25%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 29% 33/112 [00:59<02:11,  1.66s/it]Progress image saved at step 33 (29%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_29percent.png\n",
            " 35% 39/112 [01:09<01:59,  1.64s/it]Progress image saved at step 39 (34%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_34percent.png\n",
            " 39% 44/112 [01:18<01:53,  1.67s/it]Progress image saved at step 44 (39%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_39percent.png\n",
            " 45% 50/112 [01:29<01:42,  1.66s/it]Progress image saved at step 50 (44%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_44percent.png\n",
            " 50% 56/112 [01:40<01:33,  1.66s/it]Progress image saved at step 56 (50%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 54% 61/112 [01:49<01:26,  1.70s/it]Progress image saved at step 61 (54%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_54percent.png\n",
            " 60% 67/112 [02:00<01:16,  1.69s/it]Progress image saved at step 67 (59%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_59percent.png\n",
            " 64% 72/112 [02:09<01:08,  1.72s/it]Progress image saved at step 72 (64%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_64percent.png\n",
            " 70% 78/112 [02:20<00:57,  1.68s/it]Progress image saved at step 78 (69%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_69percent.png\n",
            " 75% 84/112 [02:31<00:47,  1.68s/it]Progress image saved at step 84 (75%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            " 79% 89/112 [02:41<00:39,  1.72s/it]Progress image saved at step 89 (79%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_79percent.png\n",
            " 85% 95/112 [02:52<00:28,  1.69s/it]Progress image saved at step 95 (84%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_84percent.png\n",
            " 89% 100/112 [03:01<00:20,  1.74s/it]Progress image saved at step 100 (89%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_89percent.png\n",
            " 95% 106/112 [03:13<00:10,  1.71s/it]Progress image saved at step 106 (94%): ./outputs/20231205141500_49to54_1705673721/20231205141500_49to54_normal_stride16_size64_batchsize512_progress_94percent.png\n",
            "100% 112/112 [03:23<00:00,  1.82s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 49 --end_idx 54 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IemlPr9jZ7QK"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 02 --end_idx 03 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20231205141500 --start_idx 02 --end_idx 03 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi64nJ3DcZC0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FciyDmpZ7Sj",
        "outputId": "3031b1f8-1db4-4a56-d00b-c67e1c6b3373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "[ WARN:0@4.781] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20231205141500/layers/65.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v22_normal.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v22_normal.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v22_normal.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 53 --end_idx 54 --stride 16 --size 64\n",
        "#!python inference_v22_reversed.py --reverse 1 --segment_id 20231205141500 --start_idx 53 --end_idx 60 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6D9xXfCPZ7Uq"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 28 --end_idx 29 --stride 16 --size 64\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20231205141500 --start_idx 28 --end_idx 29 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzlK-mofZ7XL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OQPqIXMZ7Za"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 28 --end_idx 36 --stride 16 --size 64\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20231205141500 --start_idx 28 --end_idx 36 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSlevCvFRegW"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231206155550 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20231206155550 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCCnkDOV1ELK",
        "outputId": "f7dc9f0c-8f3b-4941-bff4-1c95e50650f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/35 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_0percent.png\n",
            "  3% 1/35 [00:01<01:00,  1.78s/it]Progress image saved at step 1 (2%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_2percent.png\n",
            "  9% 3/35 [00:03<00:30,  1.04it/s]Progress image saved at step 3 (8%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_8percent.png\n",
            " 14% 5/35 [00:04<00:24,  1.21it/s]Progress image saved at step 5 (14%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_14percent.png\n",
            " 20% 7/35 [00:06<00:21,  1.27it/s]Progress image saved at step 7 (20%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_20percent.png\n",
            " 23% 8/35 [00:07<00:22,  1.20it/s]Progress image saved at step 8 (22%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_22percent.png\n",
            " 29% 10/35 [00:08<00:20,  1.25it/s]Progress image saved at step 10 (28%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_28percent.png\n",
            " 34% 12/35 [00:10<00:18,  1.26it/s]Progress image saved at step 12 (34%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_34percent.png\n",
            " 40% 14/35 [00:12<00:16,  1.25it/s]Progress image saved at step 14 (40%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_40percent.png\n",
            " 43% 15/35 [00:13<00:17,  1.15it/s]Progress image saved at step 15 (42%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_42percent.png\n",
            " 49% 17/35 [00:14<00:15,  1.19it/s]Progress image saved at step 17 (48%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_48percent.png\n",
            " 54% 19/35 [00:16<00:13,  1.20it/s]Progress image saved at step 19 (54%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_54percent.png\n",
            " 60% 21/35 [00:18<00:11,  1.20it/s]Progress image saved at step 21 (60%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_60percent.png\n",
            " 63% 22/35 [00:19<00:11,  1.09it/s]Progress image saved at step 22 (62%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_62percent.png\n",
            " 69% 24/35 [00:21<00:09,  1.13it/s]Progress image saved at step 24 (68%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_68percent.png\n",
            " 74% 26/35 [00:23<00:07,  1.15it/s]Progress image saved at step 26 (74%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_74percent.png\n",
            " 80% 28/35 [00:24<00:06,  1.14it/s]Progress image saved at step 28 (80%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_80percent.png\n",
            " 83% 29/35 [00:26<00:05,  1.02it/s]Progress image saved at step 29 (82%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_82percent.png\n",
            " 89% 31/35 [00:28<00:03,  1.06it/s]Progress image saved at step 31 (88%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_88percent.png\n",
            " 94% 33/35 [00:29<00:01,  1.08it/s]Progress image saved at step 33 (94%): ./outputs/20231206155550_20to50_1705669985/20231206155550_20to50_normal_stride16_size32_batchsize512_progress_94percent.png\n",
            "100% 35/35 [00:31<00:00,  1.10it/s]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeLCp-NO1ENz",
        "outputId": "287d5c21-f45b-44cb-98f7-2df0a7c3ffeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/35 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_0percent.png\n",
            "  3% 1/35 [00:01<01:00,  1.79s/it]Progress image saved at step 1 (2%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_2percent.png\n",
            "  9% 3/35 [00:03<00:31,  1.03it/s]Progress image saved at step 3 (8%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_8percent.png\n",
            " 14% 5/35 [00:04<00:24,  1.20it/s]Progress image saved at step 5 (14%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_14percent.png\n",
            " 20% 7/35 [00:06<00:22,  1.27it/s]Progress image saved at step 7 (20%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_20percent.png\n",
            " 23% 8/35 [00:07<00:22,  1.21it/s]Progress image saved at step 8 (22%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_22percent.png\n",
            " 29% 10/35 [00:08<00:19,  1.25it/s]Progress image saved at step 10 (28%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_28percent.png\n",
            " 34% 12/35 [00:10<00:18,  1.27it/s]Progress image saved at step 12 (34%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_34percent.png\n",
            " 40% 14/35 [00:12<00:16,  1.26it/s]Progress image saved at step 14 (40%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_40percent.png\n",
            " 43% 15/35 [00:13<00:17,  1.16it/s]Progress image saved at step 15 (42%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_42percent.png\n",
            " 49% 17/35 [00:14<00:15,  1.19it/s]Progress image saved at step 17 (48%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_48percent.png\n",
            " 54% 19/35 [00:16<00:13,  1.20it/s]Progress image saved at step 19 (54%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_54percent.png\n",
            " 60% 21/35 [00:18<00:11,  1.20it/s]Progress image saved at step 21 (60%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_60percent.png\n",
            " 63% 22/35 [00:19<00:11,  1.08it/s]Progress image saved at step 22 (62%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_62percent.png\n",
            " 69% 24/35 [00:21<00:09,  1.12it/s]Progress image saved at step 24 (68%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_68percent.png\n",
            " 74% 26/35 [00:23<00:07,  1.13it/s]Progress image saved at step 26 (74%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_74percent.png\n",
            " 80% 28/35 [00:24<00:06,  1.13it/s]Progress image saved at step 28 (80%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_80percent.png\n",
            " 83% 29/35 [00:26<00:05,  1.02it/s]Progress image saved at step 29 (82%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_82percent.png\n",
            " 89% 31/35 [00:28<00:03,  1.06it/s]Progress image saved at step 31 (88%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_88percent.png\n",
            " 94% 33/35 [00:30<00:01,  1.07it/s]Progress image saved at step 33 (94%): ./outputs/20231206155550_29to33_1705669941/20231206155550_29to33_normal_stride16_size32_batchsize512_progress_94percent.png\n",
            "100% 35/35 [00:32<00:00,  1.09it/s]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg2OB8SI1EQq",
        "outputId": "c2ba91db-cb83-4d49-bb71-5d33bd486ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/35 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_0percent.png\n",
            "  3% 1/35 [00:01<01:05,  1.93s/it]Progress image saved at step 1 (2%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_2percent.png\n",
            "  9% 3/35 [00:03<00:32,  1.01s/it]Progress image saved at step 3 (8%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_8percent.png\n",
            " 14% 5/35 [00:04<00:25,  1.18it/s]Progress image saved at step 5 (14%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_14percent.png\n",
            " 20% 7/35 [00:06<00:22,  1.25it/s]Progress image saved at step 7 (20%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_20percent.png\n",
            " 23% 8/35 [00:07<00:22,  1.19it/s]Progress image saved at step 8 (22%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_22percent.png\n",
            " 29% 10/35 [00:09<00:20,  1.24it/s]Progress image saved at step 10 (28%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_28percent.png\n",
            " 34% 12/35 [00:10<00:18,  1.25it/s]Progress image saved at step 12 (34%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_34percent.png\n",
            " 40% 14/35 [00:12<00:16,  1.24it/s]Progress image saved at step 14 (40%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_40percent.png\n",
            " 43% 15/35 [00:13<00:17,  1.15it/s]Progress image saved at step 15 (42%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_42percent.png\n",
            " 49% 17/35 [00:15<00:15,  1.19it/s]Progress image saved at step 17 (48%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_48percent.png\n",
            " 54% 19/35 [00:16<00:13,  1.19it/s]Progress image saved at step 19 (54%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_54percent.png\n",
            " 60% 21/35 [00:18<00:11,  1.19it/s]Progress image saved at step 21 (60%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_60percent.png\n",
            " 63% 22/35 [00:19<00:12,  1.08it/s]Progress image saved at step 22 (62%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_62percent.png\n",
            " 69% 24/35 [00:21<00:09,  1.12it/s]Progress image saved at step 24 (68%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_68percent.png\n",
            " 74% 26/35 [00:23<00:07,  1.13it/s]Progress image saved at step 26 (74%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_74percent.png\n",
            " 80% 28/35 [00:25<00:06,  1.13it/s]Progress image saved at step 28 (80%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_80percent.png\n",
            " 83% 29/35 [00:26<00:05,  1.01it/s]Progress image saved at step 29 (82%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_82percent.png\n",
            " 89% 31/35 [00:28<00:03,  1.06it/s]Progress image saved at step 31 (88%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_88percent.png\n",
            " 94% 33/35 [00:30<00:01,  1.08it/s]Progress image saved at step 33 (94%): ./outputs/20231206155550_12to21_1705669895/20231206155550_12to21_normal_stride16_size32_batchsize512_progress_94percent.png\n",
            "100% 35/35 [00:32<00:00,  1.08it/s]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwDRumGDwPOc",
        "outputId": "ddf4032e-1cac-4493-cc5d-1af6a1f1e643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/35 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_0percent.png\n",
            "  3% 1/35 [00:01<01:01,  1.80s/it]Progress image saved at step 1 (2%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_2percent.png\n",
            "  9% 3/35 [00:03<00:31,  1.03it/s]Progress image saved at step 3 (8%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_8percent.png\n",
            " 14% 5/35 [00:04<00:25,  1.20it/s]Progress image saved at step 5 (14%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_14percent.png\n",
            " 20% 7/35 [00:06<00:22,  1.27it/s]Progress image saved at step 7 (20%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_20percent.png\n",
            " 23% 8/35 [00:07<00:22,  1.20it/s]Progress image saved at step 8 (22%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_22percent.png\n",
            " 29% 10/35 [00:08<00:19,  1.26it/s]Progress image saved at step 10 (28%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_28percent.png\n",
            " 34% 12/35 [00:10<00:18,  1.27it/s]Progress image saved at step 12 (34%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_34percent.png\n",
            " 40% 14/35 [00:12<00:16,  1.27it/s]Progress image saved at step 14 (40%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_40percent.png\n",
            " 43% 15/35 [00:13<00:17,  1.16it/s]Progress image saved at step 15 (42%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_42percent.png\n",
            " 49% 17/35 [00:14<00:15,  1.19it/s]Progress image saved at step 17 (48%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_48percent.png\n",
            " 54% 19/35 [00:16<00:13,  1.20it/s]Progress image saved at step 19 (54%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_54percent.png\n",
            " 60% 21/35 [00:18<00:11,  1.19it/s]Progress image saved at step 21 (60%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_60percent.png\n",
            " 63% 22/35 [00:19<00:11,  1.08it/s]Progress image saved at step 22 (62%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_62percent.png\n",
            " 69% 24/35 [00:21<00:09,  1.13it/s]Progress image saved at step 24 (68%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_68percent.png\n",
            " 74% 26/35 [00:23<00:07,  1.14it/s]Progress image saved at step 26 (74%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_74percent.png\n",
            " 80% 28/35 [00:24<00:06,  1.14it/s]Progress image saved at step 28 (80%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_80percent.png\n",
            " 83% 29/35 [00:26<00:05,  1.01it/s]Progress image saved at step 29 (82%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_82percent.png\n",
            " 89% 31/35 [00:28<00:03,  1.06it/s]Progress image saved at step 31 (88%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_88percent.png\n",
            " 94% 33/35 [00:30<00:01,  1.07it/s]Progress image saved at step 33 (94%): ./outputs/20231206155550_20to26_1705669850/20231206155550_20to26_normal_stride16_size32_batchsize512_progress_94percent.png\n",
            "100% 35/35 [00:32<00:00,  1.09it/s]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eFNR-F9RUyl",
        "outputId": "1443cebb-56cd-460a-9262-8e0ee5715ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/9 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231206155550_6to9_1705663793/20231206155550_6to9_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 11% 1/9 [00:03<00:30,  3.86s/it]Progress image saved at step 1 (11%): ./outputs/20231206155550_6to9_1705663793/20231206155550_6to9_normal_stride32_size64_batchsize512_progress_11percent.png\n",
            " 22% 2/9 [00:05<00:18,  2.66s/it]Progress image saved at step 2 (22%): ./outputs/20231206155550_6to9_1705663793/20231206155550_6to9_normal_stride32_size64_batchsize512_progress_22percent.png\n",
            " 33% 3/9 [00:07<00:13,  2.31s/it]Progress image saved at step 3 (33%): ./outputs/20231206155550_6to9_1705663793/20231206155550_6to9_normal_stride32_size64_batchsize512_progress_33percent.png\n",
            " 44% 4/9 [00:09<00:10,  2.16s/it]Progress image saved at step 4 (44%): ./outputs/20231206155550_6to9_1705663793/20231206155550_6to9_normal_stride32_size64_batchsize512_progress_44percent.png\n",
            " 56% 5/9 [00:11<00:08,  2.10s/it]Progress image saved at step 5 (55%): ./outputs/20231206155550_6to9_1705663793/20231206155550_6to9_normal_stride32_size64_batchsize512_progress_55percent.png\n",
            " 67% 6/9 [00:13<00:06,  2.10s/it]Progress image saved at step 6 (66%): ./outputs/20231206155550_6to9_1705663793/20231206155550_6to9_normal_stride32_size64_batchsize512_progress_66percent.png\n",
            " 78% 7/9 [00:15<00:04,  2.11s/it]Progress image saved at step 7 (77%): ./outputs/20231206155550_6to9_1705663793/20231206155550_6to9_normal_stride32_size64_batchsize512_progress_77percent.png\n",
            " 89% 8/9 [00:17<00:02,  2.14s/it]Progress image saved at step 8 (88%): ./outputs/20231206155550_6to9_1705663793/20231206155550_6to9_normal_stride32_size64_batchsize512_progress_88percent.png\n",
            "100% 9/9 [00:19<00:00,  2.14s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231206155550 --start_idx 06 --end_idx 09 --stride 32 --size 64\n",
        "#!python inference_v22_reversed.py --reverse 1 --segment_id 20231206155550--start_idx 00 --end_idx 00 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ujOi2AvwOE8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzu9JmI37QdB"
      },
      "source": [
        "#scroll 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfy2KTaMIf3D",
        "outputId": "0c0dbc8b-fe85-459d-ed62-7ec22b3e9704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/A_Scroll/inkception-3d\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pBLXbNrXJfg",
        "outputId": "151c9cf6-d987-4aba-e8cc-9900daa26019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 4/406 [00:03<04:56,  1.36it/s]Progress image saved at step 4 (0%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_0percent.png\n",
            "  5% 20/406 [00:28<04:02,  1.59it/s]Progress image saved at step 20 (4%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_4percent.png\n",
            " 10% 40/406 [00:49<03:46,  1.61it/s]Progress image saved at step 40 (9%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_9percent.png\n",
            " 15% 60/406 [01:11<03:34,  1.61it/s]Progress image saved at step 60 (14%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_14percent.png\n",
            " 20% 81/406 [01:34<03:24,  1.59it/s]Progress image saved at step 81 (19%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_19percent.png\n",
            " 25% 101/406 [01:59<03:12,  1.59it/s]Progress image saved at step 101 (24%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_24percent.png\n",
            " 30% 121/406 [02:24<03:02,  1.56it/s]Progress image saved at step 121 (29%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_29percent.png\n",
            " 35% 142/406 [02:51<02:50,  1.55it/s]Progress image saved at step 142 (34%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_34percent.png\n",
            " 40% 162/406 [03:19<02:39,  1.53it/s]Progress image saved at step 162 (39%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_39percent.png\n",
            " 45% 182/406 [03:48<02:26,  1.53it/s]Progress image saved at step 182 (44%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_44percent.png\n",
            " 50% 203/406 [04:19<02:14,  1.51it/s]Progress image saved at step 203 (50%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_50percent.png\n",
            " 55% 223/406 [04:50<02:01,  1.51it/s]Progress image saved at step 223 (54%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_54percent.png\n",
            " 60% 243/406 [05:23<01:47,  1.51it/s]Progress image saved at step 243 (59%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_59percent.png\n",
            " 65% 263/406 [05:57<01:35,  1.50it/s]Progress image saved at step 263 (64%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_64percent.png\n",
            " 70% 284/406 [06:32<01:20,  1.51it/s]Progress image saved at step 284 (69%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_69percent.png\n",
            " 75% 304/406 [07:09<01:07,  1.51it/s]Progress image saved at step 304 (74%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_74percent.png\n",
            " 80% 324/406 [07:46<00:54,  1.50it/s]Progress image saved at step 324 (79%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_79percent.png\n",
            " 85% 345/406 [08:25<00:40,  1.51it/s]Progress image saved at step 345 (84%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_84percent.png\n",
            " 90% 365/406 [09:05<00:27,  1.51it/s]Progress image saved at step 365 (89%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_89percent.png\n",
            " 95% 385/406 [09:46<00:14,  1.49it/s]Progress image saved at step 385 (94%): ./outputs/20231111135340_30to30_1711951760/20231111135340_30to30_stride32_size32_batchsize512_progress_94percent.png\n",
            "100% 406/406 [10:28<00:00,  1.55s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v12.py --reverse 0 --segment_id 20231111135340 --start_idx 30 --end_idx 30 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "#!python inference_v12.py --reverse 1 --segment_id 20231111135340 --start_idx 36 --end_idx 36 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36bqonrT_8Ew",
        "outputId": "5b9068e1-5ac0-4ea7-c8f6-151750199841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 4/406 [00:03<05:06,  1.31it/s]Progress image saved at step 4 (0%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_0percent.png\n",
            "  5% 20/406 [00:21<04:15,  1.51it/s]Progress image saved at step 20 (4%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_4percent.png\n",
            " 10% 40/406 [00:41<04:03,  1.50it/s]Progress image saved at step 40 (9%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_9percent.png\n",
            " 15% 60/406 [01:03<03:48,  1.52it/s]Progress image saved at step 60 (14%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_14percent.png\n",
            " 20% 81/406 [01:27<03:32,  1.53it/s]Progress image saved at step 81 (19%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_19percent.png\n",
            " 25% 101/406 [01:51<03:20,  1.52it/s]Progress image saved at step 101 (24%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_24percent.png\n",
            " 30% 121/406 [02:16<03:09,  1.51it/s]Progress image saved at step 121 (29%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_29percent.png\n",
            " 35% 142/406 [02:43<02:54,  1.51it/s]Progress image saved at step 142 (34%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_34percent.png\n",
            " 40% 162/406 [03:11<02:39,  1.53it/s]Progress image saved at step 162 (39%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_39percent.png\n",
            " 45% 182/406 [03:40<02:28,  1.51it/s]Progress image saved at step 182 (44%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_44percent.png\n",
            " 50% 203/406 [04:11<02:13,  1.52it/s]Progress image saved at step 203 (50%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_50percent.png\n",
            " 55% 223/406 [04:42<02:00,  1.51it/s]Progress image saved at step 223 (54%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_54percent.png\n",
            " 60% 243/406 [05:14<01:47,  1.51it/s]Progress image saved at step 243 (59%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_59percent.png\n",
            " 65% 263/406 [05:48<01:35,  1.49it/s]Progress image saved at step 263 (64%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_64percent.png\n",
            " 70% 284/406 [06:23<01:20,  1.52it/s]Progress image saved at step 284 (69%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_69percent.png\n",
            " 75% 304/406 [06:59<01:07,  1.51it/s]Progress image saved at step 304 (74%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_74percent.png\n",
            " 80% 324/406 [07:36<00:54,  1.50it/s]Progress image saved at step 324 (79%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_79percent.png\n",
            " 85% 345/406 [08:15<00:40,  1.51it/s]Progress image saved at step 345 (84%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_84percent.png\n",
            " 90% 365/406 [08:55<00:27,  1.50it/s]Progress image saved at step 365 (89%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_89percent.png\n",
            " 95% 385/406 [09:35<00:13,  1.53it/s]Progress image saved at step 385 (94%): ./outputs/20231111135340_30to31_1711952471/20231111135340_30to31_stride32_size32_batchsize512_progress_94percent.png\n",
            "100% 406/406 [10:18<00:00,  1.52s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v12.py --reverse 0 --segment_id 20231111135340 --start_idx 50 --end_idx 50 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "#!python inference_v12.py --reverse 1 --segment_id 20231111135340 --start_idx 06 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrFjqtbxUPXw",
        "outputId": "29ab86d2-283a-4f09-d383-2ec19f7b6484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 4/406 [00:03<05:06,  1.31it/s]Progress image saved at step 4 (0%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_0percent.png\n",
            "  5% 20/406 [00:26<04:16,  1.51it/s]Progress image saved at step 20 (4%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_4percent.png\n",
            " 10% 40/406 [00:48<03:59,  1.53it/s]Progress image saved at step 40 (9%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_9percent.png\n",
            " 15% 60/406 [01:10<03:48,  1.52it/s]Progress image saved at step 60 (14%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_14percent.png\n",
            " 20% 81/406 [01:34<03:34,  1.52it/s]Progress image saved at step 81 (19%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_19percent.png\n",
            " 25% 101/406 [01:58<03:18,  1.54it/s]Progress image saved at step 101 (24%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_24percent.png\n",
            " 30% 121/406 [02:24<03:07,  1.52it/s]Progress image saved at step 121 (29%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_29percent.png\n",
            " 35% 142/406 [02:51<02:54,  1.51it/s]Progress image saved at step 142 (34%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_34percent.png\n",
            " 40% 162/406 [03:18<02:39,  1.53it/s]Progress image saved at step 162 (39%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_39percent.png\n",
            " 45% 182/406 [03:47<02:26,  1.52it/s]Progress image saved at step 182 (44%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_44percent.png\n",
            " 50% 203/406 [04:18<02:15,  1.50it/s]Progress image saved at step 203 (50%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_50percent.png\n",
            " 55% 223/406 [04:49<02:00,  1.52it/s]Progress image saved at step 223 (54%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_54percent.png\n",
            " 60% 243/406 [05:21<01:47,  1.52it/s]Progress image saved at step 243 (59%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_59percent.png\n",
            " 65% 263/406 [05:54<01:35,  1.50it/s]Progress image saved at step 263 (64%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_64percent.png\n",
            " 70% 284/406 [06:29<01:20,  1.52it/s]Progress image saved at step 284 (69%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_69percent.png\n",
            " 75% 304/406 [07:05<01:08,  1.50it/s]Progress image saved at step 304 (74%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_74percent.png\n",
            " 80% 324/406 [07:42<00:54,  1.50it/s]Progress image saved at step 324 (79%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_79percent.png\n",
            " 85% 345/406 [08:21<00:40,  1.51it/s]Progress image saved at step 345 (84%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_84percent.png\n",
            " 90% 365/406 [09:00<00:27,  1.50it/s]Progress image saved at step 365 (89%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_89percent.png\n",
            " 95% 385/406 [09:40<00:14,  1.49it/s]Progress image saved at step 385 (94%): ./outputs/20231111135340_40to40_1711953157/20231111135340_40to40_stride32_size32_batchsize512_progress_94percent.png\n",
            "100% 406/406 [10:22<00:00,  1.53s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v12.py --reverse 0 --segment_id 20231111135340 --start_idx 40 --end_idx 40 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "#!python inference_v12.py --reverse 1 --segment_id 20231111135340 --start_idx 06 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5kTREd5UPaR",
        "outputId": "e515ce87-3ab1-4d8a-bf17-95ff714cb24f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "[ WARN:0@44.188] global loadsave.cpp:248 findDecoder imread_('./eval_segments_shared/20231111135340/layers/66.tif'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v12.py\", line 680, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v12.py\", line 254, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v12.py\", line 232, in read_image_mask\n",
            "    pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python inference_v12.py --reverse 0 --segment_id 20231111135340 --start_idx 58 --end_idx 58 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "#!python inference_v12.py --reverse 1 --segment_id 20231111135340 --start_idx 06 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xlc4RAyzUPcv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k02sycA2FS0"
      },
      "source": [
        "#training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-3EtCenGXdd",
        "outputId": "74f32bef-4484-4b44-f2e5-b6014d34f0c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/A_Scroll_1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll_1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ47A1zGfwxV",
        "outputId": "d70b745c-ceb1-49a1-f212-8a41fe2ef1b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/modelmain/training/train_scrolls/valid-1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/modelmain/training/train_scrolls/valid-1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFTacJ5I8A_X",
        "outputId": "4edb413a-fd3b-46d4-c9d0-90d1cb9d6444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1rh93TVk8BxWN8wNVYp0_HeiWZcf_osdU/A_Scroll_1/Vesuvius-First-Letters\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qf2-TZyAW7h",
        "outputId": "7a666a44-25d8-4e3a-b5d7-b781950994d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "[ WARN:0@4.856] global loadsave.cpp:248 findDecoder imread_('/content/drive/MyDrive/modelmain/training/train_scrolls/valid-1/valid-1_inklabels.png'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1rh93TVk8BxWN8wNVYp0_HeiWZcf_osdU/A_Scroll_1/Vesuvius-First-Letters/64chans_training_06.py\", line 534, in <module>\n",
            "    pred_shape=valid_mask_gt.shape\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python 64chans_training_06.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqy0EImRbeC3",
        "outputId": "e0ba199c-7c54-492f-b766-84574291bd57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "[ WARN:0@2.200] global loadsave.cpp:248 findDecoder imread_('/content/gdrive/MyDrive/modelmain/training/train_scrolls/valid-1/valid-1_inklabels.png'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1rh93TVk8BxWN8wNVYp0_HeiWZcf_osdU/A_Scroll_1/Vesuvius-First-Letters/64x64_256stride_i3d.py\", line 529, in <module>\n",
            "    pred_shape=valid_mask_gt.shape\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python 64x64_256stride_i3d.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5UMnG2abeF1",
        "outputId": "a2d69f6f-7a82-4f3b-d9fa-fb3ea92ebd79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/modelmain/training/train_scrolls/valid-1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/modelmain/training/train_scrolls/valid-1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn4RzT5nAW-q",
        "outputId": "78421942-f5e5-4aaa-cbe4-56f0f139959d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/modelmain/training/train_scrolls/valid-1/'\n",
            "/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/modelmain/training/train_scrolls/valid-1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ6AV9HbFVJ0",
        "outputId": "9e65a10a-88e3-453a-c4a4-a52c4661d6df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1rh93TVk8BxWN8wNVYp0_HeiWZcf_osdU/A_Scroll_1/modelmain/training/train_scrolls/training-1/layers\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll_1/modelmain/training/train_scrolls/training-1/layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt4A76wgfw0C",
        "outputId": "b21fdde4-21d7-4330-bbe3-6730a21a5020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "reading  training-1\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "(2048, 9216)\n",
            "reading  training-3\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "(6144, 2304)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters/train_64chans_v2.py\", line 593, in <module>\n",
            "    valid_xyxys = np.stack(valid_xyxys)\n",
            "  File \"<__array_function__ internals>\", line 180, in stack\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\", line 422, in stack\n",
            "    raise ValueError('need at least one array to stack')\n",
            "ValueError: need at least one array to stack\n"
          ]
        }
      ],
      "source": [
        "!python train_64chans_v2.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "O0Zxb1PzrbUx",
        "kH9frdLTdsAZ",
        "0kdFLRsbspQW",
        "dZBxzSu_b0wA",
        "CvFrXOxdvqYL",
        "p2pxUbzs08EC",
        "X2fSEzFW2cvv",
        "bqVhd1vT2fzX",
        "lwt2Fyaam6b2",
        "pV1b7UnyjQRD",
        "N5lXWZCe8abF",
        "0eZisq_YwSXC",
        "mxuVSDFW5OND",
        "ggdb5sRmIuEC",
        "l-SCnWRtnVuv",
        "lrhgwsXpCeZp",
        "rUmAYkUFsyjd",
        "f6hUTjW-H0Iu",
        "6mhCkCfis95E",
        "QxonSavFZSSN",
        "puFca7Lrmxm0",
        "hzu9JmI37QdB",
        "8k02sycA2FS0"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}