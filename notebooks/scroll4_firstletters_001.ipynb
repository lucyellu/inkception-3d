{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb4nzBvLfZUj"
      },
      "source": [
        "#Vesuvius Scroll Challenge\n",
        "scroll 1 - pherc.paris4\n",
        "TITLE SEARCH\n",
        "\n",
        "scroll 4 - 1667\n",
        "FIRST LETTERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Zxb1PzrbUx"
      },
      "source": [
        "#set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSPmCv8aAM0k"
      },
      "source": [
        "##install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt9q1aNPezo-",
        "outputId": "1ae01fdb-9f8e-4bda-e192-f2a216299499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIsuYNU5glnV",
        "outputId": "f6ef5701-ef0f-4c23-df04-58e96b33b65d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 2,473 kB of archives.\n",
            "After this operation, 2,884 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.4 [1,680 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.1 [788 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.4 [5,712 B]\n",
            "Fetched 2,473 kB in 1s (1,659 kB/s)\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 123588 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.4_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.4) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.4) ...\n"
          ]
        }
      ],
      "source": [
        "!apt install python3.10-venv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpUxZ7R8gdXC"
      },
      "outputs": [],
      "source": [
        "!python3 -m venv ~/scroll_venv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVC-0_ClgrdZ"
      },
      "outputs": [],
      "source": [
        "!source ~/scroll_venv/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Jtwxk4NgwVL",
        "outputId": "30c9d4e7-7bb1-4585-83c7-2961cb62f197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Collecting torchio\n",
            "  Downloading torchio-0.19.9-py2.py3-none-any.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.17.5-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Collecting Deprecated (from torchio)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting SimpleITK!=2.0.*,!=2.1.1.1 (from torchio)\n",
            "  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from torchio) (4.10.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from torchio) (5.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torchio) (1.13.1)\n",
            "Requirement already satisfied: typer[all] in /usr/local/lib/python3.10/dist-packages (from torchio) (0.12.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.11.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->torchio) (1.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: typer 0.12.3 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (13.7.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer[all]->torchio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer[all]->torchio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer[all]->torchio) (0.1.2)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading torchio-0.19.9-py2.py3-none-any.whl (174 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.4/174.4 kB\u001b[0m \u001b[31m142.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.17.5-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.11.0-py2.py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.6/303.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: SimpleITK, smmap, setproctitle, sentry-sdk, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, docker-pycreds, Deprecated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gitdb, nvidia-cusolver-cu12, gitpython, wandb, torchio\n",
            "Successfully installed Deprecated-1.2.14 SimpleITK-2.3.1 docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 sentry-sdk-2.11.0 setproctitle-1.3.3 smmap-5.0.1 torchio-0.19.9 wandb-0.17.5\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision pillow torchio tqdm wandb matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coP6-9N17di_",
        "outputId": "7dd4b6d7-ffef-48e4-8f4f-66f7970450f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts imagemagick-6-common\n",
            "  imagemagick-6.q16 libdjvulibre-text libdjvulibre21 libfftw3-double3 libgs9 libgs9-common libidn12\n",
            "  libijs-0.35 libjbig2dec0 libjxr-tools libjxr0 liblqr-1-0 libmagickcore-6.q16-6\n",
            "  libmagickcore-6.q16-6-extra libmagickwand-6.q16-6 libnetpbm10 libwmflite-0.2-7 netpbm\n",
            "  poppler-data\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf fonts-texgyre ghostscript-x imagemagick-doc\n",
            "  autotrace cups-bsd | lpr | lprng enscript gimp gnuplot grads hp2xx html2ps libwmf-bin mplayer\n",
            "  povray radiance sane-utils texlive-base-bin transfig ufraw-batch libfftw3-bin libfftw3-dev\n",
            "  inkscape poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts imagemagick\n",
            "  imagemagick-6-common imagemagick-6.q16 libdjvulibre-text libdjvulibre21 libfftw3-double3 libgs9\n",
            "  libgs9-common libidn12 libijs-0.35 libjbig2dec0 libjxr-tools libjxr0 liblqr-1-0\n",
            "  libmagickcore-6.q16-6 libmagickcore-6.q16-6-extra libmagickwand-6.q16-6 libnetpbm10\n",
            "  libwmflite-0.2-7 netpbm poppler-data\n",
            "0 upgraded, 26 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 25.1 MB of archives.\n",
            "After this operation, 87.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfftw3-double3 amd64 3.3.8-2ubuntu8 [770 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6-common all 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [64.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [1,795 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickwand-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [328 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.9 [752 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.9 [5,033 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ghostscript amd64 9.55.0~dfsg1-0ubuntu5.9 [49.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.5 [3,120 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6.q16 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [224 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [14.6 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdjvulibre-text all 3.5.28-2build2 [50.9 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdjvulibre21 amd64 3.5.28-2build2 [624 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjxr0 amd64 1.2~git20170615.f752187-5 [174 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjxr-tools amd64 1.2~git20170615.f752187-5 [16.0 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwmflite-0.2-7 amd64 0.2.12-5ubuntu1 [68.9 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6-extra amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [70.1 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libnetpbm10 amd64 2:10.0-15.4 [59.1 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/universe amd64 netpbm amd64 2:10.0-15.4 [1,007 kB]\n",
            "Fetched 25.1 MB in 2s (16.1 MB/s)\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 123603 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package libfftw3-double3:amd64.\n",
            "Preparing to unpack .../01-libfftw3-double3_3.3.8-2ubuntu8_amd64.deb ...\n",
            "Unpacking libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Selecting previously unselected package liblqr-1-0:amd64.\n",
            "Preparing to unpack .../02-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n",
            "Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Selecting previously unselected package imagemagick-6-common.\n",
            "Preparing to unpack .../03-imagemagick-6-common_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_all.deb ...\n",
            "Unpacking imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6:amd64.\n",
            "Preparing to unpack .../04-libmagickcore-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickwand-6.q16-6:amd64.\n",
            "Preparing to unpack .../05-libmagickwand-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../06-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../07-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../08-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.55.0~dfsg1-0ubuntu5.9_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../10-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../11-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../12-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../13-libgs9_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../14-ghostscript_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../15-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.5_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Selecting previously unselected package imagemagick-6.q16.\n",
            "Preparing to unpack .../16-imagemagick-6.q16_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package imagemagick.\n",
            "Preparing to unpack .../17-imagemagick_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libdjvulibre-text.\n",
            "Preparing to unpack .../18-libdjvulibre-text_3.5.28-2build2_all.deb ...\n",
            "Unpacking libdjvulibre-text (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libdjvulibre21:amd64.\n",
            "Preparing to unpack .../19-libdjvulibre21_3.5.28-2build2_amd64.deb ...\n",
            "Unpacking libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libjxr0:amd64.\n",
            "Preparing to unpack .../20-libjxr0_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libjxr-tools.\n",
            "Preparing to unpack .../21-libjxr-tools_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libwmflite-0.2-7:amd64.\n",
            "Preparing to unpack .../22-libwmflite-0.2-7_0.2.12-5ubuntu1_amd64.deb ...\n",
            "Unpacking libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6-extra:amd64.\n",
            "Preparing to unpack .../23-libmagickcore-6.q16-6-extra_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libnetpbm10.\n",
            "Preparing to unpack .../24-libnetpbm10_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking libnetpbm10 (2:10.0-15.4) ...\n",
            "Selecting previously unselected package netpbm.\n",
            "Preparing to unpack .../25-netpbm_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking netpbm (2:10.0-15.4) ...\n",
            "Setting up imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Setting up libnetpbm10 (2:10.0-15.4) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up netpbm (2:10.0-15.4) ...\n",
            "Setting up libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up libdjvulibre-text (3.5.28-2build2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare (compare) in auto mode\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare-im6 (compare-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate (animate) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate-im6 (animate-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert (convert) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert-im6 (convert-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite (composite) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite-im6 (composite-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure (conjure) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure-im6 (conjure-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import (import) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import-im6 (import-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify (identify) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify-im6 (identify-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream (stream) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream-im6 (stream-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display (display) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display-im6 (display-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage (montage) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage-im6 (montage-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify (mogrify) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify-im6 (mogrify-im6) in auto mode\n",
            "Setting up imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install imagemagick\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_INCbCNqH_rQ"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/lucyellu/inkception-3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCSKsWv1dwNY",
        "outputId": "d3d52b18-ebc8-435f-899b-f73288d34882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/inkception-3d'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/inkception-3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTnViEOQqdtE",
        "outputId": "1009ad4e-fca0-47f9-afc3-621effb8ad8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/A_Scroll/inkception-3d\n"
          ]
        }
      ],
      "source": [
        "#%cd /content/drive/MyDrive/inkception-3d\n",
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX9K3ul_qdvk",
        "outputId": "7d0475f7-a254-4226-b180-fe0064ad1068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm@ git+https://github.com/rwightman/pytorch-image-models.git@95ba90157fbbee293e8d10ac108ced2d9b990cbc (from -r requirements.txt (line 225))\n",
            "  Cloning https://github.com/rwightman/pytorch-image-models.git (to revision 95ba90157fbbee293e8d10ac108ced2d9b990cbc) to /tmp/pip-install-2cmbngbf/timm_f06708b184be4462bc650cf63abaa487\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rwightman/pytorch-image-models.git /tmp/pip-install-2cmbngbf/timm_f06708b184be4462bc650cf63abaa487\n",
            "  Running command git rev-parse -q --verify 'sha^95ba90157fbbee293e8d10ac108ced2d9b990cbc'\n",
            "  Running command git fetch -q https://github.com/rwightman/pytorch-image-models.git 95ba90157fbbee293e8d10ac108ced2d9b990cbc\n",
            "  Running command git checkout -q 95ba90157fbbee293e8d10ac108ced2d9b990cbc\n",
            "  Resolved https://github.com/rwightman/pytorch-image-models.git to commit 95ba90157fbbee293e8d10ac108ced2d9b990cbc\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting absl-py==0.15.0 (from -r requirements.txt (line 1))\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting aicrowd-cli==0.1.15 (from -r requirements.txt (line 2))\n",
            "  Downloading aicrowd_cli-0.1.15-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting aiofiles==22.1.0 (from -r requirements.txt (line 3))\n",
            "  Downloading aiofiles-22.1.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting aiohttp==3.8.5 (from -r requirements.txt (line 4))\n",
            "  Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: aiosignal==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.3.1)\n",
            "Collecting aiosqlite==0.18.0 (from -r requirements.txt (line 6))\n",
            "  Downloading aiosqlite-0.18.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting albumentations==1.3.1 (from -r requirements.txt (line 7))\n",
            "  Downloading albumentations-1.3.1-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting anyio==3.6.2 (from -r requirements.txt (line 8))\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting appdirs==1.4.3 (from -r requirements.txt (line 9))\n",
            "  Downloading appdirs-1.4.3-py2.py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting argon2-cffi==21.3.0 (from -r requirements.txt (line 10))\n",
            "  Downloading argon2_cffi-21.3.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (21.2.0)\n",
            "Collecting arrow==1.2.3 (from -r requirements.txt (line 12))\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting astunparse==1.6.2 (from -r requirements.txt (line 13))\n",
            "  Downloading astunparse-1.6.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: async-timeout==4.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (4.0.3)\n",
            "Collecting atomicwrites==1.1.5 (from -r requirements.txt (line 15))\n",
            "  Downloading atomicwrites-1.1.5-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting attrs==19.3.0 (from -r requirements.txt (line 16))\n",
            "  Downloading attrs-19.3.0-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting Automat==0.8.0 (from -r requirements.txt (line 17))\n",
            "  Downloading Automat-0.8.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting Babel==2.12.1 (from -r requirements.txt (line 18))\n",
            "  Downloading Babel-2.12.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting backcall==0.1.0 (from -r requirements.txt (line 19))\n",
            "  Downloading backcall-0.1.0.zip (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beautifulsoup4==4.8.2 (from -r requirements.txt (line 20))\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting bleach==3.1.1 (from -r requirements.txt (line 21))\n",
            "  Downloading bleach-3.1.1-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: blinker==1.4 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 22)) (1.4)\n",
            "Collecting blosc==1.7.0 (from -r requirements.txt (line 23))\n",
            "  Downloading blosc-1.7.0.tar.gz (756 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.8/756.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cachetools==4.0.0 (from -r requirements.txt (line 25))\n",
            "  Downloading cachetools-4.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flake8==3.7.9 (from -r requirements.txt (line 27))\n",
            "  Downloading flake8-3.7.9-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting flatbuffers==1.12 (from -r requirements.txt (line 28))\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\n",
            "Collecting fonttools==4.39.0 (from -r requirements.txt (line 29))\n",
            "  Downloading fonttools-4.39.0-py3-none-any.whl.metadata (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fqdn==1.5.1 (from -r requirements.txt (line 30))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting frozenlist==1.4.0 (from -r requirements.txt (line 31))\n",
            "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting fsspec==2023.9.2 (from -r requirements.txt (line 32))\n",
            "  Downloading fsspec-2023.9.2-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting future==0.18.2 (from -r requirements.txt (line 33))\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gast==0.4.0 (from -r requirements.txt (line 34))\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting gitdb==4.0.10 (from -r requirements.txt (line 35))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting GitPython==3.1.18 (from -r requirements.txt (line 36))\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting Glances==3.1.3 (from -r requirements.txt (line 37))\n",
            "  Downloading Glances-3.1.3.tar.gz (44.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting google-auth==1.5.1 (from -r requirements.txt (line 38))\n",
            "  Downloading google_auth-1.5.1-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting google-auth-oauthlib==0.4.1 (from -r requirements.txt (line 39))\n",
            "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (0.2.0)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 1.45.0, 1.48.0, 1.49.0, 1.51.0, 1.52.0, 1.55.0, 1.65.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement grpcio==1.29.1 (from versions: 0.4.0a0, 0.4.0a1, 0.4.0a2, 0.4.0a3, 0.4.0a4, 0.4.0a5, 0.4.0a6, 0.4.0a7, 0.4.0a8, 0.4.0a13, 0.4.0a14, 0.5.0a0, 0.5.0a1, 0.5.0a2, 0.9.0a0, 0.9.0a1, 0.10.0a0, 0.11.0b0, 0.11.0b1, 0.12.0b0, 0.13.0, 0.13.1rc1, 0.13.1, 0.14.0rc1, 0.14.0, 0.15.0, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1rc1, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.1.0, 1.1.3, 1.2.0, 1.2.1, 1.3.0, 1.3.5, 1.4.0, 1.6.0, 1.6.3, 1.7.0, 1.7.3, 1.8.1, 1.8.2, 1.8.3, 1.8.4, 1.8.6, 1.9.0rc1, 1.9.0rc2, 1.9.0rc3, 1.9.0, 1.9.1, 1.10.0rc2, 1.10.0, 1.10.1rc1, 1.10.1rc2, 1.10.1, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.11.1rc1, 1.11.1, 1.12.0rc1, 1.12.0, 1.12.1, 1.13.0rc1, 1.13.0rc2, 1.13.0rc3, 1.13.0, 1.14.0rc1, 1.14.0rc2, 1.14.0, 1.14.1, 1.14.2rc1, 1.14.2, 1.15.0rc1, 1.15.0, 1.16.0rc1, 1.16.0, 1.16.1, 1.17.0, 1.17.1, 1.18.0, 1.19.0, 1.20.0rc1, 1.20.0rc2, 1.20.0rc3, 1.20.0, 1.20.1, 1.21.0rc1, 1.21.1rc1, 1.21.1, 1.22.0rc1, 1.22.0, 1.22.1, 1.23.0rc1, 1.23.0, 1.23.1, 1.24.0rc1, 1.24.0, 1.24.1, 1.24.3, 1.25.0rc1, 1.25.0, 1.26.0rc1, 1.26.0, 1.27.0rc1, 1.27.0rc2, 1.27.1, 1.27.2, 1.28.0rc1, 1.28.0rc2, 1.28.1, 1.29.0, 1.30.0, 1.31.0, 1.32.0, 1.33.1, 1.33.2, 1.34.0rc1, 1.34.0, 1.34.1, 1.35.0rc1, 1.35.0, 1.36.0rc1, 1.36.0, 1.36.1, 1.37.0rc1, 1.37.0, 1.37.1, 1.38.0rc1, 1.38.0, 1.38.1, 1.39.0rc1, 1.39.0, 1.40.0rc1, 1.40.0, 1.41.0rc2, 1.41.0, 1.41.1, 1.42.0rc1, 1.42.0, 1.43.0rc1, 1.43.0, 1.44.0rc1, 1.44.0rc2, 1.44.0, 1.45.0rc1, 1.46.0rc1, 1.46.0rc2, 1.46.0, 1.46.1, 1.46.3, 1.46.5, 1.47.0rc1, 1.47.0, 1.47.2, 1.47.5, 1.48.0rc1, 1.48.1, 1.48.2, 1.49.0rc1, 1.49.0rc3, 1.49.1, 1.50.0rc1, 1.50.0, 1.51.0rc1, 1.51.1, 1.51.3, 1.52.0rc1, 1.53.0rc2, 1.53.0, 1.53.1, 1.53.2, 1.54.0rc1, 1.54.0, 1.54.2, 1.54.3, 1.55.0rc1, 1.55.3, 1.56.0rc2, 1.56.0, 1.56.2, 1.57.0rc1, 1.57.0, 1.58.0rc1, 1.58.0, 1.59.0rc1, 1.59.0, 1.59.2, 1.59.3, 1.60.0rc1, 1.60.0, 1.60.1, 1.62.0rc1, 1.62.0, 1.62.1, 1.62.2, 1.63.0rc1, 1.63.0rc2, 1.63.0, 1.64.0rc1, 1.64.0, 1.64.1, 1.65.0rc1, 1.65.0rc2, 1.65.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for grpcio==1.29.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6ZFzd3GrJqU",
        "outputId": "e832f29e-a6ca-44d7-b899-fcdd6dd85231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.6.1)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (71.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pytorch_lightning) (12.5.82)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->pytorch_lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n",
            "Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
            "Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.11.6 pytorch_lightning-2.3.3 torchmetrics-1.4.0.post0\n",
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.18.1+cu121)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation_models_pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.1+cu121)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.23.5)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.5.82)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n",
            "Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16425 sha256=21f0e889124dbe46305200711bbdea6deeea0b768c63567ff670989f62109fc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=6ab556f0245bc3c3cfbeee4fbd164cd89b20c2e9ebdc60864eec167868367ee5\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3 timm-0.9.2\n",
            "Collecting warmup_scheduler\n",
            "  Downloading warmup_scheduler-0.3.tar.gz (2.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: warmup_scheduler\n",
            "  Building wheel for warmup_scheduler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warmup_scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2968 sha256=51ba4d403b24e0e6f8dd684108ffe82a6a48109b76a2a70ad4fa7f5423838c8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/01/9e/d1820991c32916e9808c940f572b462f3e46427f3e76c4d852\n",
            "Successfully built warmup_scheduler\n",
            "Installing collected packages: warmup_scheduler\n",
            "Successfully installed warmup_scheduler-0.3\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Collecting typed-argument-parser\n",
            "  Downloading typed_argument_parser-1.10.1-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from typed-argument-parser) (0.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from typed-argument-parser) (24.1)\n",
            "Collecting typing-inspect>=0.7.1 (from typed-argument-parser)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.7.1->typed-argument-parser)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.7.1->typed-argument-parser) (4.12.2)\n",
            "Downloading typed_argument_parser-1.10.1-py3-none-any.whl (30 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, typed-argument-parser\n",
            "Successfully installed mypy-extensions-1.0.0 typed-argument-parser-1.10.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install segmentation_models_pytorch\n",
        "!pip install warmup_scheduler\n",
        "!pip install wandb\n",
        "!pip install typed-argument-parser  # Install the correct package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjDZjjFa3NzM",
        "outputId": "a8c6bf77-bee6-414b-ca80-8756e5711179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.23.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.12.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.3.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.8.2)\n",
            "Requirement already satisfied: albucore>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.12)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from albucore>=0.0.11->albumentations) (2.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.20.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2024.7.24)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kRnD8J5_ZRjZ",
        "outputId": "3b52fb7c-548a-4029-fdea-61687a95880e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.3.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.1)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.4.0.post0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.6)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (71.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pytorch-lightning) (12.5.82)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n",
            "Requirement already satisfied: typed-argument-parser in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from typed-argument-parser) (0.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from typed-argument-parser) (24.1)\n",
            "Requirement already satisfied: typing-inspect>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from typed-argument-parser) (0.9.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.7.1->typed-argument-parser) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.7.1->typed-argument-parser) (4.12.2)\n",
            "Requirement already satisfied: segmentation_models_pytorch in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.18.1+cu121)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.7.4)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.7.1)\n",
            "Requirement already satisfied: timm==0.9.2 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.1+cu121)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.23.5)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.5.82)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.23.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.12.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.3.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.8.2)\n",
            "Requirement already satisfied: albucore>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.12)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from albucore>=0.0.11->albumentations) (2.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.20.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2024.7.24)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations) (3.5.0)\n",
            "Requirement already satisfied: warmup_scheduler in /usr/local/lib/python3.10/dist-packages (0.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting numpy==1.25.0\n",
            "  Downloading numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.25.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.25.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "a8a04983c5464fd9842d373848f1207c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 247, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2786, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3070, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2862, in __getattr__\n",
            "    if attr.startswith('_'):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1622, in _log\n",
            "    record = self.makeRecord(self.name, level, fn, lno, msg, args,\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1591, in makeRecord\n",
            "    rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 317, in __init__\n",
            "    self.filename = os.path.basename(pathname)\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 143, in basename\n",
            "    sep = _get_sep(p)\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 42, in _get_sep\n",
            "    if isinstance(path, bytes):\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Collecting matplotlib==3.6.3\n",
            "  Downloading matplotlib-3.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (1.25.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.6.3) (1.16.0)\n",
            "Downloading matplotlib-3.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning\n",
        "\n",
        "!pip install typed-argument-parser\n",
        "\n",
        "!pip install segmentation_models_pytorch\n",
        "\n",
        "!pip install albumentations\n",
        "\n",
        "!pip install warmup_scheduler\n",
        "\n",
        "!pip install opencv-python\n",
        "\n",
        "!pip install torch\n",
        "\n",
        "!pip install numpy==1.25.0\n",
        "\n",
        "!pip install wandb\n",
        "\n",
        "!pip install pandas\n",
        "\n",
        "!pip install tqdm\n",
        "\n",
        "!pip install matplotlib==3.6.3\n",
        "\n",
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwUlEMT72ZIg"
      },
      "source": [
        "##install gp and gp plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb1u8LeZzMFL",
        "outputId": "ea0703bf-932e-4f02-f6e2-165cb59be4ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login --relogin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCgrnpbJoqLW"
      },
      "source": [
        "47f9e2aa8b64b8fa2c1e379be844bb972899171e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvbJvrvsfyzw"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning==2.0.9\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ],
      "metadata": {
        "id": "uOUIAoZNuk_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhltxyQdAdby"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements_gp.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6bGFhwJAder"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements_plus.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mqbqcsf7n6M"
      },
      "source": [
        "#data prep\n",
        "-combine layers\n",
        "-crop layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46qTxzH3m_DC"
      },
      "source": [
        "##combine layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkBNpMiMXiW2",
        "outputId": "da501c30-c7f5-4b83-cc93-14c5c3754a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Renamed 0 files.\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "\n",
        "# def rename_files(output_folder):\n",
        "#     # Get all files in the output folder\n",
        "#     files = [f for f in os.listdir(output_folder) if f.startswith('combined_') and f.endswith('.tif')]\n",
        "#     files.sort()  # Sort files to ensure the correct order\n",
        "\n",
        "#     for count, file_name in enumerate(files):\n",
        "#         # Create the new file name by replacing 'combined_' with '0'\n",
        "#         new_name = f'{count:03d}.tif'\n",
        "#         old_path = os.path.join(output_folder, file_name)\n",
        "#         new_path = os.path.join(output_folder, new_name)\n",
        "\n",
        "#         # Rename the file\n",
        "#         os.rename(old_path, new_path)\n",
        "\n",
        "#     print(f'Renamed {len(files)} files.')\n",
        "\n",
        "# # Set the path to your output folder\n",
        "# #output_folder = 'path/to/your/output/folder'\n",
        "# output_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20231111135340_6_39/layers'\n",
        "# rename_files(output_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZQOPxq17svz",
        "outputId": "81cb8453-3c6b-4bfa-d2d2-ae4eb26888ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping 1 image(s) as they are less than 2.\n",
            "Combined 32 images.\n"
          ]
        }
      ],
      "source": [
        "# from PIL import Image\n",
        "# import os\n",
        "\n",
        "# # Increase the MAX_IMAGE_PIXELS limit\n",
        "# Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "# def combine_images(input_folder, output_folder, n):\n",
        "#     # Get all .tif files in the input folder\n",
        "#     tif_files = [f for f in os.listdir(input_folder) if f.endswith('.tif')]\n",
        "#     tif_files.sort()  # Sort files to ensure the correct order\n",
        "\n",
        "#     # Create output folder if it doesn't exist\n",
        "#     os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "#     combined_count = 0\n",
        "#     for i in range(0, len(tif_files), n):\n",
        "#         # Take every n images\n",
        "#         group = tif_files[i:i+n]\n",
        "\n",
        "#         # Ensure there are enough images to combine\n",
        "#         if len(group) < n:\n",
        "#             print(f\"Skipping {len(group)} image(s) as they are less than {n}.\")\n",
        "#             continue\n",
        "\n",
        "#         # Open the first image\n",
        "#         combined_image = Image.open(os.path.join(input_folder, group[0])).convert(\"RGBA\")\n",
        "\n",
        "#         for j in range(1, len(group)):\n",
        "#             image = Image.open(os.path.join(input_folder, group[j])).convert(\"RGBA\")\n",
        "#             combined_image = Image.blend(combined_image, image, alpha=0.5)\n",
        "\n",
        "#         # Save the combined image\n",
        "#         output_path = os.path.join(output_folder, f'combined_{combined_count + 1}.tif')\n",
        "#         combined_image.save(output_path)\n",
        "#         combined_count += 1\n",
        "\n",
        "#     print(f'Combined {combined_count} images.')\n",
        "\n",
        "\n",
        "\n",
        "# # Set the paths to your input folder and desired output folder\n",
        "# input_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20240304161941/layers'\n",
        "# output_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20231111135340_6_39/layers'\n",
        "# n = 2  # Set the value of n as desired\n",
        "\n",
        "# combine_images(input_folder, output_folder, n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2BW9j77nNYu"
      },
      "source": [
        "##crop segment layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfuIRkwJK-J3",
        "outputId": "ae4c72e0-8b2c-46fe-dce9-aa48aa876257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cropping complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20231215151901/layers'\n",
        "output_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20231215151901_cropped_1/layers'\n",
        "\n",
        "# Ensure the output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Increase the maximum image pixels limit to handle large images\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "def crop_image(input_path, output_path):\n",
        "    with Image.open(input_path) as img:\n",
        "# 20231215151901_cropped_1 - left delta\n",
        "      # Define crop box: (left, upper, right, lower)\n",
        "        left = 800\n",
        "        upper = 1000\n",
        "        right = 1800\n",
        "        lower = 2000\n",
        "        cropped_img = img.crop((left, upper, right, lower))\n",
        "        cropped_img.save(output_path)\n",
        "\n",
        "# Loop through the input folder and process each image\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.tif') or filename.endswith('.png'):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        crop_image(input_path, output_path)\n",
        "\n",
        "print(\"Cropping complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kViYQ4byfqZc",
        "outputId": "243f8f68-6cd0-4a42-b294-893d6045b0d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cropping complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20231215151901/layers'\n",
        "output_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20231215151901_cropped_2/layers'\n",
        "\n",
        "# Ensure the output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Increase the maximum image pixels limit to handle large images\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "def crop_image(input_path, output_path):\n",
        "    with Image.open(input_path) as img:\n",
        "\n",
        "# 20231215151901_cropped_2 - middle W\n",
        "      # Define crop box: (left, upper, right, lower)\n",
        "        left = 2800\n",
        "        upper = 2000\n",
        "        right = 3500\n",
        "        lower = 2300\n",
        "\n",
        "        cropped_img = img.crop((left, upper, right, lower))\n",
        "        cropped_img.save(output_path)\n",
        "\n",
        "# Loop through the input folder and process each image\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.tif') or filename.endswith('.png'):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        crop_image(input_path, output_path)\n",
        "\n",
        "print(\"Cropping complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YdbZPNrBZM8",
        "outputId": "b60e3135-5272-4af3-ed2d-da2349afcc82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cropping complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20231215151901/layers'\n",
        "output_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20231215151901_cropped_3/layers'\n",
        "\n",
        "# Ensure the output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Increase the maximum image pixels limit to handle large images\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "def crop_image(input_path, output_path):\n",
        "    with Image.open(input_path) as img:\n",
        "\n",
        "# 20231215151901_cropped_3 - upper right EL\n",
        "      # Define crop box: (left, upper, right, lower)\n",
        "        left = 8400\n",
        "        upper = 600\n",
        "        right = 9200\n",
        "        lower = 1100\n",
        "\n",
        "        cropped_img = img.crop((left, upper, right, lower))\n",
        "        cropped_img.save(output_path)\n",
        "\n",
        "# Loop through the input folder and process each image\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.tif') or filename.endswith('.png'):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        crop_image(input_path, output_path)\n",
        "\n",
        "print(\"Cropping complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5FscYBYBZ9o",
        "outputId": "2ed39e08-9481-456f-86a3-82089e7c2f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cropping complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20231210132040/layers'\n",
        "output_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20231210132040_cropped_4/layers'\n",
        "\n",
        "# Ensure the output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Increase the maximum image pixels limit to handle large images\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "def crop_image(input_path, output_path):\n",
        "    with Image.open(input_path) as img:\n",
        "# 20231210132040_cropped_4 - upper mid right A/N\n",
        "      # Define crop box: (left, upper, right, lower)\n",
        "        left = 8800\n",
        "        upper = 2000\n",
        "        right = 12122\n",
        "        lower = 2400\n",
        "        cropped_img = img.crop((left, upper, right, lower))\n",
        "        cropped_img.save(output_path)\n",
        "\n",
        "# Loop through the input folder and process each image\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.tif') or filename.endswith('.png'):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        crop_image(input_path, output_path)\n",
        "\n",
        "print(\"Cropping complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzNg3mcfBaAR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8XYQSkHBaCr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpiZn0poBaFJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOyOEbslC6v2",
        "outputId": "6876e448-80a0-45ab-90a2-5a548b39a17b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cropping complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20231210132040/layers'\n",
        "output_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20231210132040_cropped_1/layers'\n",
        "\n",
        "# Ensure the output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Increase the maximum image pixels limit to handle large images\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "def crop_image(input_path, output_path):\n",
        "    with Image.open(input_path) as img:\n",
        "        # Define crop box: (left, upper, right, lower)\n",
        "        left = 9300\n",
        "        upper = 800\n",
        "        right = 10200\n",
        "        lower = 14200\n",
        "        cropped_img = img.crop((left, upper, right, lower))\n",
        "        cropped_img.save(output_path)\n",
        "\n",
        "# Loop through the input folder and process each image\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.tif') or filename.endswith('.png'):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        crop_image(input_path, output_path)\n",
        "\n",
        "print(\"Cropping complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiAg3qB_kTWW"
      },
      "outputs": [],
      "source": [
        "#!python 64x64_256stride_i3d.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKCJHlvRR9eG",
        "outputId": "a05c34b1-0654-44a6-9b8d-02b0b02d1707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cropping complete!\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# from PIL import Image\n",
        "\n",
        "# input_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20240304141530'\n",
        "# output_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20240304141530_cropped_1'\n",
        "\n",
        "# # Ensure the output folder exists\n",
        "# os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# # Increase the maximum image pixels limit to handle large images\n",
        "# Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "# def crop_image(input_path, output_path):\n",
        "#     with Image.open(input_path) as img:\n",
        "#         # Define crop box: (left, upper, right, lower)\n",
        "#         left = 6000\n",
        "#         upper = 8000\n",
        "#         right = 10000\n",
        "#         lower = 12500\n",
        "#         cropped_img = img.crop((left, upper, right, lower))\n",
        "#         cropped_img.save(output_path)\n",
        "\n",
        "# # Loop through the input folder and process each image\n",
        "# for filename in os.listdir(input_folder):\n",
        "#     if filename.endswith('.tif') or filename.endswith('.png'):\n",
        "#         input_path = os.path.join(input_folder, filename)\n",
        "#         output_path = os.path.join(output_folder, filename)\n",
        "#         crop_image(input_path, output_path)\n",
        "\n",
        "# print(\"Cropping complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0YpqcNURe0z",
        "outputId": "9aa1b238-ae6c-4d20-dfda-7386f249e13c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cropping complete!\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# from PIL import Image\n",
        "\n",
        "# input_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20240304141530/layers'\n",
        "# output_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20240304141530_cropped_2/layers'\n",
        "\n",
        "# # Ensure the output folder exists\n",
        "# os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# # Increase the maximum image pixels limit to handle large images\n",
        "# Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "# def crop_image(input_path, output_path):\n",
        "#     with Image.open(input_path) as img:\n",
        "#         # Define crop box: (left, upper, right, lower)\n",
        "#         left = 13000\n",
        "#         upper = 4000\n",
        "#         right = 16000\n",
        "#         lower = 6000\n",
        "#         cropped_img = img.crop((left, upper, right, lower))\n",
        "#         cropped_img.save(output_path)\n",
        "\n",
        "# # Loop through the input folder and process each image\n",
        "# for filename in os.listdir(input_folder):\n",
        "#     if filename.endswith('.tif') or filename.endswith('.png'):\n",
        "#         input_path = os.path.join(input_folder, filename)\n",
        "#         output_path = os.path.join(output_folder, filename)\n",
        "#         crop_image(input_path, output_path)\n",
        "\n",
        "# print(\"Cropping complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpFwjMEC7s0z"
      },
      "outputs": [],
      "source": [
        "input_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20240304144031'\n",
        "output_folder = '/content/drive/MyDrive/A_Scroll/inkception-3d/eval_segments_shared/20240304144031_cropped_1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNY9RPIMERvh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2pxUbzs08EC"
      },
      "source": [
        "##Custom Segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ31S3gAir2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b3a976-478f-4bf0-828d-796936d444ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.3.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.1)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.4.0.post0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.6)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (71.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pytorch-lightning) (12.5.82)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k02sycA2FS0"
      },
      "source": [
        "#training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFTacJ5I8A_X",
        "outputId": "09a3d72a-165d-4aa4-9148-bab93600c7ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python 30chans_256tile_v24.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQcXma34j7Y_",
        "outputId": "353321ce-9337-4a83-e8d9-7a34ff561fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "reading  training-1\n",
            "reading  training-2\n",
            "reading  training-3\n",
            "reading  training-4\n",
            "reading  training-5\n",
            "reading  valid-1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240730_170207-965tezye\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtraining_scrolls_valid=valid-1_64x64_submissionlabelsi3d_finetune\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667/runs/965tezye\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/migration/utils.py:55: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.3.3, which is newer than your current Lightning version: v2.0.9\n",
            "  rank_zero_warn(\n",
            "FOLD :  0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models/ exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name       | Type                  | Params\n",
            "-----------------------------------------------------\n",
            "0 | loss_func1 | DiceLoss              | 0     \n",
            "1 | loss_func2 | SoftBCEWithLogitsLoss | 0     \n",
            "2 | backbone   | InceptionI3d          | 12.8 M\n",
            "3 | decoder    | Decoder               | 20.7 M\n",
            "-----------------------------------------------------\n",
            "33.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "33.5 M    Total params\n",
            "133.993   Total estimated model params size (MB)\n",
            "Epoch 0: 100% 329/329 [02:30<00:00,  2.19it/s, v_num=ezye, train/total_loss_step=0.591]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:07<00:09,  2.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:15<00:01,  2.53it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:17<00:00,  2.54it/s]\u001b[A\n",
            "Epoch 1:  97% 320/329 [02:26<00:04,  2.19it/s, v_num=ezye, train/total_loss_step=0.589, val/total_loss_step=0.316, val/total_loss_epoch=0.630, train/total_loss_epoch=0.591]/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:855: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "Epoch 1: 100% 329/329 [02:30<00:00,  2.18it/s, v_num=ezye, train/total_loss_step=0.567, val/total_loss_step=0.316, val/total_loss_epoch=0.630, train/total_loss_epoch=0.591]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:08<00:10,  2.49it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:15<00:01,  2.51it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:17<00:00,  2.52it/s]\u001b[A\n",
            "Epoch 2: 100% 329/329 [02:29<00:00,  2.20it/s, v_num=ezye, train/total_loss_step=0.579, val/total_loss_step=0.311, val/total_loss_epoch=0.634, train/total_loss_epoch=0.578]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:07<00:09,  2.50it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:16<00:02,  2.47it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:18<00:00,  2.48it/s]\u001b[A\n",
            "Epoch 3: 100% 329/329 [02:29<00:00,  2.19it/s, v_num=ezye, train/total_loss_step=0.591, val/total_loss_step=0.316, val/total_loss_epoch=0.642, train/total_loss_epoch=0.573]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:07<00:09,  2.54it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:15<00:01,  2.54it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:17<00:00,  2.54it/s]\u001b[A\n",
            "Epoch 4: 100% 329/329 [02:30<00:00,  2.18it/s, v_num=ezye, train/total_loss_step=0.571, val/total_loss_step=0.373, val/total_loss_epoch=0.641, train/total_loss_epoch=0.569]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:07<00:09,  2.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:15<00:01,  2.53it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:17<00:00,  2.53it/s]\u001b[A\n",
            "Epoch 5: 100% 329/329 [02:30<00:00,  2.19it/s, v_num=ezye, train/total_loss_step=0.558, val/total_loss_step=0.301, val/total_loss_epoch=0.628, train/total_loss_epoch=0.565]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:07<00:09,  2.51it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:15<00:01,  2.53it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:17<00:00,  2.53it/s]\u001b[A\n",
            "Epoch 6: 100% 329/329 [02:30<00:00,  2.19it/s, v_num=ezye, train/total_loss_step=0.551, val/total_loss_step=0.330, val/total_loss_epoch=0.624, train/total_loss_epoch=0.563]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:07<00:09,  2.51it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:16<00:02,  2.48it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:18<00:00,  2.49it/s]\u001b[A\n",
            "Epoch 7: 100% 329/329 [02:29<00:00,  2.20it/s, v_num=ezye, train/total_loss_step=0.566, val/total_loss_step=0.330, val/total_loss_epoch=0.622, train/total_loss_epoch=0.560]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:07<00:09,  2.54it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:15<00:01,  2.54it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:17<00:00,  2.54it/s]\u001b[A\n",
            "Epoch 8: 100% 329/329 [02:30<00:00,  2.19it/s, v_num=ezye, train/total_loss_step=0.539, val/total_loss_step=0.324, val/total_loss_epoch=0.628, train/total_loss_epoch=0.570]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:07<00:09,  2.54it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:15<00:01,  2.54it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:17<00:00,  2.54it/s]\u001b[A\n",
            "Epoch 9: 100% 329/329 [02:29<00:00,  2.20it/s, v_num=ezye, train/total_loss_step=0.563, val/total_loss_step=0.359, val/total_loss_epoch=0.644, train/total_loss_epoch=0.566]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:08<00:10,  2.43it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:16<00:02,  2.48it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:18<00:00,  2.49it/s]\u001b[A\n",
            "Epoch 10: 100% 329/329 [02:29<00:00,  2.20it/s, v_num=ezye, train/total_loss_step=0.547, val/total_loss_step=0.332, val/total_loss_epoch=0.630, train/total_loss_epoch=0.563]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:08<00:10,  2.49it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:16<00:02,  2.46it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:18<00:00,  2.47it/s]\u001b[A\n",
            "Epoch 11: 100% 329/329 [02:29<00:00,  2.20it/s, v_num=ezye, train/total_loss_step=0.564, val/total_loss_step=0.334, val/total_loss_epoch=0.626, train/total_loss_epoch=0.562]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:07<00:09,  2.51it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:15<00:01,  2.52it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:17<00:00,  2.52it/s]\u001b[A\n",
            "Epoch 11: 100% 329/329 [02:48<00:00,  1.95it/s, v_num=ezye, train/total_loss_step=0.564, val/total_loss_step=0.341, val/total_loss_epoch=0.627, train/total_loss_epoch=0.561]`Trainer.fit` stopped: `max_epochs=12` reached.\n",
            "Epoch 11: 100% 329/329 [02:49<00:00,  1.94it/s, v_num=ezye, train/total_loss_step=0.564, val/total_loss_step=0.341, val/total_loss_epoch=0.627, train/total_loss_epoch=0.561]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss_epoch █▅▄▃▂▂▁▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train/total_loss_step ▇▃▅▄▄▆▃█▅▅▇▃▃▄▄▅▃▄▃▃▄▂▃▄▃▄▅▃▄▅▆▆▄▂▄▃▁▂▂▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    trainer/global_step ▁▁▁▂▁▁▁▁▁▁▄▁▁▁▁▁▁▁▂▂▂▂▂▆▂▂▂▂▂▂█▂▂█▂▂▂▂▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss_epoch ▄▅▇▇▃▂▁▃█▄▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val/total_loss_step █▆▆▂▇▇▁▁▇▇▂▅▆▂▇▇▁█▅▇▁▅▆▁▇▅▁█▅▁▁▇▆▁▆▆▇▇▇▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  epoch 11\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss_epoch 0.56106\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train/total_loss_step 0.56188\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    trainer/global_step 3947\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss_epoch 0.62661\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val/total_loss_step 0.34114\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mtraining_scrolls_valid=valid-1_64x64_submissionlabelsi3d_finetune\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667/runs/965tezye\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 14 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240730_170207-965tezye/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "[ WARN:0@2523.190] global loadsave.cpp:241 findDecoder imread_('/content/drive/MyDrive/A_Scroll_1/modelmain/training/train_scrolls/valid-2/valid-2_inklabels.png'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters/30chans_256tile_v24.py\", line 527, in <module>\n",
            "    pred_shape=valid_mask_gt.shape\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4C_vbfYtkevr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VW0RoapUkeyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##past training runs"
      ],
      "metadata": {
        "id": "l1rz5Wj0kT9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python 30chans_256tile_v23b.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eWsq9H_y-pfD",
        "outputId": "ebf9b9e3-c9d2-4ddd-aaf6-6cfd7cc94540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "reading  training-1\n",
            "reading  training-2\n",
            "reading  training-3\n",
            "reading  training-4\n",
            "reading  training-5\n",
            "reading  valid-1\n",
            "FOLD :  0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240730_053738-rge0lnq0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtraining_scrolls_valid=valid-1_64x64_submissionlabelsi3d_finetune\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667/runs/rge0lnq0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name       | Type                  | Params | Mode \n",
            "-------------------------------------------------------------\n",
            "0 | loss_func1 | DiceLoss              | 0      | train\n",
            "1 | loss_func2 | SoftBCEWithLogitsLoss | 0      | train\n",
            "2 | backbone   | InceptionI3d          | 12.8 M | train\n",
            "3 | decoder    | Decoder               | 20.7 M | train\n",
            "-------------------------------------------------------------\n",
            "33.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "33.5 M    Total params\n",
            "133.993   Total estimated model params size (MB)\n",
            "Epoch 0: 100% 329/329 [09:22<00:00,  1.71s/it, v_num=lnq0, train/total_loss_step=0.616]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.06it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.06it/s]\u001b[A\n",
            "Epoch 1:  97% 320/329 [09:08<00:15,  1.71s/it, v_num=lnq0, train/total_loss_step=0.605, val/total_loss_step=0.336, val/total_loss_epoch=0.623, train/total_loss_epoch=0.610]/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:855: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "Epoch 1: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=lnq0, train/total_loss_step=0.609, val/total_loss_step=0.336, val/total_loss_epoch=0.623, train/total_loss_epoch=0.610]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.06it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.06it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.06it/s]\u001b[A\n",
            "Epoch 2: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=lnq0, train/total_loss_step=0.626, val/total_loss_step=0.312, val/total_loss_epoch=0.613, train/total_loss_epoch=0.614]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.06it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.06it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.06it/s]\u001b[A\n",
            "Epoch 3: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=lnq0, train/total_loss_step=0.615, val/total_loss_step=0.373, val/total_loss_epoch=0.657, train/total_loss_epoch=0.608]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.06it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.07it/s]\u001b[A\n",
            "Epoch 4: 100% 329/329 [09:24<00:00,  1.71s/it, v_num=lnq0, train/total_loss_step=0.594, val/total_loss_step=0.367, val/total_loss_epoch=0.635, train/total_loss_epoch=0.603]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:19<00:23,  1.05it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.06it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.06it/s]\u001b[A\n",
            "Epoch 5: 100% 329/329 [09:24<00:00,  1.72s/it, v_num=lnq0, train/total_loss_step=0.589, val/total_loss_step=0.318, val/total_loss_epoch=0.625, train/total_loss_epoch=0.596]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:19<00:24,  1.04it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.05it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.05it/s]\u001b[A\n",
            "Epoch 6: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=lnq0, train/total_loss_step=0.572, val/total_loss_step=0.336, val/total_loss_epoch=0.622, train/total_loss_epoch=0.591]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:19<00:24,  1.04it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:38<00:04,  1.04it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.05it/s]\u001b[A\n",
            "Epoch 7:   0% 0/329 [00:00<?, ?it/s, v_num=lnq0, train/total_loss_step=0.572, val/total_loss_step=0.325, val/total_loss_epoch=0.640, train/total_loss_epoch=0.585]/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "[rank: 0] Received SIGTERM: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/30chans_256tile_v23b.py\", line 576, in <module>\n",
            "    wandb.finish()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 4287, in finish\n",
            "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 449, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 390, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 2100, in finish\n",
            "    return self._finish(exit_code, quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 2134, in _finish\n",
            "    self._atexit_cleanup(exit_code=exit_code)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 2386, in _atexit_cleanup\n",
            "    self._on_finish()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 2651, in _on_finish\n",
            "    _ = exit_handle.wait(timeout=-1, on_progress=self._on_progress_exit)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 283, in wait\n",
            "    found, abandoned = self._slot._get_and_clear(timeout=wait_timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 130, in _get_and_clear\n",
            "    if self._wait(timeout=timeout):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 126, in _wait\n",
            "    return self._event.wait(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 607, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 324, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-f3deb25ee359>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python 30chans_256tile_v23b.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    280\u001b[0m   \u001b[0moutput_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m   \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m   \u001b[0minput_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##past runs"
      ],
      "metadata": {
        "id": "qqAvNCfBKHvJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUN9H7tZceeb",
        "outputId": "62e7cdd1-da9f-44bf-fbb4-43f43fff0f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "reading  training-1\n",
            "reading  training-2\n",
            "reading  training-3\n",
            "reading  training-4\n",
            "reading  training-5\n",
            "reading  valid-1\n",
            "FOLD :  0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240730_024734-zb4g4gmk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtraining_scrolls_valid=valid-1_64x64_submissionlabelsi3d_finetune\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667/runs/zb4g4gmk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name       | Type                  | Params | Mode \n",
            "-------------------------------------------------------------\n",
            "0 | loss_func1 | DiceLoss              | 0      | train\n",
            "1 | loss_func2 | SoftBCEWithLogitsLoss | 0      | train\n",
            "2 | backbone   | InceptionI3d          | 12.8 M | train\n",
            "3 | decoder    | Decoder               | 20.7 M | train\n",
            "-------------------------------------------------------------\n",
            "33.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "33.5 M    Total params\n",
            "133.993   Total estimated model params size (MB)\n",
            "Epoch 0: 100% 329/329 [09:16<00:00,  1.69s/it, v_num=4gmk, train/total_loss_step=0.755]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.06it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.07it/s]\u001b[A\n",
            "Epoch 1:  97% 320/329 [09:07<00:15,  1.71s/it, v_num=4gmk, train/total_loss_step=0.658, val/total_loss_step=0.372, val/total_loss_epoch=0.702, train/total_loss_epoch=0.725]/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:855: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "Epoch 1: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=4gmk, train/total_loss_step=0.684, val/total_loss_step=0.372, val/total_loss_epoch=0.702, train/total_loss_epoch=0.725]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.07it/s]\u001b[A\n",
            "Epoch 2: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=4gmk, train/total_loss_step=0.663, val/total_loss_step=0.304, val/total_loss_epoch=0.622, train/total_loss_epoch=0.671]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.06it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.06it/s]\u001b[A\n",
            "Epoch 3: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=4gmk, train/total_loss_step=0.655, val/total_loss_step=0.351, val/total_loss_epoch=0.627, train/total_loss_epoch=0.659]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:41<00:00,  1.07it/s]\u001b[A\n",
            "Epoch 4: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=4gmk, train/total_loss_step=0.635, val/total_loss_step=0.341, val/total_loss_epoch=0.631, train/total_loss_epoch=0.652]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.07it/s]\u001b[A\n",
            "Epoch 5: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=4gmk, train/total_loss_step=0.633, val/total_loss_step=0.328, val/total_loss_epoch=0.627, train/total_loss_epoch=0.643]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.07it/s]\u001b[A\n",
            "Epoch 6: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=4gmk, train/total_loss_step=0.612, val/total_loss_step=0.330, val/total_loss_epoch=0.630, train/total_loss_epoch=0.636]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.06it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.06it/s]\u001b[A\n",
            "Epoch 7: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=4gmk, train/total_loss_step=0.619, val/total_loss_step=0.324, val/total_loss_epoch=0.616, train/total_loss_epoch=0.630]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:41<00:00,  1.07it/s]\u001b[A\n",
            "Epoch 8: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=4gmk, train/total_loss_step=0.602, val/total_loss_step=0.330, val/total_loss_epoch=0.639, train/total_loss_epoch=0.624]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:41<00:00,  1.07it/s]\u001b[A\n",
            "Epoch 9: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=4gmk, train/total_loss_step=0.620, val/total_loss_step=0.405, val/total_loss_epoch=0.670, train/total_loss_epoch=0.619]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:19<00:23,  1.05it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.06it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.06it/s]\u001b[A\n",
            "Epoch 10: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=4gmk, train/total_loss_step=0.608, val/total_loss_step=0.329, val/total_loss_epoch=0.621, train/total_loss_epoch=0.614]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.06it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:42<00:00,  1.06it/s]\u001b[A\n",
            "Epoch 11: 100% 329/329 [09:23<00:00,  1.71s/it, v_num=4gmk, train/total_loss_step=0.604, val/total_loss_step=0.335, val/total_loss_epoch=0.634, train/total_loss_epoch=0.612]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/45 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 20/45 [00:18<00:23,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 40/45 [00:37<00:04,  1.07it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 45/45 [00:41<00:00,  1.07it/s]\u001b[A\n",
            "Epoch 11: 100% 329/329 [10:06<00:00,  1.84s/it, v_num=4gmk, train/total_loss_step=0.604, val/total_loss_step=0.343, val/total_loss_epoch=0.625, train/total_loss_epoch=0.611]`Trainer.fit` stopped: `max_epochs=12` reached.\n",
            "Epoch 11: 100% 329/329 [10:08<00:00,  1.85s/it, v_num=4gmk, train/total_loss_step=0.604, val/total_loss_step=0.343, val/total_loss_epoch=0.625, train/total_loss_epoch=0.611]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss_epoch █▅▄▃▃▃▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train/total_loss_step █▆██▆▅▄▆▅▅▅▅▅▄▄▅▅▄▄▃▄▃▃▄▃▃▄▃▄▃▄▄▃▂▃▃▁▂▂▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    trainer/global_step ▁▁▁▂▁▁▁▁▁▁▄▁▁▁▁▁▁▁▂▂▂▂▂▆▂▂▂▂▂▂█▂▂█▂▂▂▂▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss_epoch █▂▂▂▂▂▁▃▅▁▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val/total_loss_step █▇▇▁▇▆▁▂▆▇▂▅▆▂▆▆▁█▅▇▁▄▆▁▇▆▁█▅▂▁▆▆▁▅▆▇▇▆▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  epoch 11\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss_epoch 0.61063\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train/total_loss_step 0.61576\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    trainer/global_step 3947\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss_epoch 0.62508\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val/total_loss_step 0.34254\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mtraining_scrolls_valid=valid-1_64x64_submissionlabelsi3d_finetune\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667/runs/zb4g4gmk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 14 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240730_024734-zb4g4gmk/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "[ WARN:0@7725.168] global loadsave.cpp:241 findDecoder imread_('/content/drive/MyDrive/A_Scroll_1/modelmain/training/train_scrolls/valid-2/valid-2_inklabels.png'): can't open/read file: check file path/integrity\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters/30chans_256tile_v21b.py\", line 526, in <module>\n",
            "    pred_shape=valid_mask_gt.shape\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python 30chans_256tile_v21b.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhGMwbmi_H2j",
        "outputId": "efc161b8-9c46-4ea0-cd17-02437e1acf91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/A_Scroll/inkception-3d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v28_normal_ckpt11.py --reverse 0 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-3/valid_valid-1_0_fr_i3depoch=11.ckpt\n",
        "!python inference_v28_reversed_ckpt11.py --reverse 1 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-3/valid_valid-1_0_fr_i3depoch=11.ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_NItdZt9oZU",
        "outputId": "9766e2c8-a92f-4821-a457-0dbe7ac73c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_32to32_1722315338/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:20<00:53,  1.46s/it]Progress image saved at step 12 (24%): ./outputs/20231215151901_32to32_1722315338/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:39<00:36,  1.46s/it]Progress image saved at step 24 (48%): ./outputs/20231215151901_32to32_1722315338/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [00:58<00:19,  1.48s/it]Progress image saved at step 36 (73%): ./outputs/20231215151901_32to32_1722315338/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [01:20<00:00,  1.64s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_32to32_1722315439/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:21<00:56,  1.52s/it]Progress image saved at step 12 (24%): ./outputs/20231215151901_32to32_1722315439/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:40<00:38,  1.53s/it]Progress image saved at step 24 (48%): ./outputs/20231215151901_32to32_1722315439/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [01:01<00:20,  1.54s/it]Progress image saved at step 36 (73%): ./outputs/20231215151901_32to32_1722315439/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [01:23<00:00,  1.70s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v28_normal_ckpt11.py --reverse 0 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-1/valid_valid-1_0_fr_i3depoch=11.ckpt\n",
        "!python inference_v28_reversed_ckpt11.py --reverse 1 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-1/valid_valid-1_0_fr_i3depoch=11.ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1kSeOSNFBI0",
        "outputId": "9a956735-3040-4c8d-a741-c1ba1e0c6c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_32to32_1722316775/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:20<00:53,  1.44s/it]Progress image saved at step 12 (24%): ./outputs/20231215151901_32to32_1722316775/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:39<00:36,  1.46s/it]Progress image saved at step 24 (48%): ./outputs/20231215151901_32to32_1722316775/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [00:58<00:19,  1.47s/it]Progress image saved at step 36 (73%): ./outputs/20231215151901_32to32_1722316775/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [01:20<00:00,  1.64s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_32to32_1722316878/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:20<00:55,  1.50s/it]Progress image saved at step 12 (24%): ./outputs/20231215151901_32to32_1722316878/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:40<00:37,  1.51s/it]Progress image saved at step 24 (48%): ./outputs/20231215151901_32to32_1722316878/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [01:00<00:19,  1.53s/it]Progress image saved at step 36 (73%): ./outputs/20231215151901_32to32_1722316878/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [01:22<00:00,  1.69s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SxgQoYBBFBLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AQX7BAr8FBOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk2zYHIfYa0n"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApVL-44gdZw7"
      },
      "source": [
        "##train fails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULSfkMzwkBW1",
        "outputId": "11d4d2f8-9768-48e2-da27-2c20aef96f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/A_Scroll/inkception-3d\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9UjDzPPPKwf",
        "outputId": "116502f3-41a7-46f4-ff88-6f1d30d2342e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240726_053931-sb0ug43u\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msleek-sea-6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/pretraining_all\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/pretraining_all/runs/sb0ug43u\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/migration/utils.py:55: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.0.9.post0, which is newer than your current Lightning version: v2.0.9\n",
            "  rank_zero_warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/64x64_256stride_i3d_1667_7a.py\", line 427, in <module>\n",
            "    train_loop()\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/64x64_256stride_i3d_1667_7a.py\", line 416, in train_loop\n",
            "    model = BuildEngine.load_from_checkpoint(CFG.model_dir + \"valid_20230827161847_0_fr_i3depoch=7.ckpt\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1543, in load_from_checkpoint\n",
            "    loaded = _load_from_checkpoint(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 91, in _load_from_checkpoint\n",
            "    model = _load_state(cls, checkpoint, strict=strict, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 157, in _load_state\n",
            "    keys = obj.load_state_dict(checkpoint[\"state_dict\"], strict=strict)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2189, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for BuildEngine:\n",
            "\tMissing key(s) in state_dict: \"model.encoder._conv_stem.weight\", \"model.encoder._bn0.weight\", \"model.encoder._bn0.bias\", \"model.encoder._bn0.running_mean\", \"model.encoder._bn0.running_var\", \"model.encoder._blocks.0._depthwise_conv.weight\", \"model.encoder._blocks.0._bn1.weight\", \"model.encoder._blocks.0._bn1.bias\", \"model.encoder._blocks.0._bn1.running_mean\", \"model.encoder._blocks.0._bn1.running_var\", \"model.encoder._blocks.0._se_reduce.weight\", \"model.encoder._blocks.0._se_reduce.bias\", \"model.encoder._blocks.0._se_expand.weight\", \"model.encoder._blocks.0._se_expand.bias\", \"model.encoder._blocks.0._project_conv.weight\", \"model.encoder._blocks.0._bn2.weight\", \"model.encoder._blocks.0._bn2.bias\", \"model.encoder._blocks.0._bn2.running_mean\", \"model.encoder._blocks.0._bn2.running_var\", \"model.encoder._blocks.1._expand_conv.weight\", \"model.encoder._blocks.1._bn0.weight\", \"model.encoder._blocks.1._bn0.bias\", \"model.encoder._blocks.1._bn0.running_mean\", \"model.encoder._blocks.1._bn0.running_var\", \"model.encoder._blocks.1._depthwise_conv.weight\", \"model.encoder._blocks.1._bn1.weight\", \"model.encoder._blocks.1._bn1.bias\", \"model.encoder._blocks.1._bn1.running_mean\", \"model.encoder._blocks.1._bn1.running_var\", \"model.encoder._blocks.1._se_reduce.weight\", \"model.encoder._blocks.1._se_reduce.bias\", \"model.encoder._blocks.1._se_expand.weight\", \"model.encoder._blocks.1._se_expand.bias\", \"model.encoder._blocks.1._project_conv.weight\", \"model.encoder._blocks.1._bn2.weight\", \"model.encoder._blocks.1._bn2.bias\", \"model.encoder._blocks.1._bn2.running_mean\", \"model.encoder._blocks.1._bn2.running_var\", \"model.encoder._blocks.2._expand_conv.weight\", \"model.encoder._blocks.2._bn0.weight\", \"model.encoder._blocks.2._bn0.bias\", \"model.encoder._blocks.2._bn0.running_mean\", \"model.encoder._blocks.2._bn0.running_var\", \"model.encoder._blocks.2._depthwise_conv.weight\", \"model.encoder._blocks.2._bn1.weight\", \"model.encoder._blocks.2._bn1.bias\", \"model.encoder._blocks.2._bn1.running_mean\", \"model.encoder._blocks.2._bn1.running_var\", \"model.encoder._blocks.2._se_reduce.weight\", \"model.encoder._blocks.2._se_reduce.bias\", \"model.encoder._blocks.2._se_expand.weight\", \"model.encoder._blocks.2._se_expand.bias\", \"model.encoder._blocks.2._project_conv.weight\", \"model.encoder._blocks.2._bn2.weight\", \"model.encoder._blocks.2._bn2.bias\", \"model.encoder._blocks.2._bn2.running_mean\", \"model.encoder._blocks.2._bn2.running_var\", \"model.encoder._blocks.3._expand_conv.weight\", \"model.encoder._blocks.3._bn0.weight\", \"model.encoder._blocks.3._bn0.bias\", \"model.encoder._blocks.3._bn0.running_mean\", \"model.encoder._blocks.3._bn0.running_var\", \"model.encoder._blocks.3._depthwise_conv.weight\", \"model.encoder._blocks.3._bn1.weight\", \"model.encoder._blocks.3._bn1.bias\", \"model.encoder._blocks.3._bn1.running_mean\", \"model.encoder._blocks.3._bn1.running_var\", \"model.encoder._blocks.3._se_reduce.weight\", \"model.encoder._blocks.3._se_reduce.bias\", \"model.encoder._blocks.3._se_expand.weight\", \"model.encoder._blocks.3._se_expand.bias\", \"model.encoder._blocks.3._project_conv.weight\", \"model.encoder._blocks.3._bn2.weight\", \"model.encoder._blocks.3._bn2.bias\", \"model.encoder._blocks.3._bn2.running_mean\", \"model.encoder._blocks.3._bn2.running_var\", \"model.encoder._blocks.4._expand_conv.weight\", \"model.encoder._blocks.4._bn0.weight\", \"model.encoder._blocks.4._bn0.bias\", \"model.encoder._blocks.4._bn0.running_mean\", \"model.encoder._blocks.4._bn0.running_var\", \"model.encoder._blocks.4._depthwise_conv.weight\", \"model.encoder._blocks.4._bn1.weight\", \"model.encoder._blocks.4._bn1.bias\", \"model.encoder._blocks.4._bn1.running_mean\", \"model.encoder._blocks.4._bn1.running_var\", \"model.encoder._blocks.4._se_reduce.weight\", \"model.encoder._blocks.4._se_reduce.bias\", \"model.encoder._blocks.4._se_expand.weight\", \"model.encoder._blocks.4._se_expand.bias\", \"model.encoder._blocks.4._project_conv.weight\", \"model.encoder._blocks.4._bn2.weight\", \"model.encoder._blocks.4._bn2.bias\", \"model.encoder._blocks.4._bn2.running_mean\", \"model.encoder._blocks.4._bn2.running_var\", \"model.encoder._blocks.5._expand_conv.weight\", \"model.encoder._blocks.5._bn0.weight\", \"model.encoder._blocks.5._bn0.bias\", \"model.encoder._blocks.5._bn0.running_mean\", \"model.encoder._blocks.5._bn0.running_var\", \"model.encoder._blocks.5._depthwise_conv.weight\", \"model.encoder._blocks.5._bn1.weight\", \"model.encoder._blocks.5._bn1.bias\", \"model.encoder._blocks.5._bn1.running_mean\", \"model.encoder._blocks.5._bn1.running_var\", \"model.encoder._blocks.5._se_reduce.weight\", \"model.encoder._blocks.5._se_reduce.bias\", \"model.encoder._blocks.5._se_expand.weight\", \"model.encoder._blocks.5._se_expand.bias\", \"model.encoder._blocks.5._project_conv.weight\", \"model.encoder._blocks.5._bn2.weight\", \"model.encoder._blocks.5._bn2.bias\", \"model.encoder._blocks.5._bn2.running_mean\", \"model.encoder._blocks.5._bn2.running_var\", \"model.encoder._blocks.6._expand_conv.weight\", \"model.encoder._blocks.6._bn0.weight\", \"model.encoder._blocks.6._bn0.bias\", \"model.encoder._blocks.6._bn0.running_mean\", \"model.encoder._blocks.6._bn0.running_var\", \"model.encoder._blocks.6._depthwise_conv.weight\", \"model.encoder._blocks.6._bn1.weight\", \"model.encoder._blocks.6._bn1.bias\", \"model.encoder._blocks.6._bn1.running_mean\", \"model.encoder._blocks.6._bn1.running_var\", \"model.encoder._blocks.6._se_reduce.weight\", \"model.encoder._blocks.6._se_reduce.bias\", \"model.encoder._blocks.6._se_expand.weight\", \"model.encoder._blocks.6._se_expand.bias\", \"model.encoder._blocks.6._project_conv.weight\", \"model.encoder._blocks.6._bn2.weight\", \"model.encoder._blocks.6._bn2.bias\", \"model.encoder._blocks.6._bn2.running_mean\", \"model.encoder._blocks.6._bn2.running_var\", \"model.encoder._blocks.7._expand_conv.weight\", \"model.encoder._blocks.7._bn0.weight\", \"model.encoder._blocks.7._bn0.bias\", \"model.encoder._blocks.7._bn0.running_mean\", \"model.encoder._blocks.7._bn0.running_var\", \"model.encoder._blocks.7._depthwise_conv.weight\", \"model.encoder._blocks.7._bn1.weight\", \"model.encoder._blocks.7._bn1.bias\", \"model.encoder._blocks.7._bn1.running_mean\", \"model.encoder._blocks.7._bn1.running_var\", \"model.encoder._blocks.7._se_reduce.weight\", \"model.encoder._blocks.7._se_reduce.bias\", \"model.encoder._blocks.7._se_expand.weight\", \"model.encoder._blocks.7._se_expand.bias\", \"model.encoder._blocks.7._project_conv.weight\", \"model.encoder._blocks.7._bn2.weight\", \"model.encoder._blocks.7._bn2.bias\", \"model.encoder._blocks.7._bn2.running_mean\", \"model.encoder._blocks.7._bn2.running_var\", \"model.encoder._blocks.8._expand_conv.weight\", \"model.encoder._blocks.8._bn0.weight\", \"model.encoder._blocks.8._bn0.bias\", \"model.encoder._blocks.8._bn0.running_mean\", \"model.encoder._blocks.8._bn0.running_var\", \"model.encoder._blocks.8._depthwise_conv.weight\", \"model.encoder._blocks.8._bn1.weight\", \"model.encoder._blocks.8._bn1.bias\", \"model.encoder._blocks.8._bn1.running_mean\", \"model.encoder._blocks.8._bn1.running_var\", \"model.encoder._blocks.8._se_reduce.weight\", \"model.encoder._blocks.8._se_reduce.bias\", \"model.encoder._blocks.8._se_expand.weight\", \"model.encoder._blocks.8._se_expand.bias\", \"model.encoder._blocks.8._project_conv.weight\", \"model.encoder._blocks.8._bn2.weight\", \"model.encoder._blocks.8._bn2.bias\", \"model.encoder._blocks.8._bn2.running_mean\", \"model.encoder._blocks.8._bn2.running_var\", \"model.encoder._blocks.9._expand_conv.weight\", \"model.encoder._blocks.9._bn0.weight\", \"model.encoder._blocks.9._bn0.bias\", \"model.encoder._blocks.9._bn0.running_mean\", \"model.encoder._blocks.9._bn0.running_var\", \"model.encoder._blocks.9._depthwise_conv.weight\", \"model.encoder._blocks.9._bn1.weight\", \"model.encoder._blocks.9._bn1.bias\", \"model.encoder._blocks.9._bn1.running_mean\", \"model.encoder._blocks.9._bn1.running_var\", \"model.encoder._blocks.9._se_reduce.weight\", \"model.encoder._blocks.9._se_reduce.bias\", \"model.encoder._blocks.9._se_expand.weight\", \"model.encoder._blocks.9._se_expand.bias\", \"model.encoder._blocks.9._project_conv.weight\", \"model.encoder._blocks.9._bn2.weight\", \"model.encoder._blocks.9._bn2.bias\", \"model.encoder._blocks.9._bn2.running_mean\", \"model.encoder._blocks.9._bn2.running_var\", \"model.encoder._blocks.10._expand_conv.weight\", \"model.encoder._blocks.10._bn0.weight\", \"model.encoder._blocks.10._bn0.bias\", \"model.encoder._blocks.10._bn0.running_mean\", \"model.encoder._blocks.10._bn0.running_var\", \"model.encoder._blocks.10._depthwise_conv.weight\", \"model.encoder._blocks.10._bn1.weight\", \"model.encoder._blocks.10._bn1.bias\", \"model.encoder._blocks.10._bn1.running_mean\", \"model.encoder._blocks.10._bn1.running_var\", \"model.encoder._blocks.10._se_reduce.weight\", \"model.encoder._blocks.10._se_reduce.bias\", \"model.encoder._blocks.10._se_expand.weight\", \"model.encoder._blocks.10._se_expand.bias\", \"model.encoder._blocks.10._project_conv.weight\", \"model.encoder._blocks.10._bn2.weight\", \"model.encoder._blocks.10._bn2.bias\", \"model.encoder._blocks.10._bn2.running_mean\", \"model.encoder._blocks.10._bn2.running_var\", \"model.encoder._blocks.11._expand_conv.weight\", \"model.encoder._blocks.11._bn0.weight\", \"model.encoder._blocks.11._bn0.bias\", \"model.encoder._blocks.11._bn0.running_mean\", \"model.encoder._blocks.11._bn0.running_var\", \"model.encoder._blocks.11._depthwise_conv.weight\", \"model.encoder._blocks.11._bn1.weight\", \"model.encoder._blocks.11._bn1.bias\", \"model.encoder._blocks.11._bn1.running_mean\", \"model.encoder._blocks.11._bn1.running_var\", \"model.encoder._blocks.11._se_reduce.weight\", \"model.encoder._blocks.11._se_reduce.bias\", \"model.encoder._blocks.11._se_expand.weight\", \"model.encoder._blocks.11._se_expand.bias\", \"model.encoder._blocks.11._project_conv.weight\", \"model.encoder._blocks.11._bn2.weight\", \"model.encoder._blocks.11._bn2.bias\", \"model.encoder._blocks.11._bn2.running_mean\", \"model.encoder._blocks.11._bn2.running_var\", \"model.encoder._blocks.12._expand_conv.weight\", \"model.encoder._blocks.12._bn0.weight\", \"model.encoder._blocks.12._bn0.bias\", \"model.encoder._blocks.12._bn0.running_mean\", \"model.encoder._blocks.12._bn0.running_var\", \"model.encoder._blocks.12._depthwise_conv.weight\", \"model.encoder._blocks.12._bn1.weight\", \"model.encoder._blocks.12._bn1.bias\", \"model.encoder._blocks.12._bn1.running_mean\", \"model.encoder._blocks.12._bn1.running_var\", \"model.encoder._blocks.12._se_reduce.weight\", \"model.encoder._blocks.12._se_reduce.bias\", \"model.encoder._blocks.12._se_expand.weight\", \"model.encoder._blocks.12._se_expand.bias\", \"model.encoder._blocks.12._project_conv.weight\", \"model.encoder._blocks.12._bn2.weight\", \"model.encoder._blocks.12._bn2.bias\", \"model.encoder._blocks.12._bn2.running_mean\", \"model.encoder._blocks.12._bn2.running_var\", \"model.encoder._blocks.13._expand_conv.weight\", \"model.encoder._blocks.13._bn0.weight\", \"model.encoder._blocks.13._bn0.bias\", \"model.encoder._blocks.13._bn0.running_mean\", \"model.encoder._blocks.13._bn0.running_var\", \"model.encoder._blocks.13._depthwise_conv.weight\", \"model.encoder._blocks.13._bn1.weight\", \"model.encoder._blocks.13._bn1.bias\", \"model.encoder._blocks.13._bn1.running_mean\", \"model.encoder._blocks.13._bn1.running_var\", \"model.encoder._blocks.13._se_reduce.weight\", \"model.encoder._blocks.13._se_reduce.bias\", \"model.encoder._blocks.13._se_expand.weight\", \"model.encoder._blocks.13._se_expand.bias\", \"model.encoder._blocks.13._project_conv.weight\", \"model.encoder._blocks.13._bn2.weight\", \"model.encoder._blocks.13._bn2.bias\", \"model.encoder._blocks.13._bn2.running_mean\", \"model.encoder._blocks.13._bn2.running_var\", \"model.encoder._blocks.14._expand_conv.weight\", \"model.encoder._blocks.14._bn0.weight\", \"model.encoder._blocks.14._bn0.bias\", \"model.encoder._blocks.14._bn0.running_mean\", \"model.encoder._blocks.14._bn0.running_var\", \"model.encoder._blocks.14._depthwise_conv.weight\", \"model.encoder._blocks.14._bn1.weight\", \"model.encoder._blocks.14._bn1.bias\", \"model.encoder._blocks.14._bn1.running_mean\", \"model.encoder._blocks.14._bn1.running_var\", \"model.encoder._blocks.14._se_reduce.weight\", \"model.encoder._blocks.14._se_reduce.bias\", \"model.encoder._blocks.14._se_expand.weight\", \"model.encoder._blocks.14._se_expand.bias\", \"model.encoder._blocks.14._project_conv.weight\", \"model.encoder._blocks.14._bn2.weight\", \"model.encoder._blocks.14._bn2.bias\", \"model.encoder._blocks.14._bn2.running_mean\", \"model.encoder._blocks.14._bn2.running_var\", \"model.encoder._blocks.15._expand_conv.weight\", \"model.encoder._blocks.15._bn0.weight\", \"model.encoder._blocks.15._bn0.bias\", \"model.encoder._blocks.15._bn0.running_mean\", \"model.encoder._blocks.15._bn0.running_var\", \"model.encoder._blocks.15._depthwise_conv.weight\", \"model.encoder._blocks.15._bn1.weight\", \"model.encoder._blocks.15._bn1.bias\", \"model.encoder._blocks.15._bn1.running_mean\", \"model.encoder._blocks.15._bn1.running_var\", \"model.encoder._blocks.15._se_reduce.weight\", \"model.encoder._blocks.15._se_reduce.bias\", \"model.encoder._blocks.15._se_expand.weight\", \"model.encoder._blocks.15._se_expand.bias\", \"model.encoder._blocks.15._project_conv.weight\", \"model.encoder._blocks.15._bn2.weight\", \"model.encoder._blocks.15._bn2.bias\", \"model.encoder._blocks.15._bn2.running_mean\", \"model.encoder._blocks.15._bn2.running_var\", \"model.encoder._conv_head.weight\", \"model.encoder._bn1.weight\", \"model.encoder._bn1.bias\", \"model.encoder._bn1.running_mean\", \"model.encoder._bn1.running_var\", \"model.decoder.blocks.0.conv1.0.weight\", \"model.decoder.blocks.0.conv1.1.weight\", \"model.decoder.blocks.0.conv1.1.bias\", \"model.decoder.blocks.0.conv1.1.running_mean\", \"model.decoder.blocks.0.conv1.1.running_var\", \"model.decoder.blocks.0.conv2.0.weight\", \"model.decoder.blocks.0.conv2.1.weight\", \"model.decoder.blocks.0.conv2.1.bias\", \"model.decoder.blocks.0.conv2.1.running_mean\", \"model.decoder.blocks.0.conv2.1.running_var\", \"model.decoder.blocks.1.conv1.0.weight\", \"model.decoder.blocks.1.conv1.1.weight\", \"model.decoder.blocks.1.conv1.1.bias\", \"model.decoder.blocks.1.conv1.1.running_mean\", \"model.decoder.blocks.1.conv1.1.running_var\", \"model.decoder.blocks.1.conv2.0.weight\", \"model.decoder.blocks.1.conv2.1.weight\", \"model.decoder.blocks.1.conv2.1.bias\", \"model.decoder.blocks.1.conv2.1.running_mean\", \"model.decoder.blocks.1.conv2.1.running_var\", \"model.decoder.blocks.2.conv1.0.weight\", \"model.decoder.blocks.2.conv1.1.weight\", \"model.decoder.blocks.2.conv1.1.bias\", \"model.decoder.blocks.2.conv1.1.running_mean\", \"model.decoder.blocks.2.conv1.1.running_var\", \"model.decoder.blocks.2.conv2.0.weight\", \"model.decoder.blocks.2.conv2.1.weight\", \"model.decoder.blocks.2.conv2.1.bias\", \"model.decoder.blocks.2.conv2.1.running_mean\", \"model.decoder.blocks.2.conv2.1.running_var\", \"model.decoder.blocks.3.conv1.0.weight\", \"model.decoder.blocks.3.conv1.1.weight\", \"model.decoder.blocks.3.conv1.1.bias\", \"model.decoder.blocks.3.conv1.1.running_mean\", \"model.decoder.blocks.3.conv1.1.running_var\", \"model.decoder.blocks.3.conv2.0.weight\", \"model.decoder.blocks.3.conv2.1.weight\", \"model.decoder.blocks.3.conv2.1.bias\", \"model.decoder.blocks.3.conv2.1.running_mean\", \"model.decoder.blocks.3.conv2.1.running_var\", \"model.decoder.blocks.4.conv1.0.weight\", \"model.decoder.blocks.4.conv1.1.weight\", \"model.decoder.blocks.4.conv1.1.bias\", \"model.decoder.blocks.4.conv1.1.running_mean\", \"model.decoder.blocks.4.conv1.1.running_var\", \"model.decoder.blocks.4.conv2.0.weight\", \"model.decoder.blocks.4.conv2.1.weight\", \"model.decoder.blocks.4.conv2.1.bias\", \"model.decoder.blocks.4.conv2.1.running_mean\", \"model.decoder.blocks.4.conv2.1.running_var\", \"model.segmentation_head.0.weight\", \"model.segmentation_head.0.bias\". \n",
            "\tUnexpected key(s) in state_dict: \"backbone.logits.conv3d.weight\", \"backbone.logits.conv3d.bias\", \"backbone.Conv3d_1a_7x7.conv3d.weight\", \"backbone.Conv3d_1a_7x7.bn.weight\", \"backbone.Conv3d_1a_7x7.bn.bias\", \"backbone.Conv3d_1a_7x7.bn.running_mean\", \"backbone.Conv3d_1a_7x7.bn.running_var\", \"backbone.Conv3d_1a_7x7.bn.num_batches_tracked\", \"backbone.Conv3d_2b_1x1.conv3d.weight\", \"backbone.Conv3d_2b_1x1.bn.weight\", \"backbone.Conv3d_2b_1x1.bn.bias\", \"backbone.Conv3d_2b_1x1.bn.running_mean\", \"backbone.Conv3d_2b_1x1.bn.running_var\", \"backbone.Conv3d_2b_1x1.bn.num_batches_tracked\", \"backbone.Conv3d_2c_3x3.conv3d.weight\", \"backbone.Conv3d_2c_3x3.bn.weight\", \"backbone.Conv3d_2c_3x3.bn.bias\", \"backbone.Conv3d_2c_3x3.bn.running_mean\", \"backbone.Conv3d_2c_3x3.bn.running_var\", \"backbone.Conv3d_2c_3x3.bn.num_batches_tracked\", \"backbone.Mixed_3b.b0.conv3d.weight\", \"backbone.Mixed_3b.b0.bn.weight\", \"backbone.Mixed_3b.b0.bn.bias\", \"backbone.Mixed_3b.b0.bn.running_mean\", \"backbone.Mixed_3b.b0.bn.running_var\", \"backbone.Mixed_3b.b0.bn.num_batches_tracked\", \"backbone.Mixed_3b.b1a.conv3d.weight\", \"backbone.Mixed_3b.b1a.bn.weight\", \"backbone.Mixed_3b.b1a.bn.bias\", \"backbone.Mixed_3b.b1a.bn.running_mean\", \"backbone.Mixed_3b.b1a.bn.running_var\", \"backbone.Mixed_3b.b1a.bn.num_batches_tracked\", \"backbone.Mixed_3b.b1b.conv3d.weight\", \"backbone.Mixed_3b.b1b.bn.weight\", \"backbone.Mixed_3b.b1b.bn.bias\", \"backbone.Mixed_3b.b1b.bn.running_mean\", \"backbone.Mixed_3b.b1b.bn.running_var\", \"backbone.Mixed_3b.b1b.bn.num_batches_tracked\", \"backbone.Mixed_3b.b2a.conv3d.weight\", \"backbone.Mixed_3b.b2a.bn.weight\", \"backbone.Mixed_3b.b2a.bn.bias\", \"backbone.Mixed_3b.b2a.bn.running_mean\", \"backbone.Mixed_3b.b2a.bn.running_var\", \"backbone.Mixed_3b.b2a.bn.num_batches_tracked\", \"backbone.Mixed_3b.b2b.conv3d.weight\", \"backbone.Mixed_3b.b2b.bn.weight\", \"backbone.Mixed_3b.b2b.bn.bias\", \"backbone.Mixed_3b.b2b.bn.running_mean\", \"backbone.Mixed_3b.b2b.bn.running_var\", \"backbone.Mixed_3b.b2b.bn.num_batches_tracked\", \"backbone.Mixed_3b.b3b.conv3d.weight\", \"backbone.Mixed_3b.b3b.bn.weight\", \"backbone.Mixed_3b.b3b.bn.bias\", \"backbone.Mixed_3b.b3b.bn.running_mean\", \"backbone.Mixed_3b.b3b.bn.running_var\", \"backbone.Mixed_3b.b3b.bn.num_batches_tracked\", \"backbone.Mixed_3c.b0.conv3d.weight\", \"backbone.Mixed_3c.b0.bn.weight\", \"backbone.Mixed_3c.b0.bn.bias\", \"backbone.Mixed_3c.b0.bn.running_mean\", \"backbone.Mixed_3c.b0.bn.running_var\", \"backbone.Mixed_3c.b0.bn.num_batches_tracked\", \"backbone.Mixed_3c.b1a.conv3d.weight\", \"backbone.Mixed_3c.b1a.bn.weight\", \"backbone.Mixed_3c.b1a.bn.bias\", \"backbone.Mixed_3c.b1a.bn.running_mean\", \"backbone.Mixed_3c.b1a.bn.running_var\", \"backbone.Mixed_3c.b1a.bn.num_batches_tracked\", \"backbone.Mixed_3c.b1b.conv3d.weight\", \"backbone.Mixed_3c.b1b.bn.weight\", \"backbone.Mixed_3c.b1b.bn.bias\", \"backbone.Mixed_3c.b1b.bn.running_mean\", \"backbone.Mixed_3c.b1b.bn.running_var\", \"backbone.Mixed_3c.b1b.bn.num_batches_tracked\", \"backbone.Mixed_3c.b2a.conv3d.weight\", \"backbone.Mixed_3c.b2a.bn.weight\", \"backbone.Mixed_3c.b2a.bn.bias\", \"backbone.Mixed_3c.b2a.bn.running_mean\", \"backbone.Mixed_3c.b2a.bn.running_var\", \"backbone.Mixed_3c.b2a.bn.num_batches_tracked\", \"backbone.Mixed_3c.b2b.conv3d.weight\", \"backbone.Mixed_3c.b2b.bn.weight\", \"backbone.Mixed_3c.b2b.bn.bias\", \"backbone.Mixed_3c.b2b.bn.running_mean\", \"backbone.Mixed_3c.b2b.bn.running_var\", \"backbone.Mixed_3c.b2b.bn.num_batches_tracked\", \"backbone.Mixed_3c.b3b.conv3d.weight\", \"backbone.Mixed_3c.b3b.bn.weight\", \"backbone.Mixed_3c.b3b.bn.bias\", \"backbone.Mixed_3c.b3b.bn.running_mean\", \"backbone.Mixed_3c.b3b.bn.running_var\", \"backbone.Mixed_3c.b3b.bn.num_batches_tracked\", \"backbone.Mixed_4b.b0.conv3d.weight\", \"backbone.Mixed_4b.b0.bn.weight\", \"backbone.Mixed_4b.b0.bn.bias\", \"backbone.Mixed_4b.b0.bn.running_mean\", \"backbone.Mixed_4b.b0.bn.running_var\", \"backbone.Mixed_4b.b0.bn.num_batches_tracked\", \"backbone.Mixed_4b.b1a.conv3d.weight\", \"backbone.Mixed_4b.b1a.bn.weight\", \"backbone.Mixed_4b.b1a.bn.bias\", \"backbone.Mixed_4b.b1a.bn.running_mean\", \"backbone.Mixed_4b.b1a.bn.running_var\", \"backbone.Mixed_4b.b1a.bn.num_batches_tracked\", \"backbone.Mixed_4b.b1b.conv3d.weight\", \"backbone.Mixed_4b.b1b.bn.weight\", \"backbone.Mixed_4b.b1b.bn.bias\", \"backbone.Mixed_4b.b1b.bn.running_mean\", \"backbone.Mixed_4b.b1b.bn.running_var\", \"backbone.Mixed_4b.b1b.bn.num_batches_tracked\", \"backbone.Mixed_4b.b2a.conv3d.weight\", \"backbone.Mixed_4b.b2a.bn.weight\", \"backbone.Mixed_4b.b2a.bn.bias\", \"backbone.Mixed_4b.b2a.bn.running_mean\", \"backbone.Mixed_4b.b2a.bn.running_var\", \"backbone.Mixed_4b.b2a.bn.num_batches_tracked\", \"backbone.Mixed_4b.b2b.conv3d.weight\", \"backbone.Mixed_4b.b2b.bn.weight\", \"backbone.Mixed_4b.b2b.bn.bias\", \"backbone.Mixed_4b.b2b.bn.running_mean\", \"backbone.Mixed_4b.b2b.bn.running_var\", \"backbone.Mixed_4b.b2b.bn.num_batches_tracked\", \"backbone.Mixed_4b.b3b.conv3d.weight\", \"backbone.Mixed_4b.b3b.bn.weight\", \"backbone.Mixed_4b.b3b.bn.bias\", \"backbone.Mixed_4b.b3b.bn.running_mean\", \"backbone.Mixed_4b.b3b.bn.running_var\", \"backbone.Mixed_4b.b3b.bn.num_batches_tracked\", \"backbone.Mixed_4c.b0.conv3d.weight\", \"backbone.Mixed_4c.b0.bn.weight\", \"backbone.Mixed_4c.b0.bn.bias\", \"backbone.Mixed_4c.b0.bn.running_mean\", \"backbone.Mixed_4c.b0.bn.running_var\", \"backbone.Mixed_4c.b0.bn.num_batches_tracked\", \"backbone.Mixed_4c.b1a.conv3d.weight\", \"backbone.Mixed_4c.b1a.bn.weight\", \"backbone.Mixed_4c.b1a.bn.bias\", \"backbone.Mixed_4c.b1a.bn.running_mean\", \"backbone.Mixed_4c.b1a.bn.running_var\", \"backbone.Mixed_4c.b1a.bn.num_batches_tracked\", \"backbone.Mixed_4c.b1b.conv3d.weight\", \"backbone.Mixed_4c.b1b.bn.weight\", \"backbone.Mixed_4c.b1b.bn.bias\", \"backbone.Mixed_4c.b1b.bn.running_mean\", \"backbone.Mixed_4c.b1b.bn.running_var\", \"backbone.Mixed_4c.b1b.bn.num_batches_tracked\", \"backbone.Mixed_4c.b2a.conv3d.weight\", \"backbone.Mixed_4c.b2a.bn.weight\", \"backbone.Mixed_4c.b2a.bn.bias\", \"backbone.Mixed_4c.b2a.bn.running_mean\", \"backbone.Mixed_4c.b2a.bn.running_var\", \"backbone.Mixed_4c.b2a.bn.num_batches_tracked\", \"backbone.Mixed_4c.b2b.conv3d.weight\", \"backbone.Mixed_4c.b2b.bn.weight\", \"backbone.Mixed_4c.b2b.bn.bias\", \"backbone.Mixed_4c.b2b.bn.running_mean\", \"backbone.Mixed_4c.b2b.bn.running_var\", \"backbone.Mixed_4c.b2b.bn.num_batches_tracked\", \"backbone.Mixed_4c.b3b.conv3d.weight\", \"backbone.Mixed_4c.b3b.bn.weight\", \"backbone.Mixed_4c.b3b.bn.bias\", \"backbone.Mixed_4c.b3b.bn.running_mean\", \"backbone.Mixed_4c.b3b.bn.running_var\", \"backbone.Mixed_4c.b3b.bn.num_batches_tracked\", \"backbone.Mixed_4d.b0.conv3d.weight\", \"backbone.Mixed_4d.b0.bn.weight\", \"backbone.Mixed_4d.b0.bn.bias\", \"backbone.Mixed_4d.b0.bn.running_mean\", \"backbone.Mixed_4d.b0.bn.running_var\", \"backbone.Mixed_4d.b0.bn.num_batches_tracked\", \"backbone.Mixed_4d.b1a.conv3d.weight\", \"backbone.Mixed_4d.b1a.bn.weight\", \"backbone.Mixed_4d.b1a.bn.bias\", \"backbone.Mixed_4d.b1a.bn.running_mean\", \"backbone.Mixed_4d.b1a.bn.running_var\", \"backbone.Mixed_4d.b1a.bn.num_batches_tracked\", \"backbone.Mixed_4d.b1b.conv3d.weight\", \"backbone.Mixed_4d.b1b.bn.weight\", \"backbone.Mixed_4d.b1b.bn.bias\", \"backbone.Mixed_4d.b1b.bn.running_mean\", \"backbone.Mixed_4d.b1b.bn.running_var\", \"backbone.Mixed_4d.b1b.bn.num_batches_tracked\", \"backbone.Mixed_4d.b2a.conv3d.weight\", \"backbone.Mixed_4d.b2a.bn.weight\", \"backbone.Mixed_4d.b2a.bn.bias\", \"backbone.Mixed_4d.b2a.bn.running_mean\", \"backbone.Mixed_4d.b2a.bn.running_var\", \"backbone.Mixed_4d.b2a.bn.num_batches_tracked\", \"backbone.Mixed_4d.b2b.conv3d.weight\", \"backbone.Mixed_4d.b2b.bn.weight\", \"backbone.Mixed_4d.b2b.bn.bias\", \"backbone.Mixed_4d.b2b.bn.running_mean\", \"backbone.Mixed_4d.b2b.bn.running_var\", \"backbone.Mixed_4d.b2b.bn.num_batches_tracked\", \"backbone.Mixed_4d.b3b.conv3d.weight\", \"backbone.Mixed_4d.b3b.bn.weight\", \"backbone.Mixed_4d.b3b.bn.bias\", \"backbone.Mixed_4d.b3b.bn.running_mean\", \"backbone.Mixed_4d.b3b.bn.running_var\", \"backbone.Mixed_4d.b3b.bn.num_batches_tracked\", \"backbone.Mixed_4e.b0.conv3d.weight\", \"backbone.Mixed_4e.b0.bn.weight\", \"backbone.Mixed_4e.b0.bn.bias\", \"backbone.Mixed_4e.b0.bn.running_mean\", \"backbone.Mixed_4e.b0.bn.running_var\", \"backbone.Mixed_4e.b0.bn.num_batches_tracked\", \"backbone.Mixed_4e.b1a.conv3d.weight\", \"backbone.Mixed_4e.b1a.bn.weight\", \"backbone.Mixed_4e.b1a.bn.bias\", \"backbone.Mixed_4e.b1a.bn.running_mean\", \"backbone.Mixed_4e.b1a.bn.running_var\", \"backbone.Mixed_4e.b1a.bn.num_batches_tracked\", \"backbone.Mixed_4e.b1b.conv3d.weight\", \"backbone.Mixed_4e.b1b.bn.weight\", \"backbone.Mixed_4e.b1b.bn.bias\", \"backbone.Mixed_4e.b1b.bn.running_mean\", \"backbone.Mixed_4e.b1b.bn.running_var\", \"backbone.Mixed_4e.b1b.bn.num_batches_tracked\", \"backbone.Mixed_4e.b2a.conv3d.weight\", \"backbone.Mixed_4e.b2a.bn.weight\", \"backbone.Mixed_4e.b2a.bn.bias\", \"backbone.Mixed_4e.b2a.bn.running_mean\", \"backbone.Mixed_4e.b2a.bn.running_var\", \"backbone.Mixed_4e.b2a.bn.num_batches_tracked\", \"backbone.Mixed_4e.b2b.conv3d.weight\", \"backbone.Mixed_4e.b2b.bn.weight\", \"backbone.Mixed_4e.b2b.bn.bias\", \"backbone.Mixed_4e.b2b.bn.running_mean\", \"backbone.Mixed_4e.b2b.bn.running_var\", \"backbone.Mixed_4e.b2b.bn.num_batches_tracked\", \"backbone.Mixed_4e.b3b.conv3d.weight\", \"backbone.Mixed_4e.b3b.bn.weight\", \"backbone.Mixed_4e.b3b.bn.bias\", \"backbone.Mixed_4e.b3b.bn.running_mean\", \"backbone.Mixed_4e.b3b.bn.running_var\", \"backbone.Mixed_4e.b3b.bn.num_batches_tracked\", \"backbone.Mixed_4f.b0.conv3d.weight\", \"backbone.Mixed_4f.b0.bn.weight\", \"backbone.Mixed_4f.b0.bn.bias\", \"backbone.Mixed_4f.b0.bn.running_mean\", \"backbone.Mixed_4f.b0.bn.running_var\", \"backbone.Mixed_4f.b0.bn.num_batches_tracked\", \"backbone.Mixed_4f.b1a.conv3d.weight\", \"backbone.Mixed_4f.b1a.bn.weight\", \"backbone.Mixed_4f.b1a.bn.bias\", \"backbone.Mixed_4f.b1a.bn.running_mean\", \"backbone.Mixed_4f.b1a.bn.running_var\", \"backbone.Mixed_4f.b1a.bn.num_batches_tracked\", \"backbone.Mixed_4f.b1b.conv3d.weight\", \"backbone.Mixed_4f.b1b.bn.weight\", \"backbone.Mixed_4f.b1b.bn.bias\", \"backbone.Mixed_4f.b1b.bn.running_mean\", \"backbone.Mixed_4f.b1b.bn.running_var\", \"backbone.Mixed_4f.b1b.bn.num_batches_tracked\", \"backbone.Mixed_4f.b2a.conv3d.weight\", \"backbone.Mixed_4f.b2a.bn.weight\", \"backbone.Mixed_4f.b2a.bn.bias\", \"backbone.Mixed_4f.b2a.bn.running_mean\", \"backbone.Mixed_4f.b2a.bn.running_var\", \"backbone.Mixed_4f.b2a.bn.num_batches_tracked\", \"backbone.Mixed_4f.b2b.conv3d.weight\", \"backbone.Mixed_4f.b2b.bn.weight\", \"backbone.Mixed_4f.b2b.bn.bias\", \"backbone.Mixed_4f.b2b.bn.running_mean\", \"backbone.Mixed_4f.b2b.bn.running_var\", \"backbone.Mixed_4f.b2b.bn.num_batches_tracked\", \"backbone.Mixed_4f.b3b.conv3d.weight\", \"backbone.Mixed_4f.b3b.bn.weight\", \"backbone.Mixed_4f.b3b.bn.bias\", \"backbone.Mixed_4f.b3b.bn.running_mean\", \"backbone.Mixed_4f.b3b.bn.running_var\", \"backbone.Mixed_4f.b3b.bn.num_batches_tracked\", \"backbone.Mixed_5b.b0.conv3d.weight\", \"backbone.Mixed_5b.b0.bn.weight\", \"backbone.Mixed_5b.b0.bn.bias\", \"backbone.Mixed_5b.b0.bn.running_mean\", \"backbone.Mixed_5b.b0.bn.running_var\", \"backbone.Mixed_5b.b0.bn.num_batches_tracked\", \"backbone.Mixed_5b.b1a.conv3d.weight\", \"backbone.Mixed_5b.b1a.bn.weight\", \"backbone.Mixed_5b.b1a.bn.bias\", \"backbone.Mixed_5b.b1a.bn.running_mean\", \"backbone.Mixed_5b.b1a.bn.running_var\", \"backbone.Mixed_5b.b1a.bn.num_batches_tracked\", \"backbone.Mixed_5b.b1b.conv3d.weight\", \"backbone.Mixed_5b.b1b.bn.weight\", \"backbone.Mixed_5b.b1b.bn.bias\", \"backbone.Mixed_5b.b1b.bn.running_mean\", \"backbone.Mixed_5b.b1b.bn.running_var\", \"backbone.Mixed_5b.b1b.bn.num_batches_tracked\", \"backbone.Mixed_5b.b2a.conv3d.weight\", \"backbone.Mixed_5b.b2a.bn.weight\", \"backbone.Mixed_5b.b2a.bn.bias\", \"backbone.Mixed_5b.b2a.bn.running_mean\", \"backbone.Mixed_5b.b2a.bn.running_var\", \"backbone.Mixed_5b.b2a.bn.num_batches_tracked\", \"backbone.Mixed_5b.b2b.conv3d.weight\", \"backbone.Mixed_5b.b2b.bn.weight\", \"backbone.Mixed_5b.b2b.bn.bias\", \"backbone.Mixed_5b.b2b.bn.running_mean\", \"backbone.Mixed_5b.b2b.bn.running_var\", \"backbone.Mixed_5b.b2b.bn.num_batches_tracked\", \"backbone.Mixed_5b.b3b.conv3d.weight\", \"backbone.Mixed_5b.b3b.bn.weight\", \"backbone.Mixed_5b.b3b.bn.bias\", \"backbone.Mixed_5b.b3b.bn.running_mean\", \"backbone.Mixed_5b.b3b.bn.running_var\", \"backbone.Mixed_5b.b3b.bn.num_batches_tracked\", \"backbone.Mixed_5c.b0.conv3d.weight\", \"backbone.Mixed_5c.b0.bn.weight\", \"backbone.Mixed_5c.b0.bn.bias\", \"backbone.Mixed_5c.b0.bn.running_mean\", \"backbone.Mixed_5c.b0.bn.running_var\", \"backbone.Mixed_5c.b0.bn.num_batches_tracked\", \"backbone.Mixed_5c.b1a.conv3d.weight\", \"backbone.Mixed_5c.b1a.bn.weight\", \"backbone.Mixed_5c.b1a.bn.bias\", \"backbone.Mixed_5c.b1a.bn.running_mean\", \"backbone.Mixed_5c.b1a.bn.running_var\", \"backbone.Mixed_5c.b1a.bn.num_batches_tracked\", \"backbone.Mixed_5c.b1b.conv3d.weight\", \"backbone.Mixed_5c.b1b.bn.weight\", \"backbone.Mixed_5c.b1b.bn.bias\", \"backbone.Mixed_5c.b1b.bn.running_mean\", \"backbone.Mixed_5c.b1b.bn.running_var\", \"backbone.Mixed_5c.b1b.bn.num_batches_tracked\", \"backbone.Mixed_5c.b2a.conv3d.weight\", \"backbone.Mixed_5c.b2a.bn.weight\", \"backbone.Mixed_5c.b2a.bn.bias\", \"backbone.Mixed_5c.b2a.bn.running_mean\", \"backbone.Mixed_5c.b2a.bn.running_var\", \"backbone.Mixed_5c.b2a.bn.num_batches_tracked\", \"backbone.Mixed_5c.b2b.conv3d.weight\", \"backbone.Mixed_5c.b2b.bn.weight\", \"backbone.Mixed_5c.b2b.bn.bias\", \"backbone.Mixed_5c.b2b.bn.running_mean\", \"backbone.Mixed_5c.b2b.bn.running_var\", \"backbone.Mixed_5c.b2b.bn.num_batches_tracked\", \"backbone.Mixed_5c.b3b.conv3d.weight\", \"backbone.Mixed_5c.b3b.bn.weight\", \"backbone.Mixed_5c.b3b.bn.bias\", \"backbone.Mixed_5c.b3b.bn.running_mean\", \"backbone.Mixed_5c.b3b.bn.running_var\", \"backbone.Mixed_5c.b3b.bn.num_batches_tracked\", \"decoder.convs.0.0.weight\", \"decoder.convs.0.1.weight\", \"decoder.convs.0.1.bias\", \"decoder.convs.0.1.running_mean\", \"decoder.convs.0.1.running_var\", \"decoder.convs.0.1.num_batches_tracked\", \"decoder.convs.1.0.weight\", \"decoder.convs.1.1.weight\", \"decoder.convs.1.1.bias\", \"decoder.convs.1.1.running_mean\", \"decoder.convs.1.1.running_var\", \"decoder.convs.1.1.num_batches_tracked\", \"decoder.convs.2.0.weight\", \"decoder.convs.2.1.weight\", \"decoder.convs.2.1.bias\", \"decoder.convs.2.1.running_mean\", \"decoder.convs.2.1.running_var\", \"decoder.convs.2.1.num_batches_tracked\", \"decoder.logit.weight\", \"decoder.logit.bias\". \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/64x64_256stride_i3d_1667_7a.py\", line 427, in <module>\n",
            "    train_loop()\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/64x64_256stride_i3d_1667_7a.py\", line 416, in train_loop\n",
            "    model = BuildEngine.load_from_checkpoint(CFG.model_dir + \"valid_20230827161847_0_fr_i3depoch=7.ckpt\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1543, in load_from_checkpoint\n",
            "    loaded = _load_from_checkpoint(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 91, in _load_from_checkpoint\n",
            "    model = _load_state(cls, checkpoint, strict=strict, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 157, in _load_state\n",
            "    keys = obj.load_state_dict(checkpoint[\"state_dict\"], strict=strict)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2189, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for BuildEngine:\n",
            "\tMissing key(s) in state_dict: \"model.encoder._conv_stem.weight\", \"model.encoder._bn0.weight\", \"model.encoder._bn0.bias\", \"model.encoder._bn0.running_mean\", \"model.encoder._bn0.running_var\", \"model.encoder._blocks.0._depthwise_conv.weight\", \"model.encoder._blocks.0._bn1.weight\", \"model.encoder._blocks.0._bn1.bias\", \"model.encoder._blocks.0._bn1.running_mean\", \"model.encoder._blocks.0._bn1.running_var\", \"model.encoder._blocks.0._se_reduce.weight\", \"model.encoder._blocks.0._se_reduce.bias\", \"model.encoder._blocks.0._se_expand.weight\", \"model.encoder._blocks.0._se_expand.bias\", \"model.encoder._blocks.0._project_conv.weight\", \"model.encoder._blocks.0._bn2.weight\", \"model.encoder._blocks.0._bn2.bias\", \"model.encoder._blocks.0._bn2.running_mean\", \"model.encoder._blocks.0._bn2.running_var\", \"model.encoder._blocks.1._expand_conv.weight\", \"model.encoder._blocks.1._bn0.weight\", \"model.encoder._blocks.1._bn0.bias\", \"model.encoder._blocks.1._bn0.running_mean\", \"model.encoder._blocks.1._bn0.running_var\", \"model.encoder._blocks.1._depthwise_conv.weight\", \"model.encoder._blocks.1._bn1.weight\", \"model.encoder._blocks.1._bn1.bias\", \"model.encoder._blocks.1._bn1.running_mean\", \"model.encoder._blocks.1._bn1.running_var\", \"model.encoder._blocks.1._se_reduce.weight\", \"model.encoder._blocks.1._se_reduce.bias\", \"model.encoder._blocks.1._se_expand.weight\", \"model.encoder._blocks.1._se_expand.bias\", \"model.encoder._blocks.1._project_conv.weight\", \"model.encoder._blocks.1._bn2.weight\", \"model.encoder._blocks.1._bn2.bias\", \"model.encoder._blocks.1._bn2.running_mean\", \"model.encoder._blocks.1._bn2.running_var\", \"model.encoder._blocks.2._expand_conv.weight\", \"model.encoder._blocks.2._bn0.weight\", \"model.encoder._blocks.2._bn0.bias\", \"model.encoder._blocks.2._bn0.running_mean\", \"model.encoder._blocks.2._bn0.running_var\", \"model.encoder._blocks.2._depthwise_conv.weight\", \"model.encoder._blocks.2._bn1.weight\", \"model.encoder._blocks.2._bn1.bias\", \"model.encoder._blocks.2._bn1.running_mean\", \"model.encoder._blocks.2._bn1.running_var\", \"model.encoder._blocks.2._se_reduce.weight\", \"model.encoder._blocks.2._se_reduce.bias\", \"model.encoder._blocks.2._se_expand.weight\", \"model.encoder._blocks.2._se_expand.bias\", \"model.encoder._blocks.2._project_conv.weight\", \"model.encoder._blocks.2._bn2.weight\", \"model.encoder._blocks.2._bn2.bias\", \"model.encoder._blocks.2._bn2.running_mean\", \"model.encoder._blocks.2._bn2.running_var\", \"model.encoder._blocks.3._expand_conv.weight\", \"model.encoder._blocks.3._bn0.weight\", \"model.encoder._blocks.3._bn0.bias\", \"model.encoder._blocks.3._bn0.running_mean\", \"model.encoder._blocks.3._bn0.running_var\", \"model.encoder._blocks.3._depthwise_conv.weight\", \"model.encoder._blocks.3._bn1.weight\", \"model.encoder._blocks.3._bn1.bias\", \"model.encoder._blocks.3._bn1.running_mean\", \"model.encoder._blocks.3._bn1.running_var\", \"model.encoder._blocks.3._se_reduce.weight\", \"model.encoder._blocks.3._se_reduce.bias\", \"model.encoder._blocks.3._se_expand.weight\", \"model.encoder._blocks.3._se_expand.bias\", \"model.encoder._blocks.3._project_conv.weight\", \"model.encoder._blocks.3._bn2.weight\", \"model.encoder._blocks.3._bn2.bias\", \"model.encoder._blocks.3._bn2.running_mean\", \"model.encoder._blocks.3._bn2.running_var\", \"model.encoder._blocks.4._expand_conv.weight\", \"model.encoder._blocks.4._bn0.weight\", \"model.encoder._blocks.4._bn0.bias\", \"model.encoder._blocks.4._bn0.running_mean\", \"model.encoder._blocks.4._bn0.running_var\", \"model.encoder._blocks.4._depthwise_conv.weight\", \"model.encoder._blocks.4._bn1.weight\", \"model.encoder._blocks.4._bn1.bias\", \"model.encoder._blocks.4._bn1.running_mean\", \"model.encoder._blocks.4._bn1.running_var\", \"model.encoder._blocks.4._se_reduce.weight\", \"model.encoder._blocks.4._se_reduce.bias\", \"model.encoder._blocks.4._se_expand.weight\", \"model.encoder._blocks.4._se_expand.bias\", \"model.encoder._blocks.4._project_conv.weight\", \"model.encoder._blocks.4._bn2.weight\", \"model.encoder._blocks.4._bn2.bias\", \"model.encoder._blocks.4._bn2.running_mean\", \"model.encoder._blocks.4._bn2.running_var\", \"model.encoder._blocks.5._expand_conv.weight\", \"model.encoder._blocks.5._bn0.weight\", \"model.encoder._blocks.5._bn0.bias\", \"model.encoder._blocks.5._bn0.running_mean\", \"model.encoder._blocks.5._bn0.running_var\", \"model.encoder._blocks.5._depthwise_conv.weight\", \"model.encoder._blocks.5._bn1.weight\", \"model.encoder._blocks.5._bn1.bias\", \"model.encoder._blocks.5._bn1.running_mean\", \"model.encoder._blocks.5._bn1.running_var\", \"model.encoder._blocks.5._se_reduce.weight\", \"model.encoder._blocks.5._se_reduce.bias\", \"model.encoder._blocks.5._se_expand.weight\", \"model.encoder._blocks.5._se_expand.bias\", \"model.encoder._blocks.5._project_conv.weight\", \"model.encoder._blocks.5._bn2.weight\", \"model.encoder._blocks.5._bn2.bias\", \"model.encoder._blocks.5._bn2.running_mean\", \"model.encoder._blocks.5._bn2.running_var\", \"model.encoder._blocks.6._expand_conv.weight\", \"model.encoder._blocks.6._bn0.weight\", \"model.encoder._blocks.6._bn0.bias\", \"model.encoder._blocks.6._bn0.running_mean\", \"model.encoder._blocks.6._bn0.running_var\", \"model.encoder._blocks.6._depthwise_conv.weight\", \"model.encoder._blocks.6._bn1.weight\", \"model.encoder._blocks.6._bn1.bias\", \"model.encoder._blocks.6._bn1.running_mean\", \"model.encoder._blocks.6._bn1.running_var\", \"model.encoder._blocks.6._se_reduce.weight\", \"model.encoder._blocks.6._se_reduce.bias\", \"model.encoder._blocks.6._se_expand.weight\", \"model.encoder._blocks.6._se_expand.bias\", \"model.encoder._blocks.6._project_conv.weight\", \"model.encoder._blocks.6._bn2.weight\", \"model.encoder._blocks.6._bn2.bias\", \"model.encoder._blocks.6._bn2.running_mean\", \"model.encoder._blocks.6._bn2.running_var\", \"model.encoder._blocks.7._expand_conv.weight\", \"model.encoder._blocks.7._bn0.weight\", \"model.encoder._blocks.7._bn0.bias\", \"model.encoder._blocks.7._bn0.running_mean\", \"model.encoder._blocks.7._bn0.running_var\", \"model.encoder._blocks.7._depthwise_conv.weight\", \"model.encoder._blocks.7._bn1.weight\", \"model.encoder._blocks.7._bn1.bias\", \"model.encoder._blocks.7._bn1.running_mean\", \"model.encoder._blocks.7._bn1.running_var\", \"model.encoder._blocks.7._se_reduce.weight\", \"model.encoder._blocks.7._se_reduce.bias\", \"model.encoder._blocks.7._se_expand.weight\", \"model.encoder._blocks.7._se_expand.bias\", \"model.encoder._blocks.7._project_conv.weight\", \"model.encoder._blocks.7._bn2.weight\", \"model.encoder._blocks.7._bn2.bias\", \"model.encoder._blocks.7._bn2.running_mean\", \"model.encoder._blocks.7._bn2.running_var\", \"model.encoder._blocks.8._expand_conv.weight\", \"model.encoder._blocks.8._bn0.weight\", \"model.encoder._blocks.8._bn0.bias\", \"model.encoder._blocks.8._bn0.running_mean\", \"model.encoder._blocks.8._bn0.running_var\", \"model.encoder._blocks.8._depthwise_conv.weight\", \"model.encoder._blocks.8._bn1.weight\", \"model.encoder._blocks.8._bn1.bias\", \"model.encoder._blocks.8._bn1.running_mean\", \"model.encoder._blocks.8._bn1.running_var\", \"model.encoder._blocks.8._se_reduce.weight\", \"model.encoder._blocks.8._se_reduce.bias\", \"model.encoder._blocks.8._se_expand.weight\", \"model.encoder._blocks.8._se_expand.bias\", \"model.encoder._blocks.8._project_conv.weight\", \"model.encoder._blocks.8._bn2.weight\", \"model.encoder._blocks.8._bn2.bias\", \"model.encoder._blocks.8._bn2.running_mean\", \"model.encoder._blocks.8._bn2.running_var\", \"model.encoder._blocks.9._expand_conv.weight\", \"model.encoder._blocks.9._bn0.weight\", \"model.encoder._blocks.9._bn0.bias\", \"model.encoder._blocks.9._bn0.running_mean\", \"model.encoder._blocks.9._bn0.running_var\", \"model.encoder._blocks.9._depthwise_conv.weight\", \"model.encoder._blocks.9._bn1.weight\", \"model.encoder._blocks.9._bn1.bias\", \"model.encoder._blocks.9._bn1.running_mean\", \"model.encoder._blocks.9._bn1.running_var\", \"model.encoder._blocks.9._se_reduce.weight\", \"model.encoder._blocks.9._se_reduce.bias\", \"model.encoder._blocks.9._se_expand.weight\", \"model.encoder._blocks.9._se_expand.bias\", \"model.encoder._blocks.9._project_conv.weight\", \"model.encoder._blocks.9._bn2.weight\", \"model.encoder._blocks.9._bn2.bias\", \"model.encoder._blocks.9._bn2.running_mean\", \"model.encoder._blocks.9._bn2.running_var\", \"model.encoder._blocks.10._expand_conv.weight\", \"model.encoder._blocks.10._bn0.weight\", \"model.encoder._blocks.10._bn0.bias\", \"model.encoder._blocks.10._bn0.running_mean\", \"model.encoder._blocks.10._bn0.running_var\", \"model.encoder._blocks.10._depthwise_conv.weight\", \"model.encoder._blocks.10._bn1.weight\", \"model.encoder._blocks.10._bn1.bias\", \"model.encoder._blocks.10._bn1.running_mean\", \"model.encoder._blocks.10._bn1.running_var\", \"model.encoder._blocks.10._se_reduce.weight\", \"model.encoder._blocks.10._se_reduce.bias\", \"model.encoder._blocks.10._se_expand.weight\", \"model.encoder._blocks.10._se_expand.bias\", \"model.encoder._blocks.10._project_conv.weight\", \"model.encoder._blocks.10._bn2.weight\", \"model.encoder._blocks.10._bn2.bias\", \"model.encoder._blocks.10._bn2.running_mean\", \"model.encoder._blocks.10._bn2.running_var\", \"model.encoder._blocks.11._expand_conv.weight\", \"model.encoder._blocks.11._bn0.weight\", \"model.encoder._blocks.11._bn0.bias\", \"model.encoder._blocks.11._bn0.running_mean\", \"model.encoder._blocks.11._bn0.running_var\", \"model.encoder._blocks.11._depthwise_conv.weight\", \"model.encoder._blocks.11._bn1.weight\", \"model.encoder._blocks.11._bn1.bias\", \"model.encoder._blocks.11._bn1.running_mean\", \"model.encoder._blocks.11._bn1.running_var\", \"model.encoder._blocks.11._se_reduce.weight\", \"model.encoder._blocks.11._se_reduce.bias\", \"model.encoder._blocks.11._se_expand.weight\", \"model.encoder._blocks.11._se_expand.bias\", \"model.encoder._blocks.11._project_conv.weight\", \"model.encoder._blocks.11._bn2.weight\", \"model.encoder._blocks.11._bn2.bias\", \"model.encoder._blocks.11._bn2.running_mean\", \"model.encoder._blocks.11._bn2.running_var\", \"model.encoder._blocks.12._expand_conv.weight\", \"model.encoder._blocks.12._bn0.weight\", \"model.encoder._blocks.12._bn0.bias\", \"model.encoder._blocks.12._bn0.running_mean\", \"model.encoder._blocks.12._bn0.running_var\", \"model.encoder._blocks.12._depthwise_conv.weight\", \"model.encoder._blocks.12._bn1.weight\", \"model.encoder._blocks.12._bn1.bias\", \"model.encoder._blocks.12._bn1.running_mean\", \"model.encoder._blocks.12._bn1.running_var\", \"model.encoder._blocks.12._se_reduce.weight\", \"model.encoder._blocks.12._se_reduce.bias\", \"model.encoder._blocks.12._se_expand.weight\", \"model.encoder._blocks.12._se_expand.bias\", \"model.encoder._blocks.12._project_conv.weight\", \"model.encoder._blocks.12._bn2.weight\", \"model.encoder._blocks.12._bn2.bias\", \"model.encoder._blocks.12._bn2.running_mean\", \"model.encoder._blocks.12._bn2.running_var\", \"model.encoder._blocks.13._expand_conv.weight\", \"model.encoder._blocks.13._bn0.weight\", \"model.encoder._blocks.13._bn0.bias\", \"model.encoder._blocks.13._bn0.running_mean\", \"model.encoder._blocks.13._bn0.running_var\", \"model.encoder._blocks.13._depthwise_conv.weight\", \"model.encoder._blocks.13._bn1.weight\", \"model.encoder._blocks.13._bn1.bias\", \"model.encoder._blocks.13._bn1.running_mean\", \"model.encoder._blocks.13._bn1.running_var\", \"model.encoder._blocks.13._se_reduce.weight\", \"model.encoder._blocks.13._se_reduce.bias\", \"model.encoder._blocks.13._se_expand.weight\", \"model.encoder._blocks.13._se_expand.bias\", \"model.encoder._blocks.13._project_conv.weight\", \"model.encoder._blocks.13._bn2.weight\", \"model.encoder._blocks.13._bn2.bias\", \"model.encoder._blocks.13._bn2.running_mean\", \"model.encoder._blocks.13._bn2.running_var\", \"model.encoder._blocks.14._expand_conv.weight\", \"model.encoder._blocks.14._bn0.weight\", \"model.encoder._blocks.14._bn0.bias\", \"model.encoder._blocks.14._bn0.running_mean\", \"model.encoder._blocks.14._bn0.running_var\", \"model.encoder._blocks.14._depthwise_conv.weight\", \"model.encoder._blocks.14._bn1.weight\", \"model.encoder._blocks.14._bn1.bias\", \"model.encoder._blocks.14._bn1.running_mean\", \"model.encoder._blocks.14._bn1.running_var\", \"model.encoder._blocks.14._se_reduce.weight\", \"model.encoder._blocks.14._se_reduce.bias\", \"model.encoder._blocks.14._se_expand.weight\", \"model.encoder._blocks.14._se_expand.bias\", \"model.encoder._blocks.14._project_conv.weight\", \"model.encoder._blocks.14._bn2.weight\", \"model.encoder._blocks.14._bn2.bias\", \"model.encoder._blocks.14._bn2.running_mean\", \"model.encoder._blocks.14._bn2.running_var\", \"model.encoder._blocks.15._expand_conv.weight\", \"model.encoder._blocks.15._bn0.weight\", \"model.encoder._blocks.15._bn0.bias\", \"model.encoder._blocks.15._bn0.running_mean\", \"model.encoder._blocks.15._bn0.running_var\", \"model.encoder._blocks.15._depthwise_conv.weight\", \"model.encoder._blocks.15._bn1.weight\", \"model.encoder._blocks.15._bn1.bias\", \"model.encoder._blocks.15._bn1.running_mean\", \"model.encoder._blocks.15._bn1.running_var\", \"model.encoder._blocks.15._se_reduce.weight\", \"model.encoder._blocks.15._se_reduce.bias\", \"model.encoder._blocks.15._se_expand.weight\", \"model.encoder._blocks.15._se_expand.bias\", \"model.encoder._blocks.15._project_conv.weight\", \"model.encoder._blocks.15._bn2.weight\", \"model.encoder._blocks.15._bn2.bias\", \"model.encoder._blocks.15._bn2.running_mean\", \"model.encoder._blocks.15._bn2.running_var\", \"model.encoder._conv_head.weight\", \"model.encoder._bn1.weight\", \"model.encoder._bn1.bias\", \"model.encoder._bn1.running_mean\", \"model.encoder._bn1.running_var\", \"model.decoder.blocks.0.conv1.0.weight\", \"model.decoder.blocks.0.conv1.1.weight\", \"model.decoder.blocks.0.conv1.1.bias\", \"model.decoder.blocks.0.conv1.1.running_mean\", \"model.decoder.blocks.0.conv1.1.running_var\", \"model.decoder.blocks.0.conv2.0.weight\", \"model.decoder.blocks.0.conv2.1.weight\", \"model.decoder.blocks.0.conv2.1.bias\", \"model.decoder.blocks.0.conv2.1.running_mean\", \"model.decoder.blocks.0.conv2.1.running_var\", \"model.decoder.blocks.1.conv1.0.weight\", \"model.decoder.blocks.1.conv1.1.weight\", \"model.decoder.blocks.1.conv1.1.bias\", \"model.decoder.blocks.1.conv1.1.running_mean\", \"model.decoder.blocks.1.conv1.1.running_var\", \"model.decoder.blocks.1.conv2.0.weight\", \"model.decoder.blocks.1.conv2.1.weight\", \"model.decoder.blocks.1.conv2.1.bias\", \"model.decoder.blocks.1.conv2.1.running_mean\", \"model.decoder.blocks.1.conv2.1.running_var\", \"model.decoder.blocks.2.conv1.0.weight\", \"model.decoder.blocks.2.conv1.1.weight\", \"model.decoder.blocks.2.conv1.1.bias\", \"model.decoder.blocks.2.conv1.1.running_mean\", \"model.decoder.blocks.2.conv1.1.running_var\", \"model.decoder.blocks.2.conv2.0.weight\", \"model.decoder.blocks.2.conv2.1.weight\", \"model.decoder.blocks.2.conv2.1.bias\", \"model.decoder.blocks.2.conv2.1.running_mean\", \"model.decoder.blocks.2.conv2.1.running_var\", \"model.decoder.blocks.3.conv1.0.weight\", \"model.decoder.blocks.3.conv1.1.weight\", \"model.decoder.blocks.3.conv1.1.bias\", \"model.decoder.blocks.3.conv1.1.running_mean\", \"model.decoder.blocks.3.conv1.1.running_var\", \"model.decoder.blocks.3.conv2.0.weight\", \"model.decoder.blocks.3.conv2.1.weight\", \"model.decoder.blocks.3.conv2.1.bias\", \"model.decoder.blocks.3.conv2.1.running_mean\", \"model.decoder.blocks.3.conv2.1.running_var\", \"model.decoder.blocks.4.conv1.0.weight\", \"model.decoder.blocks.4.conv1.1.weight\", \"model.decoder.blocks.4.conv1.1.bias\", \"model.decoder.blocks.4.conv1.1.running_mean\", \"model.decoder.blocks.4.conv1.1.running_var\", \"model.decoder.blocks.4.conv2.0.weight\", \"model.decoder.blocks.4.conv2.1.weight\", \"model.decoder.blocks.4.conv2.1.bias\", \"model.decoder.blocks.4.conv2.1.running_mean\", \"model.decoder.blocks.4.conv2.1.running_var\", \"model.segmentation_head.0.weight\", \"model.segmentation_head.0.bias\". \n",
            "\tUnexpected key(s) in state_dict: \"backbone.logits.conv3d.weight\", \"backbone.logits.conv3d.bias\", \"backbone.Conv3d_1a_7x7.conv3d.weight\", \"backbone.Conv3d_1a_7x7.bn.weight\", \"backbone.Conv3d_1a_7x7.bn.bias\", \"backbone.Conv3d_1a_7x7.bn.running_mean\", \"backbone.Conv3d_1a_7x7.bn.running_var\", \"backbone.Conv3d_1a_7x7.bn.num_batches_tracked\", \"backbone.Conv3d_2b_1x1.conv3d.weight\", \"backbone.Conv3d_2b_1x1.bn.weight\", \"backbone.Conv3d_2b_1x1.bn.bias\", \"backbone.Conv3d_2b_1x1.bn.running_mean\", \"backbone.Conv3d_2b_1x1.bn.running_var\", \"backbone.Conv3d_2b_1x1.bn.num_batches_tracked\", \"backbone.Conv3d_2c_3x3.conv3d.weight\", \"backbone.Conv3d_2c_3x3.bn.weight\", \"backbone.Conv3d_2c_3x3.bn.bias\", \"backbone.Conv3d_2c_3x3.bn.running_mean\", \"backbone.Conv3d_2c_3x3.bn.running_var\", \"backbone.Conv3d_2c_3x3.bn.num_batches_tracked\", \"backbone.Mixed_3b.b0.conv3d.weight\", \"backbone.Mixed_3b.b0.bn.weight\", \"backbone.Mixed_3b.b0.bn.bias\", \"backbone.Mixed_3b.b0.bn.running_mean\", \"backbone.Mixed_3b.b0.bn.running_var\", \"backbone.Mixed_3b.b0.bn.num_batches_tracked\", \"backbone.Mixed_3b.b1a.conv3d.weight\", \"backbone.Mixed_3b.b1a.bn.weight\", \"backbone.Mixed_3b.b1a.bn.bias\", \"backbone.Mixed_3b.b1a.bn.running_mean\", \"backbone.Mixed_3b.b1a.bn.running_var\", \"backbone.Mixed_3b.b1a.bn.num_batches_tracked\", \"backbone.Mixed_3b.b1b.conv3d.weight\", \"backbone.Mixed_3b.b1b.bn.weight\", \"backbone.Mixed_3b.b1b.bn.bias\", \"backbone.Mixed_3b.b1b.bn.running_mean\", \"backbone.Mixed_3b.b1b.bn.running_var\", \"backbone.Mixed_3b.b1b.bn.num_batches_tracked\", \"backbone.Mixed_3b.b2a.conv3d.weight\", \"backbone.Mixed_3b.b2a.bn.weight\", \"backbone.Mixed_3b.b2a.bn.bias\", \"backbone.Mixed_3b.b2a.bn.running_mean\", \"backbone.Mixed_3b.b2a.bn.running_var\", \"backbone.Mixed_3b.b2a.bn.num_batches_tracked\", \"backbone.Mixed_3b.b2b.conv3d.weight\", \"backbone.Mixed_3b.b2b.bn.weight\", \"backbone.Mixed_3b.b2b.bn.bias\", \"backbone.Mixed_3b.b2b.bn.running_mean\", \"backbone.Mixed_3b.b2b.bn.running_var\", \"backbone.Mixed_3b.b2b.bn.num_batches_tracked\", \"backbone.Mixed_3b.b3b.conv3d.weight\", \"backbone.Mixed_3b.b3b.bn.weight\", \"backbone.Mixed_3b.b3b.bn.bias\", \"backbone.Mixed_3b.b3b.bn.running_mean\", \"backbone.Mixed_3b.b3b.bn.running_var\", \"backbone.Mixed_3b.b3b.bn.num_batches_tracked\", \"backbone.Mixed_3c.b0.conv3d.weight\", \"backbone.Mixed_3c.b0.bn.weight\", \"backbone.Mixed_3c.b0.bn.bias\", \"backbone.Mixed_3c.b0.bn.running_mean\", \"backbone.Mixed_3c.b0.bn.running_var\", \"backbone.Mixed_3c.b0.bn.num_batches_tracked\", \"backbone.Mixed_3c.b1a.conv3d.weight\", \"backbone.Mixed_3c.b1a.bn.weight\", \"backbone.Mixed_3c.b1a.bn.bias\", \"backbone.Mixed_3c.b1a.bn.running_mean\", \"backbone.Mixed_3c.b1a.bn.running_var\", \"backbone.Mixed_3c.b1a.bn.num_batches_tracked\", \"backbone.Mixed_3c.b1b.conv3d.weight\", \"backbone.Mixed_3c.b1b.bn.weight\", \"backbone.Mixed_3c.b1b.bn.bias\", \"backbone.Mixed_3c.b1b.bn.running_mean\", \"backbone.Mixed_3c.b1b.bn.running_var\", \"backbone.Mixed_3c.b1b.bn.num_batches_tracked\", \"backbone.Mixed_3c.b2a.conv3d.weight\", \"backbone.Mixed_3c.b2a.bn.weight\", \"backbone.Mixed_3c.b2a.bn.bias\", \"backbone.Mixed_3c.b2a.bn.running_mean\", \"backbone.Mixed_3c.b2a.bn.running_var\", \"backbone.Mixed_3c.b2a.bn.num_batches_tracked\", \"backbone.Mixed_3c.b2b.conv3d.weight\", \"backbone.Mixed_3c.b2b.bn.weight\", \"backbone.Mixed_3c.b2b.bn.bias\", \"backbone.Mixed_3c.b2b.bn.running_mean\", \"backbone.Mixed_3c.b2b.bn.running_var\", \"backbone.Mixed_3c.b2b.bn.num_batches_tracked\", \"backbone.Mixed_3c.b3b.conv3d.weight\", \"backbone.Mixed_3c.b3b.bn.weight\", \"backbone.Mixed_3c.b3b.bn.bias\", \"backbone.Mixed_3c.b3b.bn.running_mean\", \"backbone.Mixed_3c.b3b.bn.running_var\", \"backbone.Mixed_3c.b3b.bn.num_batches_tracked\", \"backbone.Mixed_4b.b0.conv3d.weight\", \"backbone.Mixed_4b.b0.bn.weight\", \"backbone.Mixed_4b.b0.bn.bias\", \"backbone.Mixed_4b.b0.bn.running_mean\", \"backbone.Mixed_4b.b0.bn.running_var\", \"backbone.Mixed_4b.b0.bn.num_batches_tracked\", \"backbone.Mixed_4b.b1a.conv3d.weight\", \"backbone.Mixed_4b.b1a.bn.weight\", \"backbone.Mixed_4b.b1a.bn.bias\", \"backbone.Mixed_4b.b1a.bn.running_mean\", \"backbone.Mixed_4b.b1a.bn.running_var\", \"backbone.Mixed_4b.b1a.bn.num_batches_tracked\", \"backbone.Mixed_4b.b1b.conv3d.weight\", \"backbone.Mixed_4b.b1b.bn.weight\", \"backbone.Mixed_4b.b1b.bn.bias\", \"backbone.Mixed_4b.b1b.bn.running_mean\", \"backbone.Mixed_4b.b1b.bn.running_var\", \"backbone.Mixed_4b.b1b.bn.num_batches_tracked\", \"backbone.Mixed_4b.b2a.conv3d.weight\", \"backbone.Mixed_4b.b2a.bn.weight\", \"backbone.Mixed_4b.b2a.bn.bias\", \"backbone.Mixed_4b.b2a.bn.running_mean\", \"backbone.Mixed_4b.b2a.bn.running_var\", \"backbone.Mixed_4b.b2a.bn.num_batches_tracked\", \"backbone.Mixed_4b.b2b.conv3d.weight\", \"backbone.Mixed_4b.b2b.bn.weight\", \"backbone.Mixed_4b.b2b.bn.bias\", \"backbone.Mixed_4b.b2b.bn.running_mean\", \"backbone.Mixed_4b.b2b.bn.running_var\", \"backbone.Mixed_4b.b2b.bn.num_batches_tracked\", \"backbone.Mixed_4b.b3b.conv3d.weight\", \"backbone.Mixed_4b.b3b.bn.weight\", \"backbone.Mixed_4b.b3b.bn.bias\", \"backbone.Mixed_4b.b3b.bn.running_mean\", \"backbone.Mixed_4b.b3b.bn.running_var\", \"backbone.Mixed_4b.b3b.bn.num_batches_tracked\", \"backbone.Mixed_4c.b0.conv3d.weight\", \"backbone.Mixed_4c.b0.bn.weight\", \"backbone.Mixed_4c.b0.bn.bias\", \"backbone.Mixed_4c.b0.bn.running_mean\", \"backbone.Mixed_4c.b0.bn.running_var\", \"backbone.Mixed_4c.b0.bn.num_batches_tracked\", \"backbone.Mixed_4c.b1a.conv3d.weight\", \"backbone.Mixed_4c.b1a.bn.weight\", \"backbone.Mixed_4c.b1a.bn.bias\", \"backbone.Mixed_4c.b1a.bn.running_mean\", \"backbone.Mixed_4c.b1a.bn.running_var\", \"backbone.Mixed_4c.b1a.bn.num_batches_tracked\", \"backbone.Mixed_4c.b1b.conv3d.weight\", \"backbone.Mixed_4c.b1b.bn.weight\", \"backbone.Mixed_4c.b1b.bn.bias\", \"backbone.Mixed_4c.b1b.bn.running_mean\", \"backbone.Mixed_4c.b1b.bn.running_var\", \"backbone.Mixed_4c.b1b.bn.num_batches_tracked\", \"backbone.Mixed_4c.b2a.conv3d.weight\", \"backbone.Mixed_4c.b2a.bn.weight\", \"backbone.Mixed_4c.b2a.bn.bias\", \"backbone.Mixed_4c.b2a.bn.running_mean\", \"backbone.Mixed_4c.b2a.bn.running_var\", \"backbone.Mixed_4c.b2a.bn.num_batches_tracked\", \"backbone.Mixed_4c.b2b.conv3d.weight\", \"backbone.Mixed_4c.b2b.bn.weight\", \"backbone.Mixed_4c.b2b.bn.bias\", \"backbone.Mixed_4c.b2b.bn.running_mean\", \"backbone.Mixed_4c.b2b.bn.running_var\", \"backbone.Mixed_4c.b2b.bn.num_batches_tracked\", \"backbone.Mixed_4c.b3b.conv3d.weight\", \"backbone.Mixed_4c.b3b.bn.weight\", \"backbone.Mixed_4c.b3b.bn.bias\", \"backbone.Mixed_4c.b3b.bn.running_mean\", \"backbone.Mixed_4c.b3b.bn.running_var\", \"backbone.Mixed_4c.b3b.bn.num_batches_tracked\", \"backbone.Mixed_4d.b0.conv3d.weight\", \"backbone.Mixed_4d.b0.bn.weight\", \"backbone.Mixed_4d.b0.bn.bias\", \"backbone.Mixed_4d.b0.bn.running_mean\", \"backbone.Mixed_4d.b0.bn.running_var\", \"backbone.Mixed_4d.b0.bn.num_batches_tracked\", \"backbone.Mixed_4d.b1a.conv3d.weight\", \"backbone.Mixed_4d.b1a.bn.weight\", \"backbone.Mixed_4d.b1a.bn.bias\", \"backbone.Mixed_4d.b1a.bn.running_mean\", \"backbone.Mixed_4d.b1a.bn.running_var\", \"backbone.Mixed_4d.b1a.bn.num_batches_tracked\", \"backbone.Mixed_4d.b1b.conv3d.weight\", \"backbone.Mixed_4d.b1b.bn.weight\", \"backbone.Mixed_4d.b1b.bn.bias\", \"backbone.Mixed_4d.b1b.bn.running_mean\", \"backbone.Mixed_4d.b1b.bn.running_var\", \"backbone.Mixed_4d.b1b.bn.num_batches_tracked\", \"backbone.Mixed_4d.b2a.conv3d.weight\", \"backbone.Mixed_4d.b2a.bn.weight\", \"backbone.Mixed_4d.b2a.bn.bias\", \"backbone.Mixed_4d.b2a.bn.running_mean\", \"backbone.Mixed_4d.b2a.bn.running_var\", \"backbone.Mixed_4d.b2a.bn.num_batches_tracked\", \"backbone.Mixed_4d.b2b.conv3d.weight\", \"backbone.Mixed_4d.b2b.bn.weight\", \"backbone.Mixed_4d.b2b.bn.bias\", \"backbone.Mixed_4d.b2b.bn.running_mean\", \"backbone.Mixed_4d.b2b.bn.running_var\", \"backbone.Mixed_4d.b2b.bn.num_batches_tracked\", \"backbone.Mixed_4d.b3b.conv3d.weight\", \"backbone.Mixed_4d.b3b.bn.weight\", \"backbone.Mixed_4d.b3b.bn.bias\", \"backbone.Mixed_4d.b3b.bn.running_mean\", \"backbone.Mixed_4d.b3b.bn.running_var\", \"backbone.Mixed_4d.b3b.bn.num_batches_tracked\", \"backbone.Mixed_4e.b0.conv3d.weight\", \"backbone.Mixed_4e.b0.bn.weight\", \"backbone.Mixed_4e.b0.bn.bias\", \"backbone.Mixed_4e.b0.bn.running_mean\", \"backbone.Mixed_4e.b0.bn.running_var\", \"backbone.Mixed_4e.b0.bn.num_batches_tracked\", \"backbone.Mixed_4e.b1a.conv3d.weight\", \"backbone.Mixed_4e.b1a.bn.weight\", \"backbone.Mixed_4e.b1a.bn.bias\", \"backbone.Mixed_4e.b1a.bn.running_mean\", \"backbone.Mixed_4e.b1a.bn.running_var\", \"backbone.Mixed_4e.b1a.bn.num_batches_tracked\", \"backbone.Mixed_4e.b1b.conv3d.weight\", \"backbone.Mixed_4e.b1b.bn.weight\", \"backbone.Mixed_4e.b1b.bn.bias\", \"backbone.Mixed_4e.b1b.bn.running_mean\", \"backbone.Mixed_4e.b1b.bn.running_var\", \"backbone.Mixed_4e.b1b.bn.num_batches_tracked\", \"backbone.Mixed_4e.b2a.conv3d.weight\", \"backbone.Mixed_4e.b2a.bn.weight\", \"backbone.Mixed_4e.b2a.bn.bias\", \"backbone.Mixed_4e.b2a.bn.running_mean\", \"backbone.Mixed_4e.b2a.bn.running_var\", \"backbone.Mixed_4e.b2a.bn.num_batches_tracked\", \"backbone.Mixed_4e.b2b.conv3d.weight\", \"backbone.Mixed_4e.b2b.bn.weight\", \"backbone.Mixed_4e.b2b.bn.bias\", \"backbone.Mixed_4e.b2b.bn.running_mean\", \"backbone.Mixed_4e.b2b.bn.running_var\", \"backbone.Mixed_4e.b2b.bn.num_batches_tracked\", \"backbone.Mixed_4e.b3b.conv3d.weight\", \"backbone.Mixed_4e.b3b.bn.weight\", \"backbone.Mixed_4e.b3b.bn.bias\", \"backbone.Mixed_4e.b3b.bn.running_mean\", \"backbone.Mixed_4e.b3b.bn.running_var\", \"backbone.Mixed_4e.b3b.bn.num_batches_tracked\", \"backbone.Mixed_4f.b0.conv3d.weight\", \"backbone.Mixed_4f.b0.bn.weight\", \"backbone.Mixed_4f.b0.bn.bias\", \"backbone.Mixed_4f.b0.bn.running_mean\", \"backbone.Mixed_4f.b0.bn.running_var\", \"backbone.Mixed_4f.b0.bn.num_batches_tracked\", \"backbone.Mixed_4f.b1a.conv3d.weight\", \"backbone.Mixed_4f.b1a.bn.weight\", \"backbone.Mixed_4f.b1a.bn.bias\", \"backbone.Mixed_4f.b1a.bn.running_mean\", \"backbone.Mixed_4f.b1a.bn.running_var\", \"backbone.Mixed_4f.b1a.bn.num_batches_tracked\", \"backbone.Mixed_4f.b1b.conv3d.weight\", \"backbone.Mixed_4f.b1b.bn.weight\", \"backbone.Mixed_4f.b1b.bn.bias\", \"backbone.Mixed_4f.b1b.bn.running_mean\", \"backbone.Mixed_4f.b1b.bn.running_var\", \"backbone.Mixed_4f.b1b.bn.num_batches_tracked\", \"backbone.Mixed_4f.b2a.conv3d.weight\", \"backbone.Mixed_4f.b2a.bn.weight\", \"backbone.Mixed_4f.b2a.bn.bias\", \"backbone.Mixed_4f.b2a.bn.running_mean\", \"backbone.Mixed_4f.b2a.bn.running_var\", \"backbone.Mixed_4f.b2a.bn.num_batches_tracked\", \"backbone.Mixed_4f.b2b.conv3d.weight\", \"backbone.Mixed_4f.b2b.bn.weight\", \"backbone.Mixed_4f.b2b.bn.bias\", \"backbone.Mixed_4f.b2b.bn.running_mean\", \"backbone.Mixed_4f.b2b.bn.running_var\", \"backbone.Mixed_4f.b2b.bn.num_batches_tracked\", \"backbone.Mixed_4f.b3b.conv3d.weight\", \"backbone.Mixed_4f.b3b.bn.weight\", \"backbone.Mixed_4f.b3b.bn.bias\", \"backbone.Mixed_4f.b3b.bn.running_mean\", \"backbone.Mixed_4f.b3b.bn.running_var\", \"backbone.Mixed_4f.b3b.bn.num_batches_tracked\", \"backbone.Mixed_5b.b0.conv3d.weight\", \"backbone.Mixed_5b.b0.bn.weight\", \"backbone.Mixed_5b.b0.bn.bias\", \"backbone.Mixed_5b.b0.bn.running_mean\", \"backbone.Mixed_5b.b0.bn.running_var\", \"backbone.Mixed_5b.b0.bn.num_batches_tracked\", \"backbone.Mixed_5b.b1a.conv3d.weight\", \"backbone.Mixed_5b.b1a.bn.weight\", \"backbone.Mixed_5b.b1a.bn.bias\", \"backbone.Mixed_5b.b1a.bn.running_mean\", \"backbone.Mixed_5b.b1a.bn.running_var\", \"backbone.Mixed_5b.b1a.bn.num_batches_tracked\", \"backbone.Mixed_5b.b1b.conv3d.weight\", \"backbone.Mixed_5b.b1b.bn.weight\", \"backbone.Mixed_5b.b1b.bn.bias\", \"backbone.Mixed_5b.b1b.bn.running_mean\", \"backbone.Mixed_5b.b1b.bn.running_var\", \"backbone.Mixed_5b.b1b.bn.num_batches_tracked\", \"backbone.Mixed_5b.b2a.conv3d.weight\", \"backbone.Mixed_5b.b2a.bn.weight\", \"backbone.Mixed_5b.b2a.bn.bias\", \"backbone.Mixed_5b.b2a.bn.running_mean\", \"backbone.Mixed_5b.b2a.bn.running_var\", \"backbone.Mixed_5b.b2a.bn.num_batches_tracked\", \"backbone.Mixed_5b.b2b.conv3d.weight\", \"backbone.Mixed_5b.b2b.bn.weight\", \"backbone.Mixed_5b.b2b.bn.bias\", \"backbone.Mixed_5b.b2b.bn.running_mean\", \"backbone.Mixed_5b.b2b.bn.running_var\", \"backbone.Mixed_5b.b2b.bn.num_batches_tracked\", \"backbone.Mixed_5b.b3b.conv3d.weight\", \"backbone.Mixed_5b.b3b.bn.weight\", \"backbone.Mixed_5b.b3b.bn.bias\", \"backbone.Mixed_5b.b3b.bn.running_mean\", \"backbone.Mixed_5b.b3b.bn.running_var\", \"backbone.Mixed_5b.b3b.bn.num_batches_tracked\", \"backbone.Mixed_5c.b0.conv3d.weight\", \"backbone.Mixed_5c.b0.bn.weight\", \"backbone.Mixed_5c.b0.bn.bias\", \"backbone.Mixed_5c.b0.bn.running_mean\", \"backbone.Mixed_5c.b0.bn.running_var\", \"backbone.Mixed_5c.b0.bn.num_batches_tracked\", \"backbone.Mixed_5c.b1a.conv3d.weight\", \"backbone.Mixed_5c.b1a.bn.weight\", \"backbone.Mixed_5c.b1a.bn.bias\", \"backbone.Mixed_5c.b1a.bn.running_mean\", \"backbone.Mixed_5c.b1a.bn.running_var\", \"backbone.Mixed_5c.b1a.bn.num_batches_tracked\", \"backbone.Mixed_5c.b1b.conv3d.weight\", \"backbone.Mixed_5c.b1b.bn.weight\", \"backbone.Mixed_5c.b1b.bn.bias\", \"backbone.Mixed_5c.b1b.bn.running_mean\", \"backbone.Mixed_5c.b1b.bn.running_var\", \"backbone.Mixed_5c.b1b.bn.num_batches_tracked\", \"backbone.Mixed_5c.b2a.conv3d.weight\", \"backbone.Mixed_5c.b2a.bn.weight\", \"backbone.Mixed_5c.b2a.bn.bias\", \"backbone.Mixed_5c.b2a.bn.running_mean\", \"backbone.Mixed_5c.b2a.bn.running_var\", \"backbone.Mixed_5c.b2a.bn.num_batches_tracked\", \"backbone.Mixed_5c.b2b.conv3d.weight\", \"backbone.Mixed_5c.b2b.bn.weight\", \"backbone.Mixed_5c.b2b.bn.bias\", \"backbone.Mixed_5c.b2b.bn.running_mean\", \"backbone.Mixed_5c.b2b.bn.running_var\", \"backbone.Mixed_5c.b2b.bn.num_batches_tracked\", \"backbone.Mixed_5c.b3b.conv3d.weight\", \"backbone.Mixed_5c.b3b.bn.weight\", \"backbone.Mixed_5c.b3b.bn.bias\", \"backbone.Mixed_5c.b3b.bn.running_mean\", \"backbone.Mixed_5c.b3b.bn.running_var\", \"backbone.Mixed_5c.b3b.bn.num_batches_tracked\", \"decoder.convs.0.0.weight\", \"decoder.convs.0.1.weight\", \"decoder.convs.0.1.bias\", \"decoder.convs.0.1.running_mean\", \"decoder.convs.0.1.running_var\", \"decoder.convs.0.1.num_batches_tracked\", \"decoder.convs.1.0.weight\", \"decoder.convs.1.1.weight\", \"decoder.convs.1.1.bias\", \"decoder.convs.1.1.running_mean\", \"decoder.convs.1.1.running_var\", \"decoder.convs.1.1.num_batches_tracked\", \"decoder.convs.2.0.weight\", \"decoder.convs.2.1.weight\", \"decoder.convs.2.1.bias\", \"decoder.convs.2.1.running_mean\", \"decoder.convs.2.1.running_var\", \"decoder.convs.2.1.num_batches_tracked\", \"decoder.logit.weight\", \"decoder.logit.bias\". \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msleek-sea-6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/pretraining_all/runs/sb0ug43u\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/pretraining_all\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240726_053931-sb0ug43u/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
          ]
        }
      ],
      "source": [
        "!python 64x64_256stride_i3d_1667_7a.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb3DxbMfkCte",
        "outputId": "10ee43fc-f436-43e0-d0bb-b0dd154e49a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "reading  20231210132040\n",
            "reading  20231215151901\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240726_021514-p6ebx5fo\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtraining_scrolls_valid=20231210132040_64x64_submissionlabelsi3d_finetune\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667/runs/p6ebx5fo\u001b[0m\n",
            "FOLD :  0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name       | Type                  | Params\n",
            "-----------------------------------------------------\n",
            "0 | loss_func1 | DiceLoss              | 0     \n",
            "1 | loss_func2 | SoftBCEWithLogitsLoss | 0     \n",
            "2 | backbone   | InceptionI3d          | 12.8 M\n",
            "3 | decoder    | Decoder               | 20.7 M\n",
            "-----------------------------------------------------\n",
            "33.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "33.5 M    Total params\n",
            "133.993   Total estimated model params size (MB)\n",
            "Sanity Checking DataLoader 0: 100% 2/2 [00:03<00:00,  1.87s/it]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (110100480 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "Epoch 0: 100% 80/80 [02:22<00:00,  1.78s/it, v_num=x5fo, train/total_loss_step=0.698]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4842 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/4842 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 20/4842 [00:20<1:21:57,  1.02s/it]\u001b[A\n",
            "Validation DataLoader 0:   1% 40/4842 [00:40<1:20:21,  1.00s/it]\u001b[A\n",
            "Validation DataLoader 0:   1% 60/4842 [01:00<1:19:42,  1.00s/it]\u001b[A\n",
            "Validation DataLoader 0:   2% 80/4842 [01:19<1:19:13,  1.00it/s]\u001b[A\n",
            "Validation DataLoader 0:   2% 100/4842 [01:39<1:18:44,  1.00it/s]\u001b[A\n",
            "Validation DataLoader 0:   2% 120/4842 [01:59<1:18:30,  1.00it/s]\u001b[A\n",
            "Validation DataLoader 0:   3% 140/4842 [02:19<1:18:02,  1.00it/s]\u001b[A\n",
            "Validation DataLoader 0:   3% 160/4842 [02:39<1:17:39,  1.00it/s]\u001b[A\n",
            "Validation DataLoader 0:   4% 180/4842 [02:59<1:17:16,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:   4% 200/4842 [03:18<1:16:54,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 220/4842 [03:39<1:16:40,  1.00it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 240/4842 [03:58<1:16:19,  1.00it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 260/4842 [04:18<1:15:57,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:   6% 280/4842 [04:38<1:15:36,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:   6% 300/4842 [04:58<1:15:14,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:   7% 320/4842 [05:18<1:14:57,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:   7% 340/4842 [05:38<1:14:37,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:   7% 360/4842 [05:57<1:14:17,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:   8% 380/4842 [06:17<1:13:56,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:   8% 400/4842 [06:37<1:13:35,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:   9% 420/4842 [06:57<1:13:18,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:   9% 440/4842 [07:17<1:12:57,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 460/4842 [07:37<1:12:36,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 480/4842 [07:57<1:12:15,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 500/4842 [08:16<1:11:55,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  11% 520/4842 [08:37<1:11:37,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  11% 540/4842 [08:56<1:11:16,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  12% 560/4842 [09:16<1:10:55,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  12% 580/4842 [09:36<1:10:35,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  12% 600/4842 [09:56<1:10:14,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  13% 620/4842 [10:16<1:09:56,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  13% 640/4842 [10:36<1:09:36,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  14% 660/4842 [10:55<1:09:16,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  14% 680/4842 [11:15<1:08:56,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  14% 700/4842 [11:35<1:08:35,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 720/4842 [11:55<1:08:17,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 740/4842 [12:15<1:07:56,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  16% 760/4842 [12:35<1:07:36,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  16% 780/4842 [12:55<1:07:16,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  17% 800/4842 [13:14<1:06:56,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  17% 820/4842 [13:35<1:06:37,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  17% 840/4842 [13:54<1:06:17,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  18% 860/4842 [14:14<1:05:57,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  18% 880/4842 [14:34<1:05:37,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  19% 900/4842 [14:54<1:05:16,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  19% 920/4842 [15:14<1:04:57,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  19% 940/4842 [15:34<1:04:37,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 960/4842 [15:53<1:04:17,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 980/4842 [16:13<1:03:57,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  21% 1000/4842 [16:33<1:03:36,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  21% 1020/4842 [16:53<1:03:17,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  21% 1040/4842 [17:13<1:02:57,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  22% 1060/4842 [17:33<1:02:37,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  22% 1080/4842 [17:52<1:02:16,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  23% 1100/4842 [18:12<1:01:56,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  23% 1120/4842 [18:32<1:01:37,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  24% 1140/4842 [18:52<1:01:16,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  24% 1160/4842 [19:12<1:00:56,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  24% 1180/4842 [19:31<1:00:36,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 1200/4842 [19:51<1:00:16,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 1220/4842 [20:11<59:57,  1.01it/s]  \u001b[A\n",
            "Validation DataLoader 0:  26% 1240/4842 [20:31<59:37,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  26% 1260/4842 [20:51<59:17,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  26% 1280/4842 [21:11<58:57,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  27% 1300/4842 [21:31<58:37,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  27% 1320/4842 [21:51<58:18,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  28% 1340/4842 [22:10<57:58,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  28% 1360/4842 [22:30<57:38,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  29% 1380/4842 [22:50<57:18,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  29% 1400/4842 [23:10<56:57,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  29% 1420/4842 [23:30<56:38,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 1440/4842 [23:50<56:18,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 1460/4842 [24:09<55:58,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  31% 1480/4842 [24:29<55:38,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  31% 1500/4842 [24:49<55:18,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  31% 1520/4842 [25:09<54:58,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  32% 1540/4842 [25:29<54:38,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  32% 1560/4842 [25:48<54:18,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  33% 1580/4842 [26:08<53:58,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  33% 1600/4842 [26:28<53:38,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  33% 1620/4842 [26:48<53:18,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  34% 1640/4842 [27:08<52:58,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  34% 1660/4842 [27:27<52:38,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 1680/4842 [27:47<52:18,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 1700/4842 [28:07<51:58,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  36% 1720/4842 [28:27<51:38,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  36% 1740/4842 [28:46<51:18,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  36% 1760/4842 [29:06<50:58,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  37% 1780/4842 [29:26<50:38,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  37% 1800/4842 [29:46<50:18,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  38% 1820/4842 [30:06<49:59,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  38% 1840/4842 [30:26<49:39,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  38% 1860/4842 [30:45<49:19,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  39% 1880/4842 [31:05<48:59,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  39% 1900/4842 [31:25<48:39,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 1920/4842 [31:45<48:19,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 1940/4842 [32:05<47:59,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 1960/4842 [32:24<47:39,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  41% 1980/4842 [32:44<47:19,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  41% 2000/4842 [33:04<46:59,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  42% 2020/4842 [33:24<46:40,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  42% 2040/4842 [33:44<46:20,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  43% 2060/4842 [34:04<46:00,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  43% 2080/4842 [34:23<45:40,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  43% 2100/4842 [34:43<45:20,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 2120/4842 [35:03<45:00,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  44% 2140/4842 [35:23<44:40,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 2160/4842 [35:43<44:20,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 2180/4842 [36:02<44:00,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 2200/4842 [36:22<43:40,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  46% 2220/4842 [36:42<43:21,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  46% 2240/4842 [37:02<43:01,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  47% 2260/4842 [37:22<42:41,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  47% 2280/4842 [37:41<42:21,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  48% 2300/4842 [38:01<42:01,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  48% 2320/4842 [38:21<41:42,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  48% 2340/4842 [38:41<41:22,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  49% 2360/4842 [39:01<41:02,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  49% 2380/4842 [39:20<40:42,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 2400/4842 [39:40<40:22,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 2420/4842 [40:00<40:02,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 2440/4842 [40:20<39:42,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  51% 2460/4842 [40:40<39:22,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  51% 2480/4842 [41:00<39:02,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  52% 2500/4842 [41:19<38:43,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  52% 2520/4842 [41:39<38:23,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  52% 2540/4842 [41:59<38:03,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  53% 2560/4842 [42:19<37:43,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  53% 2580/4842 [42:39<37:23,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  54% 2600/4842 [42:58<37:03,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  54% 2620/4842 [43:18<36:44,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 2640/4842 [43:38<36:24,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 2660/4842 [43:58<36:04,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 2680/4842 [44:18<35:44,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  56% 2700/4842 [44:37<35:24,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  56% 2720/4842 [44:57<35:04,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  57% 2740/4842 [45:17<34:44,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  57% 2760/4842 [45:37<34:24,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  57% 2780/4842 [45:56<34:04,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  58% 2800/4842 [46:16<33:45,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  58% 2820/4842 [46:36<33:25,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  59% 2840/4842 [46:56<33:05,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  59% 2860/4842 [47:16<32:45,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  59% 2880/4842 [47:35<32:25,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 2900/4842 [47:55<32:05,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 2920/4842 [48:15<31:46,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  61% 2940/4842 [48:35<31:26,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  61% 2960/4842 [48:55<31:06,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  62% 2980/4842 [49:14<30:46,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  62% 3000/4842 [49:34<30:26,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  62% 3020/4842 [49:54<30:06,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  63% 3040/4842 [50:14<29:46,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  63% 3060/4842 [50:34<29:26,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  64% 3080/4842 [50:53<29:07,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  64% 3100/4842 [51:13<28:47,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  64% 3120/4842 [51:33<28:27,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 3140/4842 [51:53<28:07,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 3160/4842 [52:12<27:47,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  66% 3180/4842 [52:32<27:27,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  66% 3200/4842 [52:52<27:07,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  67% 3220/4842 [53:12<26:48,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  67% 3240/4842 [53:32<26:28,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  67% 3260/4842 [53:51<26:08,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  68% 3280/4842 [54:11<25:48,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  68% 3300/4842 [54:31<25:28,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  69% 3320/4842 [54:51<25:08,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  69% 3340/4842 [55:11<24:48,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  69% 3360/4842 [55:30<24:29,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 3380/4842 [55:50<24:09,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 3400/4842 [56:10<23:49,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  71% 3420/4842 [56:30<23:29,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  71% 3440/4842 [56:50<23:09,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  71% 3460/4842 [57:09<22:49,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  72% 3480/4842 [57:29<22:30,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  72% 3500/4842 [57:49<22:10,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  73% 3520/4842 [58:09<21:50,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  73% 3540/4842 [58:29<21:30,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  74% 3560/4842 [58:49<21:10,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  74% 3580/4842 [59:08<20:51,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  74% 3600/4842 [59:28<20:31,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 3620/4842 [59:48<20:11,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 3640/4842 [1:00:08<19:51,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  76% 3660/4842 [1:00:28<19:31,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  76% 3680/4842 [1:00:47<19:11,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  76% 3700/4842 [1:01:07<18:51,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  77% 3720/4842 [1:01:27<18:32,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  77% 3740/4842 [1:01:47<18:12,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  78% 3760/4842 [1:02:06<17:52,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  78% 3780/4842 [1:02:26<17:32,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  78% 3800/4842 [1:02:46<17:12,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  79% 3820/4842 [1:03:06<16:53,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  79% 3840/4842 [1:03:26<16:33,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 3860/4842 [1:03:45<16:13,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 3880/4842 [1:04:05<15:53,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  81% 3900/4842 [1:04:25<15:33,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  81% 3920/4842 [1:04:45<15:13,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  81% 3940/4842 [1:05:05<14:53,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  82% 3960/4842 [1:05:24<14:34,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  82% 3980/4842 [1:05:44<14:14,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  83% 4000/4842 [1:06:04<13:54,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  83% 4020/4842 [1:06:24<13:34,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  83% 4040/4842 [1:06:44<13:14,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  84% 4060/4842 [1:07:03<12:55,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  84% 4080/4842 [1:07:23<12:35,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 4100/4842 [1:07:43<12:15,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 4120/4842 [1:08:03<11:55,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  86% 4140/4842 [1:08:23<11:35,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  86% 4160/4842 [1:08:42<11:15,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  86% 4180/4842 [1:09:02<10:56,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  87% 4200/4842 [1:09:22<10:36,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  87% 4220/4842 [1:09:42<10:16,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  88% 4240/4842 [1:10:01<09:56,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  88% 4260/4842 [1:10:21<09:36,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  88% 4280/4842 [1:10:41<09:16,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 4300/4842 [1:11:01<08:57,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 4320/4842 [1:11:21<08:37,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 4340/4842 [1:11:40<08:17,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 4360/4842 [1:12:00<07:57,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 4380/4842 [1:12:20<07:37,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  91% 4400/4842 [1:12:40<07:17,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  91% 4420/4842 [1:13:00<06:58,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  92% 4440/4842 [1:13:19<06:38,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  92% 4460/4842 [1:13:39<06:18,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  93% 4480/4842 [1:13:59<05:58,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  93% 4500/4842 [1:14:19<05:38,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  93% 4520/4842 [1:14:39<05:19,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  94% 4540/4842 [1:14:58<04:59,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  94% 4560/4842 [1:15:18<04:39,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 4580/4842 [1:15:38<04:19,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 4600/4842 [1:15:58<03:59,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 4620/4842 [1:16:18<03:39,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  96% 4640/4842 [1:16:37<03:20,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  96% 4660/4842 [1:16:57<03:00,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  97% 4680/4842 [1:17:17<02:40,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  97% 4700/4842 [1:17:36<02:20,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  97% 4720/4842 [1:17:57<02:00,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  98% 4740/4842 [1:18:16<01:41,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  98% 4760/4842 [1:18:36<01:21,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  99% 4780/4842 [1:18:56<01:01,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  99% 4800/4842 [1:19:16<00:41,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4820/4842 [1:19:36<00:21,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4840/4842 [1:19:55<00:01,  1.01it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4842/4842 [1:19:57<00:00,  1.01it/s]\u001b[A\n",
            "Epoch 0: 100% 80/80 [1:22:35<00:00, 61.94s/it, v_num=x5fo, train/total_loss_step=0.698, val/total_loss_step=0.327, val/total_loss_epoch=0.368, train/total_loss_epoch=0.690]Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/64x64_256stride_i3d_1667_5.py\", line 585, in <module>\n",
            "    trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 203, in run\n",
            "    self.on_advance_end()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 370, in on_advance_end\n",
            "    call._call_callback_hooks(trainer, \"on_train_epoch_end\", monitoring_callbacks=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 195, in _call_callback_hooks\n",
            "    fn(trainer, trainer.lightning_module, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 303, in on_train_epoch_end\n",
            "    self._save_topk_checkpoint(trainer, monitor_candidates)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 358, in _save_topk_checkpoint\n",
            "    raise MisconfigurationException(m)\n",
            "lightning_fabric.utilities.exceptions.MisconfigurationException: `ModelCheckpoint(monitor='train/Arcface_loss')` could not find the monitored key in the returned metrics: ['train/total_loss', 'train/total_loss_step', 'val/total_loss', 'val/total_loss_epoch', 'train/total_loss_epoch', 'epoch', 'step']. HINT: Did you call `log('train/Arcface_loss', value)` in the `LightningModule`?\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/64x64_256stride_i3d_1667_5.py\", line 585, in <module>\n",
            "    trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 203, in run\n",
            "    self.on_advance_end()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 370, in on_advance_end\n",
            "    call._call_callback_hooks(trainer, \"on_train_epoch_end\", monitoring_callbacks=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 195, in _call_callback_hooks\n",
            "    fn(trainer, trainer.lightning_module, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 303, in on_train_epoch_end\n",
            "    self._save_topk_checkpoint(trainer, monitor_candidates)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 358, in _save_topk_checkpoint\n",
            "    raise MisconfigurationException(m)\n",
            "lightning_fabric.utilities.exceptions.MisconfigurationException: `ModelCheckpoint(monitor='train/Arcface_loss')` could not find the monitored key in the returned metrics: ['train/total_loss', 'train/total_loss_step', 'val/total_loss', 'val/total_loss_epoch', 'train/total_loss_epoch', 'epoch', 'step']. HINT: Did you call `log('train/Arcface_loss', value)` in the `LightningModule`?\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 epoch ▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss_step ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  val/total_loss_epoch ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss_step ▁▁▁▁▁█▁▁▁▁▁▁█▁█▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 epoch 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss_step 0.683\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   trainer/global_step 79\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  val/total_loss_epoch 0.36832\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss_step 0.32684\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mtraining_scrolls_valid=20231210132040_64x64_submissionlabelsi3d_finetune\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667/runs/p6ebx5fo\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/scroll-4-1667\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 3 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240726_021514-p6ebx5fo/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
          ]
        }
      ],
      "source": [
        "!python 64x64_256stride_i3d_1667_5.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT3skfCaOuCg",
        "outputId": "883b0439-67e6-49a0-f740-7138816712f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Latest checkpoint: None\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Define the path to the default checkpoint directory\n",
        "default_checkpoint_dir = '/content/lightning_logs'\n",
        "\n",
        "# Get the list of all version directories\n",
        "version_dirs = glob.glob(os.path.join(default_checkpoint_dir, 'version_*'))\n",
        "\n",
        "# Sort the version directories by creation time\n",
        "version_dirs.sort(key=os.path.getctime)\n",
        "\n",
        "# Find the latest version directory\n",
        "latest_version_dir = version_dirs[-1] if version_dirs else None\n",
        "\n",
        "# Define the path to the checkpoints within the latest version directory\n",
        "checkpoint_dir = os.path.join(latest_version_dir, 'checkpoints') if latest_version_dir else None\n",
        "\n",
        "# Get the list of all checkpoint files and sort them by creation time\n",
        "checkpoint_files = glob.glob(os.path.join(checkpoint_dir, '*.ckpt')) if checkpoint_dir else []\n",
        "checkpoint_files.sort(key=os.path.getctime)\n",
        "\n",
        "# Get the latest checkpoint file\n",
        "latest_checkpoint = checkpoint_files[-1] if checkpoint_files else None\n",
        "\n",
        "print(f\"Latest checkpoint: {latest_checkpoint}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR2nru2e4O3j"
      },
      "outputs": [],
      "source": [
        "!python 64x64_256stride_i3d_1667_5_efficientnet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc2RBoNBlbTl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2LomgImlbV6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-x31VlllbYK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaflAeSen9GA"
      },
      "source": [
        "##training fails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neP0CqyZ_ies",
        "outputId": "31c669c7-5fca-4e51-c884-c8fed2817a71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "reading  training-1\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "(8960, 12288)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240725_231324-wbutldzl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpretraining_all\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/wbutldzl\u001b[0m\n",
            "Using 16bit None Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type | Params\n",
            "-------------------------------\n",
            "0 | model | Unet | 6.3 M \n",
            "-------------------------------\n",
            "6.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "6.3 M     Total params\n",
            "12.539    Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:110: UserWarning: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
            "  rank_zero_warn(\n",
            "Epoch 0:   0% 0/6433 [00:00<?, ?it/s] Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters/train_64chans_efficientnet_5.py\", line 352, in <module>\n",
            "    train_model()\n",
            "  File \"/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters/train_64chans_efficientnet_5.py\", line 349, in train_model\n",
            "    trainer.fit(model, data_module)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 608, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _fit_impl\n",
            "    self._run(model, ckpt_path=self.ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1103, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1182, in _run_stage\n",
            "    self._run_train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1205, in _run_train\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 267, in advance\n",
            "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 213, in advance\n",
            "    batch_output = self.batch_loop.run(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 88, in advance\n",
            "    outputs = self.optimizer_loop.run(optimizers, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 202, in advance\n",
            "    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 249, in _run_optimization\n",
            "    self._optimizer_step(optimizer, opt_idx, kwargs.get(\"batch_idx\", 0), closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 370, in _optimizer_step\n",
            "    self.trainer._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1347, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1744, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 169, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 234, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/native_amp.py\", line 75, in optimizer_step\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 149, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 135, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 419, in _training_step\n",
            "    training_step_output = self.trainer._call_strategy_hook(\"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1485, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 378, in training_step\n",
            "    return self.model.training_step(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters/train_64chans_efficientnet_5.py\", line 301, in training_step\n",
            "    loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 3224, in binary_cross_entropy_with_logits\n",
            "    raise ValueError(f\"Target size ({target.size()}) must be the same as input size ({input.size()})\")\n",
            "ValueError: Target size (torch.Size([256, 64, 64])) must be the same as input size (torch.Size([256, 1, 64, 64]))\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters/train_64chans_efficientnet_5.py\", line 352, in <module>\n",
            "    train_model()\n",
            "  File \"/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters/train_64chans_efficientnet_5.py\", line 349, in train_model\n",
            "    trainer.fit(model, data_module)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 608, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _fit_impl\n",
            "    self._run(model, ckpt_path=self.ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1103, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1182, in _run_stage\n",
            "    self._run_train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1205, in _run_train\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 267, in advance\n",
            "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 213, in advance\n",
            "    batch_output = self.batch_loop.run(kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 88, in advance\n",
            "    outputs = self.optimizer_loop.run(optimizers, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 202, in advance\n",
            "    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 249, in _run_optimization\n",
            "    self._optimizer_step(optimizer, opt_idx, kwargs.get(\"batch_idx\", 0), closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 370, in _optimizer_step\n",
            "    self.trainer._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1347, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1744, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 169, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 234, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/native_amp.py\", line 75, in optimizer_step\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 149, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 135, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 419, in _training_step\n",
            "    training_step_output = self.trainer._call_strategy_hook(\"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1485, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 378, in training_step\n",
            "    return self.model.training_step(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters/train_64chans_efficientnet_5.py\", line 301, in training_step\n",
            "    loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 3224, in binary_cross_entropy_with_logits\n",
            "    raise ValueError(f\"Target size ({target.size()}) must be the same as input size ({input.size()})\")\n",
            "ValueError: Target size (torch.Size([256, 64, 64])) must be the same as input size (torch.Size([256, 1, 64, 64]))\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mpretraining_all\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/wbutldzl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240725_231324-wbutldzl/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
          ]
        }
      ],
      "source": [
        "!python train_64chans_efficientnet_6.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L3bU48qIONc",
        "outputId": "2dfc967a-44d7-41e2-a067-9969bd674c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "reading  training-1\n",
            "Error in sys.excepthook:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dask/base.py\", line 68, in wrapper\n",
            "    @wraps(func)\n",
            "KeyboardInterrupt\n",
            "\n",
            "Original exception was:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters/64chans_training_16.py\", line 250, in <module>\n",
            "    train_images, train_masks, valid_images, valid_masks, valid_xyxys = get_train_valid_dataset()\n",
            "  File \"/content/drive/MyDrive/A_Scroll_1/Vesuvius-First-Letters/64chans_training_16.py\", line 213, in get_train_valid_dataset\n",
            "    if not np.all(mask[a:a + CFG.tile_size, b:b + CFG.tile_size] < 0.05):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\", line 2504, in all\n",
            "    return _wrapreduction(a, np.logical_and, 'all', axis, None, out,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\", line 88, in _wrapreduction\n",
            "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python 64chans_training_16.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsnLoM_rJ79y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ImsXEaKJ8AI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGto4LgcJ8Cz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dT7__H-IOP3"
      },
      "outputs": [],
      "source": [
        "!python train_64chans_v2.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qHMqsx_IOSa"
      },
      "outputs": [],
      "source": [
        "!python 64x64_256stride_i3d.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1Vhk0OUIPoj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTbHFWHTIPrS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK_x6R-rL86T"
      },
      "outputs": [],
      "source": [
        "python3 inference_timesformer.py --segment_id <id> --start <s> --num_layers <n>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HH7ZrESGKAca"
      },
      "outputs": [],
      "source": [
        "%cd Vesuvius-Grandprize-Winner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qf2-TZyAW7h"
      },
      "outputs": [],
      "source": [
        "!python 64chans_training_06.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt4A76wgfw0C"
      },
      "outputs": [],
      "source": [
        "!python train_64chans_v2.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlpWPgvYIsFb"
      },
      "source": [
        "#Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQhqtUSt2llP",
        "outputId": "0e8d270e-56fb-4c07-d962-cc361d5e0cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/A_Scroll/inkception-3d\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt"
      ],
      "metadata": {
        "id": "mmHvZzVqCJCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzu9JmI37QdB"
      },
      "source": [
        "#scroll 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVR2deTXbLcs"
      },
      "source": [
        "##2040"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_v29_rev_04ckpt6"
      ],
      "metadata": {
        "id": "ER-rRvXeDf_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yk0p9g53FG05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231210132040 --start_idx 06 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231210132040 --start_idx 06 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIsMN5wbDgfR",
        "outputId": "c10a7c9f-8f60-46b8-93a6-b038b462a277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:03<08:36,  3.27s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_6to6_1722406739/20231210132040_6to6_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [00:39<01:44,  1.14it/s]Progress image saved at step 39 (24%): ./outputs/20231210132040_6to6_1722406739/20231210132040_6to6_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [01:19<01:10,  1.14it/s]Progress image saved at step 79 (49%): ./outputs/20231210132040_6to6_1722406739/20231210132040_6to6_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [02:01<00:35,  1.13it/s]Progress image saved at step 119 (74%): ./outputs/20231210132040_6to6_1722406739/20231210132040_6to6_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [02:45<00:00,  1.04s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:03<08:00,  3.04s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_6to6_1722407072/20231210132040_6to6_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [00:39<01:47,  1.12it/s]Progress image saved at step 39 (24%): ./outputs/20231210132040_6to6_1722407072/20231210132040_6to6_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [01:20<01:11,  1.12it/s]Progress image saved at step 79 (49%): ./outputs/20231210132040_6to6_1722407072/20231210132040_6to6_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [02:03<00:35,  1.12it/s]Progress image saved at step 119 (74%): ./outputs/20231210132040_6to6_1722407072/20231210132040_6to6_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [02:47<00:00,  1.05s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231210132040 --start_idx 50 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231210132040 --start_idx 50 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEb9RW4Zbk4z",
        "outputId": "9fbfb4f3-df83-4ce8-e708-4a99f0089e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:03<08:11,  3.11s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_50to64_1722407537/20231210132040_50to64_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [00:39<01:46,  1.13it/s]Progress image saved at step 39 (24%): ./outputs/20231210132040_50to64_1722407537/20231210132040_50to64_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [01:19<01:10,  1.13it/s]Progress image saved at step 79 (49%): ./outputs/20231210132040_50to64_1722407537/20231210132040_50to64_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [02:01<00:35,  1.12it/s]Progress image saved at step 119 (74%): ./outputs/20231210132040_50to64_1722407537/20231210132040_50to64_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [02:45<00:00,  1.04s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:02<07:13,  2.74s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_50to64_1722407810/20231210132040_50to64_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [00:39<01:47,  1.12it/s]Progress image saved at step 39 (24%): ./outputs/20231210132040_50to64_1722407810/20231210132040_50to64_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [01:20<01:11,  1.12it/s]Progress image saved at step 79 (49%): ./outputs/20231210132040_50to64_1722407810/20231210132040_50to64_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [02:02<00:35,  1.12it/s]Progress image saved at step 119 (74%): ./outputs/20231210132040_50to64_1722407810/20231210132040_50to64_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [02:47<00:00,  1.05s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231210132040 --start_idx 20 --end_idx 40 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231210132040 --start_idx 20 --end_idx 40 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "id": "Hd4BK_yG0RIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S4ZTdpz5Lw5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TIwKcpP6Lw8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1nM5SXsSLxDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vVy1DYuyLxGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##hide"
      ],
      "metadata": {
        "id": "fhlFz7fyLs0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231210132040 --start_idx 16 --end_idx 36 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231210132040 --start_idx 16 --end_idx 36 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVVywLuSDgc7",
        "outputId": "4c5e7312-fdaa-438a-9ba0-5cfc1dc88776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:02<07:17,  2.77s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_16to36_1722386578/20231210132040_16to36_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [00:39<01:47,  1.12it/s]Progress image saved at step 39 (24%): ./outputs/20231210132040_16to36_1722386578/20231210132040_16to36_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [01:19<01:11,  1.12it/s]Progress image saved at step 79 (49%): ./outputs/20231210132040_16to36_1722386578/20231210132040_16to36_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [02:02<00:35,  1.12it/s]Progress image saved at step 119 (74%): ./outputs/20231210132040_16to36_1722386578/20231210132040_16to36_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [02:46<00:00,  1.05s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:03<08:04,  3.07s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_16to36_1722386787/20231210132040_16to36_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [00:40<01:48,  1.11it/s]Progress image saved at step 39 (24%): ./outputs/20231210132040_16to36_1722386787/20231210132040_16to36_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [01:20<01:11,  1.12it/s]Progress image saved at step 79 (49%): ./outputs/20231210132040_16to36_1722386787/20231210132040_16to36_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [02:03<00:35,  1.12it/s]Progress image saved at step 119 (74%): ./outputs/20231210132040_16to36_1722386787/20231210132040_16to36_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [02:47<00:00,  1.05s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231210132040 --start_idx 18 --end_idx 18 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231210132040 --start_idx 18 --end_idx 18 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL5DrPj55wPt",
        "outputId": "8073f2e5-6835-4d04-8a7c-8d03131bda07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 6/636 [00:07<10:19,  1.02it/s]Progress image saved at step 6 (0%): ./outputs/20231210132040_18to18_1722385311/20231210132040_18to18_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 159/636 [02:24<06:59,  1.14it/s]Progress image saved at step 159 (25%): ./outputs/20231210132040_18to18_1722385311/20231210132040_18to18_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 318/636 [04:49<04:39,  1.14it/s]Progress image saved at step 318 (50%): ./outputs/20231210132040_18to18_1722385311/20231210132040_18to18_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 477/636 [07:16<02:19,  1.14it/s]Progress image saved at step 477 (75%): ./outputs/20231210132040_18to18_1722385311/20231210132040_18to18_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 636/636 [09:45<00:00,  1.09it/s]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 6/636 [00:07<10:27,  1.00it/s]Progress image saved at step 6 (0%): ./outputs/20231210132040_18to18_1722385945/20231210132040_18to18_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 159/636 [02:24<06:58,  1.14it/s]Progress image saved at step 159 (25%): ./outputs/20231210132040_18to18_1722385945/20231210132040_18to18_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 318/636 [04:49<04:39,  1.14it/s]Progress image saved at step 318 (50%): ./outputs/20231210132040_18to18_1722385945/20231210132040_18to18_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 477/636 [07:16<02:20,  1.13it/s]Progress image saved at step 477 (75%): ./outputs/20231210132040_18to18_1722385945/20231210132040_18to18_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 636/636 [09:44<00:00,  1.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231210132040 --start_idx 22 --end_idx 22 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231210132040 --start_idx 22 --end_idx 22 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnQBgl6qAxNN",
        "outputId": "38f16731-5a75-4c43-dc1d-0edbcdfba01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 6/636 [00:07<10:26,  1.01it/s]Progress image saved at step 6 (0%): ./outputs/20231210132040_22to22_1722384044/20231210132040_22to22_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 159/636 [02:25<07:01,  1.13it/s]Progress image saved at step 159 (25%): ./outputs/20231210132040_22to22_1722384044/20231210132040_22to22_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 318/636 [04:50<04:40,  1.13it/s]Progress image saved at step 318 (50%): ./outputs/20231210132040_22to22_1722384044/20231210132040_22to22_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 477/636 [07:17<02:19,  1.14it/s]Progress image saved at step 477 (75%): ./outputs/20231210132040_22to22_1722384044/20231210132040_22to22_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 636/636 [09:45<00:00,  1.09it/s]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 6/636 [00:07<10:29,  1.00it/s]Progress image saved at step 6 (0%): ./outputs/20231210132040_22to22_1722384679/20231210132040_22to22_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 159/636 [02:24<06:58,  1.14it/s]Progress image saved at step 159 (25%): ./outputs/20231210132040_22to22_1722384679/20231210132040_22to22_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 318/636 [04:48<04:38,  1.14it/s]Progress image saved at step 318 (50%): ./outputs/20231210132040_22to22_1722384679/20231210132040_22to22_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 477/636 [07:14<02:19,  1.14it/s]Progress image saved at step 477 (75%): ./outputs/20231210132040_22to22_1722384679/20231210132040_22to22_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 636/636 [09:42<00:00,  1.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231210132040 --start_idx 20 --end_idx 25 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231210132040 --start_idx 20 --end_idx 25 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e5WDOfgAxKo",
        "outputId": "eaa304c1-b662-4dc5-9b76-c6e3a5091638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 6/636 [00:06<10:18,  1.02it/s]Progress image saved at step 6 (0%): ./outputs/20231210132040_20to25_1722382776/20231210132040_20to25_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 159/636 [02:25<06:57,  1.14it/s]Progress image saved at step 159 (25%): ./outputs/20231210132040_20to25_1722382776/20231210132040_20to25_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 318/636 [04:50<04:38,  1.14it/s]Progress image saved at step 318 (50%): ./outputs/20231210132040_20to25_1722382776/20231210132040_20to25_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 477/636 [07:17<02:19,  1.14it/s]Progress image saved at step 477 (75%): ./outputs/20231210132040_20to25_1722382776/20231210132040_20to25_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 636/636 [09:46<00:00,  1.09it/s]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 6/636 [00:07<10:29,  1.00it/s]Progress image saved at step 6 (0%): ./outputs/20231210132040_20to25_1722383411/20231210132040_20to25_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 159/636 [02:24<07:03,  1.13it/s]Progress image saved at step 159 (25%): ./outputs/20231210132040_20to25_1722383411/20231210132040_20to25_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 318/636 [04:49<04:39,  1.14it/s]Progress image saved at step 318 (50%): ./outputs/20231210132040_20to25_1722383411/20231210132040_20to25_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 477/636 [07:16<02:19,  1.14it/s]Progress image saved at step 477 (75%): ./outputs/20231210132040_20to25_1722383411/20231210132040_20to25_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 636/636 [09:44<00:00,  1.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ywNCeMFaA3FH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pvqBFPk4AxPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##break"
      ],
      "metadata": {
        "id": "dLzTrgFmLe8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231210132040 --start_idx 52 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231210132040 --start_idx 52 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKjfqX_Zf1pn",
        "outputId": "a8ac372d-9978-4c6b-cc34-9d9857c90b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "Image file not found for index 66\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v29_normal_04ckpt17.py\", line 698, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v29_normal_04ckpt17.py\", line 273, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "Image file not found for index 66\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v29_rev_04ckpt17.py\", line 698, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v29_rev_04ckpt17.py\", line 273, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231210132040 --start_idx 20 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231210132040 --start_idx 20 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKyagTe4f1sg",
        "outputId": "810c74e5-fbae-42ed-89ae-288fb93b36c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:02<06:50,  2.60s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_20to20_1722374708/20231210132040_20to20_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [00:41<01:46,  1.13it/s]Progress image saved at step 39 (24%): ./outputs/20231210132040_20to20_1722374708/20231210132040_20to20_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [01:22<01:11,  1.12it/s]Progress image saved at step 79 (49%): ./outputs/20231210132040_20to20_1722374708/20231210132040_20to20_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [02:05<00:35,  1.12it/s]Progress image saved at step 119 (74%): ./outputs/20231210132040_20to20_1722374708/20231210132040_20to20_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [02:50<00:00,  1.07s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:02<07:19,  2.78s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_20to20_1722374921/20231210132040_20to20_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [00:39<01:46,  1.12it/s]Progress image saved at step 39 (24%): ./outputs/20231210132040_20to20_1722374921/20231210132040_20to20_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [01:20<01:10,  1.13it/s]Progress image saved at step 79 (49%): ./outputs/20231210132040_20to20_1722374921/20231210132040_20to20_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [02:02<00:35,  1.13it/s]Progress image saved at step 119 (74%): ./outputs/20231210132040_20to20_1722374921/20231210132040_20to20_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [02:47<00:00,  1.05s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231210132040 --start_idx 20 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231210132040 --start_idx 20 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "id": "OxWpoWfpgArg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gPIU2w7NgAv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TJwF_7wif72I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fb2wYkZyf74h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yEFa-Ij3f77N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K9Jy3VHUDgh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231210132040 --start_idx 00 --end_idx 00 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_normal_04ckpt17.py --reverse 1 --segment_id 20231210132040 --start_idx 00 --end_idx 00 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWOQhMxVlC0_",
        "outputId": "2b2c6b2f-a565-48b1-daf0-9dcb13b09d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:02<07:20,  2.79s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_0to0_1722374121/20231210132040_0to0_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [00:58<01:45,  1.13it/s]Progress image saved at step 39 (24%): ./outputs/20231210132040_0to0_1722374121/20231210132040_0to0_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [01:39<01:11,  1.13it/s]Progress image saved at step 79 (49%): ./outputs/20231210132040_0to0_1722374121/20231210132040_0to0_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [02:22<00:35,  1.12it/s]Progress image saved at step 119 (74%): ./outputs/20231210132040_0to0_1722374121/20231210132040_0to0_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [03:07<00:00,  1.18s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:02<07:47,  2.96s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_0to0_1722374350/20231210132040_0to0_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [00:39<01:46,  1.12it/s]Progress image saved at step 39 (24%): ./outputs/20231210132040_0to0_1722374350/20231210132040_0to0_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [01:19<01:11,  1.12it/s]Progress image saved at step 79 (49%): ./outputs/20231210132040_0to0_1722374350/20231210132040_0to0_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [02:02<00:35,  1.13it/s]Progress image saved at step 119 (74%): ./outputs/20231210132040_0to0_1722374350/20231210132040_0to0_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [02:46<00:00,  1.05s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aV3P8KQolC3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_WwZ5Bg-lC6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaKUGudxbMmx",
        "outputId": "91249654-b718-4928-80cb-00ce29ac8bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:03<09:52,  3.75s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_30to34_1722288888/20231210132040_30to34_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [01:03<03:00,  1.50s/it]Progress image saved at step 39 (24%): ./outputs/20231210132040_30to34_1722288888/20231210132040_30to34_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [02:08<02:04,  1.56s/it]Progress image saved at step 79 (49%): ./outputs/20231210132040_30to34_1722288888/20231210132040_30to34_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [03:18<01:02,  1.55s/it]Progress image saved at step 119 (74%): ./outputs/20231210132040_30to34_1722288888/20231210132040_30to34_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [04:29<00:00,  1.69s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:03<08:22,  3.18s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_30to34_1722289202/20231210132040_30to34_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [01:05<03:10,  1.58s/it]Progress image saved at step 39 (24%): ./outputs/20231210132040_30to34_1722289202/20231210132040_30to34_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [02:12<02:05,  1.57s/it]Progress image saved at step 79 (49%): ./outputs/20231210132040_30to34_1722289202/20231210132040_30to34_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [03:21<01:02,  1.55s/it]Progress image saved at step 119 (74%): ./outputs/20231210132040_30to34_1722289202/20231210132040_30to34_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [04:32<00:00,  1.71s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v28_normal_ckpt11.py --reverse 0 --segment_id 20231210132040 --start_idx 30 --end_idx 34 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-2/02_valid-1_0_fr_i3depoch=11.ckpt\n",
        "!python inference_v28_reversed_ckpt11.py --reverse 1 --segment_id 20231210132040 --start_idx 30 --end_idx 34 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-2/02_valid-1_0_fr_i3depoch=11.ckpt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o73-QwXn7ke1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfI3k4IxbMpH",
        "outputId": "baab5ce0-41f3-46be-f1d3-e431dc73eee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:03<09:27,  3.59s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_0to64_1722280450/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [01:02<02:57,  1.48s/it]Progress image saved at step 39 (24%): ./outputs/20231210132040_0to64_1722280450/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [02:08<02:06,  1.58s/it]Progress image saved at step 79 (49%): ./outputs/20231210132040_0to64_1722280450/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [03:17<01:02,  1.56s/it]Progress image saved at step 119 (74%): ./outputs/20231210132040_0to64_1722280450/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [04:29<00:00,  1.69s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v26_normal_ckpt11.py --reverse 0 --segment_id 20231210132040 --start_idx 32 --end_idx 32 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/checkpoints/valid_valid-1_0_fr_i3depoch=11.ckpt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqiLldzZbMrg",
        "outputId": "72cfae9a-36d7-4909-a3ab-37bc96aee5c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:03<08:52,  3.37s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_0to64_1722280776/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [01:05<03:06,  1.55s/it]Progress image saved at step 39 (24%): ./outputs/20231210132040_0to64_1722280776/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [02:12<02:04,  1.56s/it]Progress image saved at step 79 (49%): ./outputs/20231210132040_0to64_1722280776/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [03:22<01:02,  1.55s/it]Progress image saved at step 119 (74%): ./outputs/20231210132040_0to64_1722280776/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [04:33<00:00,  1.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231210132040 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmKsdxfS6vd2",
        "outputId": "1d30896b-a554-4000-8f49-d43f582234fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:03<08:25,  3.20s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_0to64_1722281103/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [01:05<03:06,  1.56s/it]Progress image saved at step 39 (24%): ./outputs/20231210132040_0to64_1722281103/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [02:12<02:04,  1.56s/it]Progress image saved at step 79 (49%): ./outputs/20231210132040_0to64_1722281103/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [03:21<01:02,  1.55s/it]Progress image saved at step 119 (74%): ./outputs/20231210132040_0to64_1722281103/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [04:32<00:00,  1.71s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v26_normal_ckpt11.py --reverse 0 --segment_id 20231210132040 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models/valid_valid-1_0_fr_i3depoch=7.ckpt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG3maTgW698h",
        "outputId": "c6f6ce2f-344b-4e82-b174-bd65dfe69fad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/159 [00:03<08:38,  3.28s/it]Progress image saved at step 1 (0%): ./outputs/20231210132040_0to64_1722281420/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 39/159 [01:05<03:06,  1.56s/it]Progress image saved at step 39 (24%): ./outputs/20231210132040_0to64_1722281420/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 79/159 [02:12<02:04,  1.56s/it]Progress image saved at step 79 (49%): ./outputs/20231210132040_0to64_1722281420/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_49percent.png\n",
            " 75% 119/159 [03:21<01:02,  1.56s/it]Progress image saved at step 119 (74%): ./outputs/20231210132040_0to64_1722281420/20231210132040_0to64_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 159/159 [04:33<00:00,  1.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v26_normal_ckpt11.py --reverse 0 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/1-outputsvesuvius-models/valid_valid-1_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0PrkWx7A-da"
      },
      "source": [
        "##901"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvHWEId9bVGx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231215151901 --start_idx 10 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231215151901 --start_idx 10 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "id": "xz0YhtBYMiR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd14ed1a-82bb-4365-bd5b-9f9840a76344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_10to10_1722408435/20231215151901_10to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:14<00:33,  1.10it/s]Progress image saved at step 12 (24%): ./outputs/20231215151901_10to10_1722408435/20231215151901_10to10_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:26<00:22,  1.11it/s]Progress image saved at step 24 (48%): ./outputs/20231215151901_10to10_1722408435/20231215151901_10to10_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [00:39<00:11,  1.10it/s]Progress image saved at step 36 (73%): ./outputs/20231215151901_10to10_1722408435/20231215151901_10to10_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [00:53<00:00,  1.10s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_10to10_1722408533/20231215151901_10to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:13<00:33,  1.10it/s]Progress image saved at step 12 (24%): ./outputs/20231215151901_10to10_1722408533/20231215151901_10to10_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:25<00:22,  1.11it/s]Progress image saved at step 24 (48%): ./outputs/20231215151901_10to10_1722408533/20231215151901_10to10_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [00:38<00:11,  1.10it/s]Progress image saved at step 36 (73%): ./outputs/20231215151901_10to10_1722408533/20231215151901_10to10_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [00:53<00:00,  1.08s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231215151901 --start_idx 0 --end_idx 0 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231215151901 --start_idx 0 --end_idx 0 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwK_kBOEiwMD",
        "outputId": "86d39281-23f4-445d-c8c9-433b17201595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_0to0_1722408607/20231215151901_0to0_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:15<00:34,  1.08it/s]Progress image saved at step 12 (24%): ./outputs/20231215151901_0to0_1722408607/20231215151901_0to0_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:28<00:22,  1.10it/s]Progress image saved at step 24 (48%): ./outputs/20231215151901_0to0_1722408607/20231215151901_0to0_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [00:41<00:11,  1.10it/s]Progress image saved at step 36 (73%): ./outputs/20231215151901_0to0_1722408607/20231215151901_0to0_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [00:55<00:00,  1.13s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_0to0_1722408710/20231215151901_0to0_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:14<00:33,  1.10it/s]Progress image saved at step 12 (24%): ./outputs/20231215151901_0to0_1722408710/20231215151901_0to0_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:26<00:22,  1.11it/s]Progress image saved at step 24 (48%): ./outputs/20231215151901_0to0_1722408710/20231215151901_0to0_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [00:39<00:11,  1.10it/s]Progress image saved at step 36 (73%): ./outputs/20231215151901_0to0_1722408710/20231215151901_0to0_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [00:53<00:00,  1.09s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "id": "6PhhhPB0MiUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a0474e-0abe-4864-8f36-e9e658d0f679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_32to32_1722408020/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:13<00:33,  1.10it/s]Progress image saved at step 12 (24%): ./outputs/20231215151901_32to32_1722408020/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:25<00:22,  1.11it/s]Progress image saved at step 24 (48%): ./outputs/20231215151901_32to32_1722408020/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [00:38<00:11,  1.10it/s]Progress image saved at step 36 (73%): ./outputs/20231215151901_32to32_1722408020/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [00:52<00:00,  1.08s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_32to32_1722408130/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:14<00:33,  1.10it/s]Progress image saved at step 12 (24%): ./outputs/20231215151901_32to32_1722408130/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:26<00:22,  1.11it/s]Progress image saved at step 24 (48%): ./outputs/20231215151901_32to32_1722408130/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [00:38<00:11,  1.10it/s]Progress image saved at step 36 (73%): ./outputs/20231215151901_32to32_1722408130/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [00:52<00:00,  1.08s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zNJxeKS-MiW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BwkzxrGNMiZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oacDj5WaTZ7h"
      },
      "outputs": [],
      "source": [
        "!python inference_timesformer_5.py --segment_id 20231215151901 --start 30 --num_layers 3 --stride 32 --size 64 --model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSxyEmv27oZy",
        "outputId": "38dcef29-97ed-41cc-fe3d-40407a2a5a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_20to50_1722324427/20231215151901_20to50_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:20<00:53,  1.45s/it]Progress image saved at step 12 (24%): ./outputs/20231215151901_20to50_1722324427/20231215151901_20to50_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:39<00:36,  1.46s/it]Progress image saved at step 24 (48%): ./outputs/20231215151901_20to50_1722324427/20231215151901_20to50_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [00:58<00:19,  1.47s/it]Progress image saved at step 36 (73%): ./outputs/20231215151901_20to50_1722324427/20231215151901_20to50_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [01:20<00:00,  1.64s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_20to50_1722324541/20231215151901_20to50_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:21<00:55,  1.50s/it]Progress image saved at step 12 (24%): ./outputs/20231215151901_20to50_1722324541/20231215151901_20to50_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:40<00:37,  1.51s/it]Progress image saved at step 24 (48%): ./outputs/20231215151901_20to50_1722324541/20231215151901_20to50_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [01:01<00:19,  1.54s/it]Progress image saved at step 36 (73%): ./outputs/20231215151901_20to50_1722324541/20231215151901_20to50_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [01:23<00:00,  1.70s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v29_normal_04ckpt6.py --reverse 0 --segment_id 20231215151901 --start_idx 20 --end_idx 50 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models/vesuvius-3_valid-1_0_fr_i3depoch=6.ckpt\n",
        "!python inference_v29_normal_04ckpt6.py --reverse 1 --segment_id 20231215151901 --start_idx 20 --end_idx 50 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models/vesuvius-3_valid-1_0_fr_i3depoch=6.ckpt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt6.py --reverse 0 --segment_id 20231215151901 --start_idx 20 --end_idx 30 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models/vesuvius-3_valid-1_0_fr_i3depoch=6.ckpt\n",
        "!python inference_v29_normal_04ckpt6.py --reverse 1 --segment_id 20231215151901 --start_idx 20 --end_idx 30 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models/vesuvius-3_valid-1_0_fr_i3depoch=6.ckpt\n"
      ],
      "metadata": {
        "id": "kkRlaOm5iQie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ukp1ZHdMiQlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J6UISbjpiQnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1DcJdffZiQqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt6.py --reverse 0 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models/vesuvius-3_valid-1_0_fr_i3depoch=6.ckpt\n",
        "!python inference_v29_normal_04ckpt6.py --reverse 1 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models/vesuvius-3_valid-1_0_fr_i3depoch=6.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP2OTyB7iQsu",
        "outputId": "e11d4c13-1d6d-45b3-8bb5-c2fd5adee68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/196 [00:03<11:27,  3.53s/it]Progress image saved at step 1 (0%): ./outputs/20231215151901_32to32_1722324645/20231215151901_32to32_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 49/196 [01:17<03:40,  1.50s/it]Progress image saved at step 49 (25%): ./outputs/20231215151901_32to32_1722324645/20231215151901_32to32_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 98/196 [02:32<02:28,  1.51s/it]Progress image saved at step 98 (50%): ./outputs/20231215151901_32to32_1722324645/20231215151901_32to32_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 147/196 [03:48<01:13,  1.50s/it]Progress image saved at step 147 (75%): ./outputs/20231215151901_32to32_1722324645/20231215151901_32to32_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 196/196 [05:03<00:00,  1.55s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 1/196 [00:03<10:30,  3.23s/it]Progress image saved at step 1 (0%): ./outputs/20231215151901_32to32_1722324973/20231215151901_32to32_normal_stride16_size64_batchsize512_progress_0percent.png\n",
            " 25% 49/196 [01:17<03:41,  1.51s/it]Progress image saved at step 49 (25%): ./outputs/20231215151901_32to32_1722324973/20231215151901_32to32_normal_stride16_size64_batchsize512_progress_25percent.png\n",
            " 50% 98/196 [02:32<02:28,  1.51s/it]Progress image saved at step 98 (50%): ./outputs/20231215151901_32to32_1722324973/20231215151901_32to32_normal_stride16_size64_batchsize512_progress_50percent.png\n",
            " 75% 147/196 [03:49<01:13,  1.51s/it]Progress image saved at step 147 (75%): ./outputs/20231215151901_32to32_1722324973/20231215151901_32to32_normal_stride16_size64_batchsize512_progress_75percent.png\n",
            "100% 196/196 [05:04<00:00,  1.55s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIO94yCc7p_-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2E0IGrW7qCX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHr2fwlc7qUg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK-Wp-KIVaWa",
        "outputId": "53f61f86-47ea-45c7-f980-37c1e0b88715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/50 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_20to50_1722138410/20231215151901_20to50_normal_stride32_size32_batchsize512_progress_0percent.png\n",
            " 24% 12/50 [00:09<00:24,  1.57it/s]Progress image saved at step 12 (24%): ./outputs/20231215151901_20to50_1722138410/20231215151901_20to50_normal_stride32_size32_batchsize512_progress_24percent.png\n",
            " 50% 25/50 [00:18<00:15,  1.58it/s]Progress image saved at step 25 (50%): ./outputs/20231215151901_20to50_1722138410/20231215151901_20to50_normal_stride32_size32_batchsize512_progress_50percent.png\n",
            " 74% 37/50 [00:28<00:08,  1.56it/s]Progress image saved at step 37 (74%): ./outputs/20231215151901_20to50_1722138410/20231215151901_20to50_normal_stride32_size32_batchsize512_progress_74percent.png\n",
            "100% 50/50 [00:40<00:00,  1.25it/s]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "usage: inference_v26_reversed_ckpt11.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                                        [--model_path MODEL_PATH] [--out_path OUT_PATH]\n",
            "                                        [--stride STRIDE] [--start_idx START_IDX]\n",
            "                                        [--end_idx END_IDX] [--workers WORKERS]\n",
            "                                        [--batch_size BATCH_SIZE] [--size SIZE]\n",
            "                                        [--reverse REVERSE] [-h]\n",
            "inference_v26_reversed_ckpt11.py: error: unrecognized arguments: --start_idxc 20\n"
          ]
        }
      ],
      "source": [
        "!python inference_v26_normal_ckpt11.py --reverse 0 --segment_id 20231215151901 --start_idx 20 --end_idx 50 --stride 32 --size 32\n",
        "!python inference_v26_reversed_ckpt11.py --reverse 1 --segment_id 20231215151901 --start_idx 20 --end_idx 50 --stride 32 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3-l3x57VaY-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_DIeqdZVtob",
        "outputId": "d53a4e6e-d5c3-44f0-890f-0ef652c6b170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_30to34_1722137740/20231215151901_30to34_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:20<00:53,  1.45s/it]Progress image saved at step 12 (24%): ./outputs/20231215151901_30to34_1722137740/20231215151901_30to34_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:39<00:36,  1.46s/it]Progress image saved at step 24 (48%): ./outputs/20231215151901_30to34_1722137740/20231215151901_30to34_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [00:58<00:19,  1.47s/it]Progress image saved at step 36 (73%): ./outputs/20231215151901_30to34_1722137740/20231215151901_30to34_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [01:20<00:00,  1.65s/it]\n"
          ]
        }
      ],
      "source": [
        "#!python inference_v26_normal_ckpt11.py --reverse 0 --segment_id 20231215151901 --start_idx 30 --end_idx 34 --stride 32 --size 64\n",
        "!python inference_v26_reversed_ckpt11.py --reverse 1 --segment_id 20231215151901 --start_idx 30 --end_idx 34 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EonsCdWHVtq8"
      },
      "outputs": [],
      "source": [
        "%cd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-tLjtryVttc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udjB_gD9TrFQ"
      },
      "source": [
        "## timeformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "e7PlRvtYR4ze",
        "outputId": "af402b26-1ad5-4078-9012-c3f927fa0082"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (<ipython-input-20-9f21c6522976>, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-9f21c6522976>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    content/drive/MyDrive/A_Scroll/inkception-3d/checkpoints/valid_valid-1_0_fr_i3depoch=11.ckpt()\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ],
      "source": [
        " #/content/drive/MyDrive/A_Scroll/inkception-3d/checkpoints/valid_valid-1_0_fr_i3depoch=11.ckpt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO-7Rl0PRr3G",
        "outputId": "a5be9450-72cb-4271-b5f1-ffa26b70bf68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/migration/utils.py:55: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.3.3, which is newer than your current Lightning version: v2.0.9\n",
            "  rank_zero_warn(\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_32to32_1722294182/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:20<00:53,  1.44s/it]Progress image saved at step 12 (24%): ./outputs/20231215151901_32to32_1722294182/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:39<00:35,  1.43s/it]Progress image saved at step 24 (48%): ./outputs/20231215151901_32to32_1722294182/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [00:58<00:18,  1.45s/it]Progress image saved at step 36 (73%): ./outputs/20231215151901_32to32_1722294182/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [01:19<00:00,  1.63s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v28_reversed_ckpt11.py --reverse 1 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/1-outputsvesuvius-models/valid_valid-1_0_fr_i3depoch=11.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orYF_wj7llLb"
      },
      "outputs": [],
      "source": [
        "!python inference_v28_reversed_ckpt11.py --reverse 1 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/1-outputsvesuvius-models/valid_valid-1_0_fr_i3depoch=10.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcPPOJqCllOI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uvl_C5fellQx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK6qgPnHllTq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tov18O-vllWR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkBSFhzq9FcW",
        "outputId": "b09ae370-ba83-4856-8b05-b7084afd0e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/A_Scroll/inkception-3d/wandb/run-20240730_011515-tj2n9p9r\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mALL_scrolls_tta\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/tj2n9p9r\u001b[0m\n",
            "\n",
            "Loading image 1 of 8...\n",
            "./eval_segments_shared/20231215151901/layers/30.tif\n",
            "Loading image 2 of 8...\n",
            "./eval_segments_shared/20231215151901/layers/31.tif\n",
            "Loading image 3 of 8...\n",
            "./eval_segments_shared/20231215151901/layers/32.tif\n",
            "Loading image 4 of 8...\n",
            "./eval_segments_shared/20231215151901/layers/33.tif\n",
            "Loading image 5 of 8...\n",
            "./eval_segments_shared/20231215151901/layers/34.tif\n",
            "Loading image 6 of 8...\n",
            "./eval_segments_shared/20231215151901/layers/35.tif\n",
            "Loading image 7 of 8...\n",
            "./eval_segments_shared/20231215151901/layers/36.tif\n",
            "Loading image 8 of 8...\n",
            "./eval_segments_shared/20231215151901/layers/37.tif\n",
            "Successfully loaded 8 images.\n",
            "Reverse Segment\n",
            "100% 99/99 [00:40<00:00,  2.42it/s]\n",
            "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
            "\n",
            "Saving predictions...\n",
            "Done.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mALL_scrolls_tta\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/tj2n9p9r\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240730_011515-tj2n9p9r/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_6_rev.py --reverse 1 --segment_id 20231215151901 --start 30 --num_layers 8 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwpERqkB9e3Z",
        "outputId": "21c0e3e5-3519-486a-a9c6-d9ca0394a7f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_timesformer_5_rev.py\", line 372, in <module>\n",
            "    model = RegressionPLModel.load_from_checkpoint(args.model_path, strict=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1543, in load_from_checkpoint\n",
            "    loaded = _load_from_checkpoint(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 63, in _load_from_checkpoint\n",
            "    checkpoint = pl_load(checkpoint_path, map_location=map_location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/cloud_io.py\", line 52, in _load\n",
            "    return torch.load(f, map_location=map_location)  # type: ignore[arg-type]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1004, in load\n",
            "    with _open_zipfile_reader(opened_file) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 456, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))\n",
            "RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_5_rev.py --reverse 1 --segment_id 20231215151901 --start 32 --num_layers 1 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXIU8M_J997C",
        "outputId": "5a6aa57b-c0a7-4a9e-89b6-9f372abb9dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_timesformer_5_rev.py\", line 372, in <module>\n",
            "    model = RegressionPLModel.load_from_checkpoint(args.model_path, strict=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1543, in load_from_checkpoint\n",
            "    loaded = _load_from_checkpoint(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 63, in _load_from_checkpoint\n",
            "    checkpoint = pl_load(checkpoint_path, map_location=map_location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/cloud_io.py\", line 52, in _load\n",
            "    return torch.load(f, map_location=map_location)  # type: ignore[arg-type]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1004, in load\n",
            "    with _open_zipfile_reader(opened_file) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 456, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))\n",
            "RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_5_rev.py --segment_id 20231215151901 --start 32 --num_layers 1 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/models/wild14_deduped_64_pretrained2_20231210121321_0_fr_i3depoch=3-v2_256.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSnnaun8-Ihw"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231215151901 --start_idx 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AFQjE_VV4dw"
      },
      "source": [
        "##tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRvcZ_pY6bRW"
      },
      "outputs": [],
      "source": [
        "inference_v25_normal_se_resnext50_32x4d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uFBXzPq2OKH",
        "outputId": "78e3cb3f-6e11-4bf4-9ee2-87acf1021b08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 2/254 [00:04<09:35,  2.28s/it]Progress image saved at step 2 (0%): ./outputs/20231016151002_20to50_1722062451/20231016151002_20to50_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 63/254 [01:37<04:38,  1.46s/it]Progress image saved at step 63 (24%): ./outputs/20231016151002_20to50_1722062451/20231016151002_20to50_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 127/254 [03:20<03:16,  1.55s/it]Progress image saved at step 127 (50%): ./outputs/20231016151002_20to50_1722062451/20231016151002_20to50_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 72% 183/254 [04:58<01:55,  1.63s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal_se_resnext50_32x4d.py\", line 705, in <module>\n",
            "    mask_pred = predict_fn(test_loader, model, device, test_xyxz, test_shape)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal_se_resnext50_32x4d.py\", line 655, in predict_fn\n",
            "    y_preds = torch.sigmoid(y_preds).to('cpu')\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal_se_resnext50_32x4d.py --reverse 0 --segment_id 20231016151002 --start_idx 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncq374fh2OMk",
        "outputId": "307b7c65-81ea-4c3d-de47-f97868c69a28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 2/254 [00:04<09:32,  2.27s/it]Progress image saved at step 2 (0%): ./outputs/20231016151002_20to50_1722061331/20231016151002_20to50_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 63/254 [01:37<04:42,  1.48s/it]Progress image saved at step 63 (24%): ./outputs/20231016151002_20to50_1722061331/20231016151002_20to50_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 127/254 [03:20<03:10,  1.50s/it]Progress image saved at step 127 (50%): ./outputs/20231016151002_20to50_1722061331/20231016151002_20to50_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 190/254 [05:05<01:36,  1.51s/it]Progress image saved at step 190 (74%): ./outputs/20231016151002_20to50_1722061331/20231016151002_20to50_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            " 96% 245/254 [06:43<00:13,  1.53s/it]"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal_resnet3d.py --reverse 0 --segment_id 20231016151002 --start_idx 20 --end_idx 50 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoHKxhE12OO9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ckuGjaRVre1"
      },
      "source": [
        "##brunis segs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPjP5bP-POb8",
        "outputId": "098b498c-fb26-4f29-e134-ed80132551d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "Image file not found for index 20\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 697, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 272, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "usage: inference_v25_reversed.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                                 [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                                 [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                                 [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v25_reversed.py: error: unrecognized arguments: --start_idxc 20\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240415174406 --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240415174406 --start_idxc 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp5QP6XonH0n",
        "outputId": "ac1f0487-70e5-45b4-ba4b-31a5db703be2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "Image file not found for index 20\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 697, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 272, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "usage: inference_v25_reversed.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                                 [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                                 [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                                 [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v25_reversed.py: error: unrecognized arguments: --start_idxc 20\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240415174219 --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240415174219 --start_idxc 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX9FLcxLPOek",
        "outputId": "4cc8aef6-e1c5-42e3-a8ec-1f4a4ce33053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "Image file not found for index 20\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 697, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 272, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "usage: inference_v25_reversed.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                                 [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                                 [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                                 [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v25_reversed.py: error: unrecognized arguments: --start_idxc 20\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240413132301 --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240413132301 --start_idxc 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPD6iAqKPOhE",
        "outputId": "88d3be71-30ce-4515-8224-27760ac1718d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "Image file not found for index 20\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 697, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 272, in get_img_splits\n",
            "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "usage: inference_v25_reversed.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                                 [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                                 [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                                 [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v25_reversed.py: error: unrecognized arguments: --start_idxc 20\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240415174406 --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240415174406 --start_idxc 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFmmg20_nKgs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktsj0CJknKlG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNjJA68unKqF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLsEdojxB7gw",
        "outputId": "56163dfc-73c1-4826-cd01-c005df4e17a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/migration/utils.py:55: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.0.9.post0, which is newer than your current Lightning version: v2.0.9\n",
            "  rank_zero_warn(\n",
            "  0% 0/49 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20231215151901_32to32_1721789071/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 12/49 [00:21<00:55,  1.49s/it]Progress image saved at step 12 (24%): ./outputs/20231215151901_32to32_1721789071/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 49% 24/49 [00:40<00:37,  1.50s/it]Progress image saved at step 24 (48%): ./outputs/20231215151901_32to32_1721789071/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_48percent.png\n",
            " 73% 36/49 [01:00<00:19,  1.53s/it]Progress image saved at step 36 (73%): ./outputs/20231215151901_32to32_1721789071/20231215151901_32to32_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 49/49 [01:23<00:00,  1.71s/it]\n",
            "usage: inference_v25_reversed.py [--segment_id SEGMENT_ID] [--segment_path SEGMENT_PATH]\n",
            "                                 [--model_path MODEL_PATH] [--out_path OUT_PATH] [--stride STRIDE]\n",
            "                                 [--start_idx START_IDX] [--end_idx END_IDX] [--workers WORKERS]\n",
            "                                 [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE] [-h]\n",
            "inference_v25_reversed.py: error: unrecognized arguments: --start_idxc 32\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231215151901 --start_idxc 32 --end_idx 32 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY_N-iHDrneb",
        "outputId": "e1a43dbe-dd8e-4959-f9fa-2285691c30ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/A_Scroll/inkception-3d/wandb/run-20240722_053709-3urlnwwb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mALL_scrolls_tta\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/3urlnwwb\u001b[0m\n",
            "\n",
            "Loading image 1 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/00.tif\n",
            "Loading image 2 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/01.tif\n",
            "Loading image 3 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/02.tif\n",
            "Loading image 4 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/03.tif\n",
            "Loading image 5 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/04.tif\n",
            "Loading image 6 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/05.tif\n",
            "Loading image 7 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/06.tif\n",
            "Loading image 8 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/07.tif\n",
            "Loading image 9 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/08.tif\n",
            "Loading image 10 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/09.tif\n",
            "Loading image 11 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/10.tif\n",
            "Loading image 12 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/11.tif\n",
            "Loading image 13 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/12.tif\n",
            "Loading image 14 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/13.tif\n",
            "Loading image 15 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/14.tif\n",
            "Loading image 16 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/15.tif\n",
            "Loading image 17 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/16.tif\n",
            "Loading image 18 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/17.tif\n",
            "Loading image 19 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/18.tif\n",
            "Loading image 20 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/19.tif\n",
            "Loading image 21 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/20.tif\n",
            "Loading image 22 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/21.tif\n",
            "Loading image 23 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/22.tif\n",
            "Loading image 24 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/23.tif\n",
            "Loading image 25 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/24.tif\n",
            "Loading image 26 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/25.tif\n",
            "Loading image 27 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/26.tif\n",
            "Loading image 28 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/27.tif\n",
            "Loading image 29 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/28.tif\n",
            "Loading image 30 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/29.tif\n",
            "Loading image 31 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/30.tif\n",
            "Loading image 32 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/31.tif\n",
            "Loading image 33 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/32.tif\n",
            "Loading image 34 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/33.tif\n",
            "Loading image 35 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/34.tif\n",
            "Loading image 36 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/35.tif\n",
            "Loading image 37 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/36.tif\n",
            "Loading image 38 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/37.tif\n",
            "Loading image 39 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/38.tif\n",
            "Loading image 40 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/39.tif\n",
            "Loading image 41 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/40.tif\n",
            "Loading image 42 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/41.tif\n",
            "Loading image 43 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/42.tif\n",
            "Loading image 44 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/43.tif\n",
            "Loading image 45 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/44.tif\n",
            "Loading image 46 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/45.tif\n",
            "Loading image 47 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/46.tif\n",
            "Loading image 48 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/47.tif\n",
            "Loading image 49 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/48.tif\n",
            "Loading image 50 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/49.tif\n",
            "Loading image 51 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/50.tif\n",
            "Loading image 52 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/51.tif\n",
            "Loading image 53 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/52.tif\n",
            "Loading image 54 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/53.tif\n",
            "Loading image 55 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/54.tif\n",
            "Loading image 56 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/55.tif\n",
            "Loading image 57 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/56.tif\n",
            "Loading image 58 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/57.tif\n",
            "Loading image 59 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/58.tif\n",
            "Loading image 60 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/59.tif\n",
            "Loading image 61 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/60.tif\n",
            "Loading image 62 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/61.tif\n",
            "Loading image 63 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/62.tif\n",
            "Loading image 64 of 64...\n",
            "./eval_segments_shared/20231016151002/layers/63.tif\n",
            "Successfully loaded 64 images.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 1180/1180 [1:03:11<00:00,  3.21s/it]\n",
            "\n",
            "Saving predictions...\n",
            "Done.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mALL_scrolls_tta\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/3urlnwwb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240722_053709-3urlnwwb/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_2.py --segment_id 20231016151002 --start 00 --num_layers 64 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry17fu0AdHm4"
      },
      "outputs": [],
      "source": [
        "!python inference_timesformer_reversed_2.py --segment_id \t20231016151002 --start 20 --num_layers 30 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdPxSYsdm5k8",
        "outputId": "5784a5d8-893f-4a1d-f1cb-c196a57b2c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_timesformer_2.py\", line 14, in <module>\n",
            "    from timesformer_pytorch import TimeSformer\n",
            "ModuleNotFoundError: No module named 'timesformer_pytorch'\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_2.py --segment_id 20240623200654_5_64 --start 50 --num_layers 10 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNXKsRRAm4bM"
      },
      "outputs": [],
      "source": [
        "20240623200654_5_64_50to60_stride32_size64_batchsize512_01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSJutehUdUZu",
        "outputId": "b3af0bcb-e399-42a2-98d8-7384ccb32580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\n",
            "Loading image 1 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/20.tif\n",
            "Loading image 2 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/21.tif\n",
            "Loading image 3 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/22.tif\n",
            "Loading image 4 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/23.tif\n",
            "Loading image 5 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/24.tif\n",
            "Loading image 6 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/25.tif\n",
            "Loading image 7 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/26.tif\n",
            "Loading image 8 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/27.tif\n",
            "Loading image 9 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/28.tif\n",
            "Loading image 10 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/29.tif\n",
            "Loading image 11 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/30.tif\n",
            "Loading image 12 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/31.tif\n",
            "Loading image 13 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/32.tif\n",
            "Loading image 14 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/33.tif\n",
            "Loading image 15 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/34.tif\n",
            "Loading image 16 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/35.tif\n",
            "Loading image 17 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/36.tif\n",
            "Loading image 18 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/37.tif\n",
            "Loading image 19 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/38.tif\n",
            "Loading image 20 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/39.tif\n",
            "Successfully loaded 20 images.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 98/98 [01:39<00:00,  1.02s/it]\n",
            "\n",
            "Saving predictions...\n",
            "Done.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/A_Scroll/inkception-3d/wandb/offline-run-20240724_072021-byngr8v8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20240724_072021-byngr8v8/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_2.py --segment_id 20240102231959_og --start 20 --num_layers 20 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc-MNxoedMKl",
        "outputId": "d199b735-f014-4336-8abd-18292b985dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\n",
            "Loading image 1 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/20.tif\n",
            "Loading image 2 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/21.tif\n",
            "Loading image 3 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/22.tif\n",
            "Loading image 4 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/23.tif\n",
            "Loading image 5 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/24.tif\n",
            "Loading image 6 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/25.tif\n",
            "Loading image 7 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/26.tif\n",
            "Loading image 8 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/27.tif\n",
            "Loading image 9 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/28.tif\n",
            "Loading image 10 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/29.tif\n",
            "Loading image 11 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/30.tif\n",
            "Loading image 12 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/31.tif\n",
            "Loading image 13 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/32.tif\n",
            "Loading image 14 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/33.tif\n",
            "Loading image 15 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/34.tif\n",
            "Loading image 16 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/35.tif\n",
            "Loading image 17 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/36.tif\n",
            "Loading image 18 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/37.tif\n",
            "Loading image 19 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/38.tif\n",
            "Loading image 20 of 20...\n",
            "./eval_segments_shared/20240102231959_og/layers/39.tif\n",
            "Successfully loaded 20 images.\n",
            "Reverse Segment\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 98/98 [01:45<00:00,  1.07s/it]\n",
            "\n",
            "Saving predictions...\n",
            "Done.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/A_Scroll/inkception-3d/wandb/offline-run-20240724_073641-s0nbakpm\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20240724_073641-s0nbakpm/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_reversed_2.py --segment_id 20240102231959_og --start 20 --num_layers 20 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaicKU7GdMM1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMS-_9-JdMPW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3G3QeJUdMRw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJTrtACMB7Y7"
      },
      "outputs": [],
      "source": [
        "!python inference_timesformer_2.py --segment_id 20231215151901 --start 30 --num_layers 4 --stride 32 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhNqHV-HMCX-",
        "outputId": "1e678369-e401-4c22-a433-6d7a504f593e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/A_Scroll/inkception-3d/wandb/run-20240722_020716-bwbc4v92\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mALL_scrolls_tta\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/bwbc4v92\u001b[0m\n",
            "\n",
            "Loading image 1 of 4...\n",
            "./eval_segments_shared/20231215151901/layers/30.tif\n",
            "Loading image 2 of 4...\n",
            "./eval_segments_shared/20231215151901/layers/31.tif\n",
            "Loading image 3 of 4...\n",
            "./eval_segments_shared/20231215151901/layers/32.tif\n",
            "Loading image 4 of 4...\n",
            "./eval_segments_shared/20231215151901/layers/33.tif\n",
            "Successfully loaded 4 images.\n",
            "Reverse Segment\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 229/229 [00:52<00:00,  4.39it/s]\n",
            "\n",
            "Saving predictions...\n",
            "Done.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mALL_scrolls_tta\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/bwbc4v92\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240722_020716-bwbc4v92/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_reversed_2.py --segment_id 20231215151901 --start 30 --num_layers 4 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FMf3txqB7eD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_X7Ciy8A_q4",
        "outputId": "cb0a667f-88bd-4810-a7fe-30f49c6cc8b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `python inference_timesformer_2.py --segment_id <id> --start <s> --num_layers <n>'\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_2.py --segment_id <id> --start <s> --num_layers <n>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKfV55vSl1_P"
      },
      "source": [
        "##530"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_urvqR66l4Eu",
        "outputId": "9691abd2-a3c3-4d0c-ab69-698e58875be9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/34 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240304141530_cropped_1_20to50_1721473986/20240304141530_cropped_1_20to50_normal_stride32_size32_batchsize512_progress_0percent.png\n",
            " 24% 8/34 [00:06<00:17,  1.49it/s]Progress image saved at step 8 (23%): ./outputs/20240304141530_cropped_1_20to50_1721473986/20240304141530_cropped_1_20to50_normal_stride32_size32_batchsize512_progress_23percent.png\n",
            " 50% 17/34 [00:13<00:11,  1.54it/s]Progress image saved at step 17 (50%): ./outputs/20240304141530_cropped_1_20to50_1721473986/20240304141530_cropped_1_20to50_normal_stride32_size32_batchsize512_progress_50percent.png\n",
            " 74% 25/34 [00:19<00:06,  1.49it/s]Progress image saved at step 25 (73%): ./outputs/20240304141530_cropped_1_20to50_1721473986/20240304141530_cropped_1_20to50_normal_stride32_size32_batchsize512_progress_73percent.png\n",
            "100% 34/34 [00:27<00:00,  1.23it/s]\n",
            "set dataset path\n",
            "  0% 0/34 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240304141530_cropped_1_20to50_1721474030/20240304141530_cropped_1_20to50_reversed_stride32_size32_batchsize512_progress_0percent.png\n",
            " 24% 8/34 [00:06<00:17,  1.47it/s]Progress image saved at step 8 (23%): ./outputs/20240304141530_cropped_1_20to50_1721474030/20240304141530_cropped_1_20to50_reversed_stride32_size32_batchsize512_progress_23percent.png\n",
            " 50% 17/34 [00:13<00:11,  1.52it/s]Progress image saved at step 17 (50%): ./outputs/20240304141530_cropped_1_20to50_1721474030/20240304141530_cropped_1_20to50_reversed_stride32_size32_batchsize512_progress_50percent.png\n",
            " 74% 25/34 [00:19<00:06,  1.47it/s]Progress image saved at step 25 (73%): ./outputs/20240304141530_cropped_1_20to50_1721474030/20240304141530_cropped_1_20to50_reversed_stride32_size32_batchsize512_progress_73percent.png\n",
            "100% 34/34 [00:27<00:00,  1.22it/s]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304141530_cropped_1 --start_idx 20 --end_idx 50 --stride 32 --size 32\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304141530_cropped_1 --start_idx 20 --end_idx 50 --stride 32 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PozXGDRzlKf"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304141530_cropped_1 --start_idx 64 --end_idx 64 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304141530_cropped_1 --start_idx 64 --end_idx 64 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZeNt4qszlM-"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304141530_cropped_1 --start_idx 00 --end_idx 00 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304141530_cropped_1 --start_idx 00 --end_idx 00 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFqDaS0A0OwP"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304141530_cropped_1 --start_idx 20 --end_idx 30 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304141530_cropped_1 --start_idx 20 --end_idx 30 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBT5lVdK0Oys",
        "outputId": "8a73f43a-cb3e-4153-9eb0-0c5030dbbfd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/34 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240304141530_cropped_1_10to10_1721604207/20240304141530_cropped_1_10to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 8/34 [00:14<00:39,  1.51s/it]Progress image saved at step 8 (23%): ./outputs/20240304141530_cropped_1_10to10_1721604207/20240304141530_cropped_1_10to10_normal_stride32_size64_batchsize512_progress_23percent.png\n",
            " 50% 17/34 [00:28<00:24,  1.46s/it]Progress image saved at step 17 (50%): ./outputs/20240304141530_cropped_1_10to10_1721604207/20240304141530_cropped_1_10to10_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 74% 25/34 [00:41<00:13,  1.49s/it]Progress image saved at step 25 (73%): ./outputs/20240304141530_cropped_1_10to10_1721604207/20240304141530_cropped_1_10to10_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 34/34 [00:55<00:00,  1.63s/it]\n",
            "set dataset path\n",
            "  0% 0/34 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240304141530_cropped_1_10to10_1721604349/20240304141530_cropped_1_10to10_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 8/34 [00:14<00:40,  1.55s/it]Progress image saved at step 8 (23%): ./outputs/20240304141530_cropped_1_10to10_1721604349/20240304141530_cropped_1_10to10_reversed_stride32_size64_batchsize512_progress_23percent.png\n",
            " 50% 17/34 [00:28<00:25,  1.50s/it]Progress image saved at step 17 (50%): ./outputs/20240304141530_cropped_1_10to10_1721604349/20240304141530_cropped_1_10to10_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 74% 25/34 [00:42<00:13,  1.52s/it]Progress image saved at step 25 (73%): ./outputs/20240304141530_cropped_1_10to10_1721604349/20240304141530_cropped_1_10to10_reversed_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 34/34 [00:56<00:00,  1.67s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304141530_cropped_1 --start_idx 10 --end_idx 10 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304141530_cropped_1 --start_idx 10 --end_idx 10 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhQ1fTaZ0O1M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otfOnKSuzlPn",
        "outputId": "e9cf63ca-48dc-4b7a-f917-3a539500bc97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/3 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240304141530_cropped_2_20to50_1721476261/20240304141530_cropped_2_20to50_normal_stride64_size32_batchsize512_progress_0percent.png\n",
            " 33% 1/3 [00:01<00:02,  1.47s/it]Progress image saved at step 1 (33%): ./outputs/20240304141530_cropped_2_20to50_1721476261/20240304141530_cropped_2_20to50_normal_stride64_size32_batchsize512_progress_33percent.png\n",
            " 67% 2/3 [00:02<00:01,  1.13s/it]Progress image saved at step 2 (66%): ./outputs/20240304141530_cropped_2_20to50_1721476261/20240304141530_cropped_2_20to50_normal_stride64_size32_batchsize512_progress_66percent.png\n",
            "100% 3/3 [00:03<00:00,  1.10s/it]\n",
            "set dataset path\n",
            "  0% 0/3 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240304141530_cropped_2_20to50_1721476276/20240304141530_cropped_2_20to50_reversed_stride64_size32_batchsize512_progress_0percent.png\n",
            " 33% 1/3 [00:01<00:02,  1.47s/it]Progress image saved at step 1 (33%): ./outputs/20240304141530_cropped_2_20to50_1721476276/20240304141530_cropped_2_20to50_reversed_stride64_size32_batchsize512_progress_33percent.png\n",
            " 67% 2/3 [00:02<00:01,  1.15s/it]Progress image saved at step 2 (66%): ./outputs/20240304141530_cropped_2_20to50_1721476276/20240304141530_cropped_2_20to50_reversed_stride64_size32_batchsize512_progress_66percent.png\n",
            "100% 3/3 [00:03<00:00,  1.11s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304141530_cropped_2 --start_idx 20 --end_idx 50 --stride 64 --size 32\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304141530_cropped_2 --start_idx 20 --end_idx 50 --stride 64 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URw5WhXnl4HV",
        "outputId": "211575fe-3503-4095-8442-f7b5e72c006c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/11 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240304141530_cropped_2_30to34_1721476291/20240304141530_cropped_2_30to34_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 18% 2/11 [00:04<00:20,  2.31s/it]Progress image saved at step 2 (18%): ./outputs/20240304141530_cropped_2_30to34_1721476291/20240304141530_cropped_2_30to34_normal_stride32_size64_batchsize512_progress_18percent.png\n",
            " 45% 5/11 [00:09<00:10,  1.70s/it]Progress image saved at step 5 (45%): ./outputs/20240304141530_cropped_2_30to34_1721476291/20240304141530_cropped_2_30to34_normal_stride32_size64_batchsize512_progress_45percent.png\n",
            " 73% 8/11 [00:14<00:04,  1.61s/it]Progress image saved at step 8 (72%): ./outputs/20240304141530_cropped_2_30to34_1721476291/20240304141530_cropped_2_30to34_normal_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 11/11 [00:19<00:00,  1.80s/it]\n",
            "set dataset path\n",
            "  0% 0/11 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240304141530_cropped_2_30to34_1721476323/20240304141530_cropped_2_30to34_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 18% 2/11 [00:04<00:20,  2.26s/it]Progress image saved at step 2 (18%): ./outputs/20240304141530_cropped_2_30to34_1721476323/20240304141530_cropped_2_30to34_reversed_stride32_size64_batchsize512_progress_18percent.png\n",
            " 45% 5/11 [00:09<00:10,  1.70s/it]Progress image saved at step 5 (45%): ./outputs/20240304141530_cropped_2_30to34_1721476323/20240304141530_cropped_2_30to34_reversed_stride32_size64_batchsize512_progress_45percent.png\n",
            " 73% 8/11 [00:14<00:04,  1.63s/it]Progress image saved at step 8 (72%): ./outputs/20240304141530_cropped_2_30to34_1721476323/20240304141530_cropped_2_30to34_reversed_stride32_size64_batchsize512_progress_72percent.png\n",
            "100% 11/11 [00:19<00:00,  1.80s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304141530_cropped_2 --start_idx 32 --end_idx 32 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304141530_cropped_2 --start_idx 32 --end_idx 32 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdxdGKpQziXZ",
        "outputId": "76ee8a9a-9865-4ac0-ba46-df19197f2cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  0% 0/34 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240304141530_cropped_1_0to64_1721476356/20240304141530_cropped_1_0to64_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 8/34 [00:16<00:42,  1.63s/it]Progress image saved at step 8 (23%): ./outputs/20240304141530_cropped_1_0to64_1721476356/20240304141530_cropped_1_0to64_normal_stride32_size64_batchsize512_progress_23percent.png\n",
            " 50% 17/34 [00:32<00:26,  1.55s/it]Progress image saved at step 17 (50%): ./outputs/20240304141530_cropped_1_0to64_1721476356/20240304141530_cropped_1_0to64_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 74% 25/34 [00:46<00:14,  1.60s/it]Progress image saved at step 25 (73%): ./outputs/20240304141530_cropped_1_0to64_1721476356/20240304141530_cropped_1_0to64_normal_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 34/34 [01:01<00:00,  1.82s/it]\n",
            "set dataset path\n",
            "  0% 0/34 [00:00<?, ?it/s]Progress image saved at step 0 (0%): ./outputs/20240304141530_cropped_1_0to64_1721476447/20240304141530_cropped_1_0to64_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 24% 8/34 [00:15<00:43,  1.66s/it]Progress image saved at step 8 (23%): ./outputs/20240304141530_cropped_1_0to64_1721476447/20240304141530_cropped_1_0to64_reversed_stride32_size64_batchsize512_progress_23percent.png\n",
            " 50% 17/34 [00:30<00:27,  1.63s/it]Progress image saved at step 17 (50%): ./outputs/20240304141530_cropped_1_0to64_1721476447/20240304141530_cropped_1_0to64_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 74% 25/34 [00:45<00:14,  1.62s/it]Progress image saved at step 25 (73%): ./outputs/20240304141530_cropped_1_0to64_1721476447/20240304141530_cropped_1_0to64_reversed_stride32_size64_batchsize512_progress_73percent.png\n",
            "100% 34/34 [01:00<00:00,  1.77s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304141530_cropped_1 --start_idx 00 --end_idx 64 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304141530_cropped_1 --start_idx 00 --end_idx 64 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOzlLOQZ-9Ax",
        "outputId": "6408b197-57d1-4669-dd92-0446ebe8883a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "  1% 5/554 [00:09<15:24,  1.68s/it]Progress image saved at step 5 (0%): ./outputs/20240304141530_0to64_1721476524/20240304141530_0to64_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 138/554 [05:40<10:56,  1.58s/it]Progress image saved at step 138 (24%): ./outputs/20240304141530_0to64_1721476524/20240304141530_0to64_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 277/554 [10:14<07:14,  1.57s/it]Progress image saved at step 277 (50%): ./outputs/20240304141530_0to64_1721476524/20240304141530_0to64_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 415/554 [14:38<03:39,  1.58s/it]Progress image saved at step 415 (74%): ./outputs/20240304141530_0to64_1721476524/20240304141530_0to64_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 554/554 [19:10<00:00,  2.08s/it]\n",
            "set dataset path\n",
            "  1% 5/554 [00:09<15:48,  1.73s/it]Progress image saved at step 5 (0%): ./outputs/20240304141530_0to64_1721477847/20240304141530_0to64_reversed_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 138/554 [03:53<10:55,  1.58s/it]Progress image saved at step 138 (24%): ./outputs/20240304141530_0to64_1721477847/20240304141530_0to64_reversed_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 277/554 [07:58<07:15,  1.57s/it]Progress image saved at step 277 (50%): ./outputs/20240304141530_0to64_1721477847/20240304141530_0to64_reversed_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 415/554 [11:59<03:40,  1.58s/it]Progress image saved at step 415 (74%): ./outputs/20240304141530_0to64_1721477847/20240304141530_0to64_reversed_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 554/554 [16:09<00:00,  1.75s/it]\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304141530 --start_idx 00 --end_idx 64 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304141530 --start_idx 00 --end_idx 64 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkEWIxBnziZ_"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304141530 --start_idx 30 --end_idx 64 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304141530 --start_idx 30 --end_idx 64 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHOX8AcVzic3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo20s4i9l4J9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNkFOLuPkXkb"
      },
      "source": [
        "##4031"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20240304144031 --start_idx 10 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20240304144031 --start_idx 10 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrSM63a3jHVP",
        "outputId": "6b0945fc-c390-48dd-a15f-5a3a7e4a04a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 6/694 [00:07<11:36,  1.01s/it]Progress image saved at step 6 (0%): ./outputs/20240304144031_10to10_1722408786/20240304144031_10to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 173/694 [04:54<07:45,  1.12it/s]Progress image saved at step 173 (24%): ./outputs/20240304144031_10to10_1722408786/20240304144031_10to10_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 347/694 [08:25<05:10,  1.12it/s]Progress image saved at step 347 (50%): ./outputs/20240304144031_10to10_1722408786/20240304144031_10to10_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 520/694 [11:57<02:34,  1.12it/s]Progress image saved at step 520 (74%): ./outputs/20240304144031_10to10_1722408786/20240304144031_10to10_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 694/694 [15:46<00:00,  1.36s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 6/694 [00:07<11:25,  1.00it/s]Progress image saved at step 6 (0%): ./outputs/20240304144031_10to10_1722410119/20240304144031_10to10_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 173/694 [04:55<07:45,  1.12it/s]Progress image saved at step 173 (24%): ./outputs/20240304144031_10to10_1722410119/20240304144031_10to10_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 347/694 [09:00<05:09,  1.12it/s]Progress image saved at step 347 (50%): ./outputs/20240304144031_10to10_1722410119/20240304144031_10to10_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 520/694 [12:47<02:35,  1.12it/s]Progress image saved at step 520 (74%): ./outputs/20240304144031_10to10_1722410119/20240304144031_10to10_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 694/694 [16:12<00:00,  1.40s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20240304144031 --start_idx 32 --end_idx 32 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20240304144031 --start_idx 32 --end_idx 32 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK_AH6zfjH0D",
        "outputId": "112f92d3-a9d2-4883-fb29-1211c4a75513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 6/694 [00:06<11:18,  1.01it/s]Progress image saved at step 6 (0%): ./outputs/20240304144031_32to32_1722413761/20240304144031_32to32_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 173/694 [04:33<07:43,  1.12it/s]Progress image saved at step 173 (24%): ./outputs/20240304144031_32to32_1722413761/20240304144031_32to32_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 347/694 [08:27<05:09,  1.12it/s]Progress image saved at step 347 (50%): ./outputs/20240304144031_32to32_1722413761/20240304144031_32to32_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 520/694 [12:07<02:35,  1.12it/s]Progress image saved at step 520 (74%): ./outputs/20240304144031_32to32_1722413761/20240304144031_32to32_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 694/694 [15:33<00:00,  1.35s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 6/694 [00:07<11:38,  1.02s/it]Progress image saved at step 6 (0%): ./outputs/20240304144031_32to32_1722414988/20240304144031_32to32_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 173/694 [04:25<07:43,  1.12it/s]Progress image saved at step 173 (24%): ./outputs/20240304144031_32to32_1722414988/20240304144031_32to32_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 347/694 [08:35<05:08,  1.13it/s]Progress image saved at step 347 (50%): ./outputs/20240304144031_32to32_1722414988/20240304144031_32to32_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 520/694 [12:10<02:35,  1.12it/s]Progress image saved at step 520 (74%): ./outputs/20240304144031_32to32_1722414988/20240304144031_32to32_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 694/694 [15:28<00:00,  1.34s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_v29_normal_04ckpt17.py --reverse 0 --segment_id 20240304144031 --start_idx 20 --end_idx 50 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n",
        "!python inference_v29_rev_04ckpt17.py --reverse 1 --segment_id 20240304144031 --start_idx 20 --end_idx 50 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll_1/modelmain/training/outputs/vesuvius-models-4/vesuvius-3_valid-1_0_fr_i3depoch=17.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rah0BTWhjH2q",
        "outputId": "ed036b82-93a2-4e18-fd66-289a4404117e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 6/694 [00:07<11:37,  1.01s/it]Progress image saved at step 6 (0%): ./outputs/20240304144031_20to50_1722411266/20240304144031_20to50_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 173/694 [04:02<07:43,  1.12it/s]Progress image saved at step 173 (24%): ./outputs/20240304144031_20to50_1722411266/20240304144031_20to50_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 347/694 [07:35<05:08,  1.12it/s]Progress image saved at step 347 (50%): ./outputs/20240304144031_20to50_1722411266/20240304144031_20to50_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 520/694 [10:52<02:34,  1.13it/s]Progress image saved at step 520 (74%): ./outputs/20240304144031_20to50_1722411266/20240304144031_20to50_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 694/694 [14:27<00:00,  1.25s/it]\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
            "set dataset path\n",
            "  1% 6/694 [00:06<11:23,  1.01it/s]Progress image saved at step 6 (0%): ./outputs/20240304144031_20to50_1722412389/20240304144031_20to50_normal_stride32_size64_batchsize512_progress_0percent.png\n",
            " 25% 173/694 [06:41<07:44,  1.12it/s]Progress image saved at step 173 (24%): ./outputs/20240304144031_20to50_1722412389/20240304144031_20to50_normal_stride32_size64_batchsize512_progress_24percent.png\n",
            " 50% 347/694 [12:08<05:09,  1.12it/s]Progress image saved at step 347 (50%): ./outputs/20240304144031_20to50_1722412389/20240304144031_20to50_normal_stride32_size64_batchsize512_progress_50percent.png\n",
            " 75% 520/694 [16:43<02:36,  1.11it/s]Progress image saved at step 520 (74%): ./outputs/20240304144031_20to50_1722412389/20240304144031_20to50_normal_stride32_size64_batchsize512_progress_74percent.png\n",
            "100% 694/694 [20:15<00:00,  1.75s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_ysu63ljQIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVJNR_wSjQLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ebeyhhy5jQNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EPTmCOHRjQP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Fu7VujrBhsH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY7UlLSvBhve",
        "outputId": "2f0d0831-0957-4cda-e0d7-ffc9d3744ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set dataset path\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 697, in <module>\n",
            "    test_loader, test_xyxz, test_shape, fragment_mask = get_img_splits(fragment_id, args.start_idx, args.start_idx + in_chans, 0)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 271, in get_img_splits\n",
            "    image,fragment_mask = read_image_mask(fragment_id,s,e,rotation)\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_v25_normal.py\", line 242, in read_image_mask\n",
            "    image = cv2.imread(file_path, 0)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304141531_cropped_1 --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304141531_cropped_1 --start_idx 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDmh9-fEBhyO"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304141531 --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304141531 --start_idx 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdZBiioL4G8O"
      },
      "outputs": [],
      "source": [
        "20240304141531"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpMBQhwO4PRp"
      },
      "outputs": [],
      "source": [
        "20240304161941"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjWnqSVl4PaM"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240304161941 --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240304161941 --start_idx 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSv60yu24PjQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOz7Vbm04G-_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8BeqHPr1J4I"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231215151901 --start_idx 20 --end_idx 50 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231215151901 --start_idx 20 --end_idx 50 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNSUScUh_1w0"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231215151901 --start_idx 32 --end_idx 32 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYDWKrrN_1zK"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231215151901 --start_idx 20 --end_idx 50 --stride 64 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231215151901 --start_idx 20 --end_idx 50 --stride 64 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zzdGJBD_104"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231215151901 --start_idx 20 --end_idx 50 --stride 32 --size 32\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231215151901 --start_idx 20 --end_idx 50 --stride 32 --size 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18uSgs1enwmp"
      },
      "source": [
        "##*340"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5amEwQ11J6n"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_cropped_5 --start_idx 060 --end_idx 080 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FC0t1Tasi0P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3SibL0p1J9G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6HxYBJGvmjm"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_cropped_2 --start_idx 050 --end_idx 100 --stride 32 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omg5Qocrzjsi"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_cropped_2 --start_idx 060 --end_idx 080 --stride 32 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqdt_wwJ0m3z"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_cropped_2 --start_idx 035 --end_idx 102 --stride 32 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzgAn16c0m5_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVYaoVoW0m8X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1g_zqO-Sy2cX"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_cropped_2 --start_idx 070 --end_idx 070 --stride 32 --size 64\n",
        "#!python inference_v25_reversed.py --reverse 1 --segment_id 20231111135340_cropped_2 --start_idx 076 --end_idx 078 --stride 64 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-5sF3R9y2ew"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHadxQo9y2hA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIST3Dqrj12Q"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_cropped_2 --start_idx 040 --end_idx 090 --stride 48 --size 64\n",
        "#!python inference_v25_reversed.py --reverse 1 --segment_id 20231111135340_cropped_2 --start_idx 040 --end_idx 090 --stride 32 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7myiTsjYvYkB"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_cropped_2 --start_idx 080 --end_idx 080 --stride 32 --size 64\n",
        "#!python inference_v25_reversed.py --reverse 1 --segment_id 20231111135340_cropped_2 --start_idx 076 --end_idx 078 --stride 64 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD4UbJGDvePS"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_cropped_2 --start_idx 060 --end_idx 060 --stride 32 --size 64\n",
        "#!python inference_v25_reversed.py --reverse 1 --segment_id 20231111135340_cropped_2 --start_idx 076 --end_idx 078 --stride 64 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yjes0qG6YGHV"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_cropped_2 --start_idx 040 --end_idx 040 --stride 32 --size 64\n",
        "#!python inference_v25_reversed.py --reverse 1 --segment_id 20231111135340_cropped_2 --start_idx 076 --end_idx 078 --stride 64 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hidUWHm3MOj4"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_cropped_2 --start_idx 50 --end_idx 80 --stride 64 --size 32\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231111135340_cropped_2 --start_idx 50 --end_idx 80 --stride 64 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE2PtQQCYGEu"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_cropped_2 --start_idx 070--end_idx 080 --stride 128 --size 32\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231111135340_cropped_2 --start_idx 070 --end_idx 080 --stride 128 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7-1afY8MOmR"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_og --start_idx 078 --end_idx 078 --stride 64 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231111135340_og --start_idx 078 --end_idx 078 --stride 64 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUOpLnKoMOoy"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240623200654_5_64 --start_idx 025 --end_idx 025 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240623200654_5_64 --start_idx 025 --end_idx 025 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRSALio2MOqv"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240623200654_5_64 --start_idx 100 --end_idx 100 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240623200654_5_64 --start_idx 100 --end_idx 100 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFtFwM-mLGVT"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240623200654_5_64 --start_idx 030 --end_idx 030 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240623200654_5_64 --start_idx 030 --end_idx 030 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQUQshYqLGXv"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240623200654_5_64 --start_idx 040 --end_idx 050 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240623200654_5_64 --start_idx 040 --end_idx 050 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbdZDO6xLGaA"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240623200654_5_64 --start_idx 050 --end_idx 050 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240623200654_5_64 --start_idx 050 --end_idx 050 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B75G2U5LHcTr"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240623200654_5_64 --start_idx 110 --end_idx 110 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240623200654_5_64 --start_idx 110 --end_idx 110 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o_3Ka_6HcWI"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240623200654_5_64 --start_idx 000 --end_idx 050 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240623200654_5_64 --start_idx 000 --end_idx 050 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7TM6SLpHcYz"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240623200654_5_64 --start_idx 080 --end_idx 128 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240623200654_5_64 --start_idx 080 --end_idx 128 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO1E6QeiErl-"
      },
      "outputs": [],
      "source": [
        "20240710035048_1_64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PutmiTHH8BL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu834RNN6oHZ"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240619212214_2_32 --start_idx 20 --end_idx 50 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/wild14_deduped_64_pretrained2_20231210121321_0_fr_i3depoch=3-v2_256.ckpt\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240619212214_2_32 --start_idx 20 --end_idx 50 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/wild14_deduped_64_pretrained2_20231210121321_0_fr_i3depoch=3-v2_256.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQePLqow6oMI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XsNoqq-6oPw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsLq4UcW1BN5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soYCs5doxITf"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240619212214_og --start_idx 00 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/wild14_deduped_64_pretrained2_20231210121321_0_fr_i3depoch=3-v2_256.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240619212214_og --start_idx 00 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/wild14_deduped_64_pretrained2_20231210121321_0_fr_i3depoch=3-v2_256.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VawFZnj0xIOY"
      },
      "outputs": [],
      "source": [
        "20240619212214_og"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL5pQ3yr7lZ9"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcOlXcgSJvTs"
      },
      "source": [
        "##20240619212214"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw6HneeKxIQo"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240619212214_2_32 --start_idx 20 --end_idx 32 --stride 8 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240619212214_2_32 --start_idx 20 --end_idx 32 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNpvkkNzx9pk"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240619212214_2_32 --start_idx 30 --end_idx 34 --stride 4 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240619212214_2_32 --start_idx 30 --end_idx 34 --stride 4 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxfas-X-saoF"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240619212214_2_32 --start_idx 15 --end_idx 35 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240619212214_2_32 --start_idx 15 --end_idx 35 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZS1J1hvpYpi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMLlD23HLbAR"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240619212214_2_32 --start_idx 20 --end_idx 25 --stride 4 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240619212214_2_32 --start_idx 20 --end_idx 25 --stride 4 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl1e65pmLbCe"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240619212214_2_32 --start_idx 25 --end_idx 25 --stride 8 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240619212214_2_32 --start_idx 25 --end_idx 25 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neExW4E6LbE7"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240619212214_2_32 --start_idx 00 --end_idx 64 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240619212214_2_32 --start_idx 00 --end_idx 64 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA950EMzmepN"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240619212214_2_32 --start_idx 00 --end_idx 00 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240619212214_2_32 --start_idx 00 --end_idx 00 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ7zgVZWmeri"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240619212214_2_32 --start_idx 64 --end_idx 64 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240619212214_2_32 --start_idx 64 --end_idx 64 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssW3rsIVLbG4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1ASERTs1BGg"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240619212214_1_64 --start_idx 040 --end_idx 080 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240619212214_1_64 --start_idx 040 --end_idx 080 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tqsgqynz1BJG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlFsv3oK1BLd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfy2KTaMIf3D"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir0uGOwRMpZc"
      },
      "outputs": [],
      "source": [
        "20231111135340_og_64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2DJeEO1MurH"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_og_64 --start_idx 020 --end_idx 050 --stride 64 --size 32\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231111135340_og_64 --start_idx 020 --end_idx 050 --stride 64 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcJeJWv3Mutv"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_og_64 --start_idx 030 --end_idx 034 --stride 128 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231111135340_og_64 --start_idx 030 --end_idx 034 --stride 128 --size 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhMLusBtRXkL"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_og_64 --start_idx 032 --end_idx 032 --stride 128 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231111135340_og_64 --start_idx 032 --end_idx 032 --stride 128 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9gMT-QpYI--"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231111135340_og_64 --start_idx 026 --end_idx 038 --stride 256 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231111135340_og_64 --start_idx 026 --end_idx 038 --stride 256 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqf6wJmERXmz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RwY4Gf6RXpK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrODprtLMuwr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pBLXbNrXJfg"
      },
      "outputs": [],
      "source": [
        "!python inference_v12.py --reverse 0 --segment_id 20231111135340 --start_idx 30 --end_idx 30 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "#!python inference_v12.py --reverse 1 --segment_id 20231111135340 --start_idx 36 --end_idx 36 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36bqonrT_8Ew"
      },
      "outputs": [],
      "source": [
        "!python inference_v12.py --reverse 0 --segment_id 20231111135340 --start_idx 50 --end_idx 50 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "#!python inference_v12.py --reverse 1 --segment_id 20231111135340 --start_idx 06 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrFjqtbxUPXw"
      },
      "outputs": [],
      "source": [
        "!python inference_v12.py --reverse 0 --segment_id 20231111135340 --start_idx 40 --end_idx 40 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "#!python inference_v12.py --reverse 1 --segment_id 20231111135340 --start_idx 06 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5kTREd5UPaR"
      },
      "outputs": [],
      "source": [
        "!python inference_v12.py --reverse 0 --segment_id 20231111135340 --start_idx 58 --end_idx 58 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "#!python inference_v12.py --reverse 1 --segment_id 20231111135340 --start_idx 06 --end_idx 06 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xlc4RAyzUPcv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqVhd1vT2fzX"
      },
      "source": [
        "#604"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bvg4DoNRCYzm"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240626040604_3_64 --start_idx 064 --end_idx 090 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240626040604_3_64 --start_idx 064 --end_idx 090 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4XAnYCrlZeu"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240626040604_3_64 --start_idx 000 --end_idx 020 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240626040604_3_64 --start_idx 000 --end_idx 020 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzo_SE6ZlZhM"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240626040604_3_64 --start_idx 100 --end_idx 128 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240626040604_3_64 --start_idx 100 --end_idx 128 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPPhlXU3lm6v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Udtfj1FnlZjc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR5RKubXlZmG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPu_ZXvuZfH4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J44qU_FUN9g9"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 100 --end_idx 110 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 100 --end_idx 110 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hZwjMkmm1Ut"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 050 --end_idx 90 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 050 --end_idx 90 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGMHcb47zOnO"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 020 --end_idx 020 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 020 --end_idx 020 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "johqnj2wzOpd"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 095 --end_idx 100 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 095 --end_idx 100 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-VlNCpWzOr9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTTgTOVtm1Wr"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 110 --end_idx 128 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 110 --end_idx 128 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUD7cE79m1ZP"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 128 --end_idx 128 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 128 --end_idx 128 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkQ8QPfam1bk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvr0ZB-Xm1SP"
      },
      "outputs": [],
      "source": [
        "# Play an audio beep. Any audio URL will do.\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJB8bCfsjf97"
      },
      "source": [
        "# **scroll 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH9frdLTdsAZ"
      },
      "source": [
        "##720"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhW8CWtTNaL5",
        "outputId": "3aafe15c-4e2a-4f9d-db31-5c1994d72ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/A_Scroll/inkception-3d/wandb/run-20240722_021909-cxywchi0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mALL_scrolls_tta\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/cxywchi0\u001b[0m\n",
            "\n",
            "Loading image 1 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/20.tif\n",
            "Loading image 2 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/21.tif\n",
            "Loading image 3 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/22.tif\n",
            "Loading image 4 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/23.tif\n",
            "Loading image 5 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/24.tif\n",
            "Loading image 6 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/25.tif\n",
            "Loading image 7 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/26.tif\n",
            "Loading image 8 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/27.tif\n",
            "Loading image 9 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/28.tif\n",
            "Loading image 10 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/29.tif\n",
            "Loading image 11 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/30.tif\n",
            "Loading image 12 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/31.tif\n",
            "Loading image 13 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/32.tif\n",
            "Loading image 14 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/33.tif\n",
            "Loading image 15 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/34.tif\n",
            "Loading image 16 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/35.tif\n",
            "Loading image 17 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/36.tif\n",
            "Loading image 18 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/37.tif\n",
            "Loading image 19 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/38.tif\n",
            "Loading image 20 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/39.tif\n",
            "Loading image 21 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/40.tif\n",
            "Loading image 22 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/41.tif\n",
            "Loading image 23 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/42.tif\n",
            "Loading image 24 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/43.tif\n",
            "Loading image 25 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/44.tif\n",
            "Loading image 26 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/45.tif\n",
            "Loading image 27 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/46.tif\n",
            "Loading image 28 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/47.tif\n",
            "Loading image 29 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/48.tif\n",
            "Loading image 30 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/49.tif\n",
            "Successfully loaded 30 images.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 39/39 [01:00<00:00,  1.54s/it]\n",
            "\n",
            "Saving predictions...\n",
            "Done.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mALL_scrolls_tta\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/cxywchi0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240722_021909-cxywchi0/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\n",
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/A_Scroll/inkception-3d/wandb/run-20240722_022033-7vehswcd\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mALL_scrolls_tta\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/7vehswcd\u001b[0m\n",
            "\n",
            "Loading image 1 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/20.tif\n",
            "Loading image 2 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/21.tif\n",
            "Loading image 3 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/22.tif\n",
            "Loading image 4 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/23.tif\n",
            "Loading image 5 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/24.tif\n",
            "Loading image 6 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/25.tif\n",
            "Loading image 7 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/26.tif\n",
            "Loading image 8 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/27.tif\n",
            "Loading image 9 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/28.tif\n",
            "Loading image 10 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/29.tif\n",
            "Loading image 11 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/30.tif\n",
            "Loading image 12 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/31.tif\n",
            "Loading image 13 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/32.tif\n",
            "Loading image 14 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/33.tif\n",
            "Loading image 15 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/34.tif\n",
            "Loading image 16 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/35.tif\n",
            "Loading image 17 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/36.tif\n",
            "Loading image 18 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/37.tif\n",
            "Loading image 19 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/38.tif\n",
            "Loading image 20 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/39.tif\n",
            "Loading image 21 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/40.tif\n",
            "Loading image 22 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/41.tif\n",
            "Loading image 23 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/42.tif\n",
            "Loading image 24 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/43.tif\n",
            "Loading image 25 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/44.tif\n",
            "Loading image 26 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/45.tif\n",
            "Loading image 27 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/46.tif\n",
            "Loading image 28 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/47.tif\n",
            "Loading image 29 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/48.tif\n",
            "Loading image 30 of 30...\n",
            "./eval_segments_shared/20240109095720_og/layers/49.tif\n",
            "Successfully loaded 30 images.\n",
            "Reverse Segment\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 39/39 [01:00<00:00,  1.55s/it]\n",
            "\n",
            "Saving predictions...\n",
            "Done.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mALL_scrolls_tta\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/7vehswcd\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240722_022033-7vehswcd/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_2.py --segment_id 20240109095720_og --start 20 --num_layers 30 --stride 32 --size 64\n",
        "!python inference_timesformer_reversed_2.py --segment_id 20240109095720_og --start 20 --num_layers 30 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9_hDNHwNTUe",
        "outputId": "1c008cb3-9552-4e2e-bd21-a5ce5ae1c6ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/A_Scroll/inkception-3d/wandb/run-20240722_021145-0r9kebhk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mALL_scrolls_tta\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/0r9kebhk\u001b[0m\n",
            "\n",
            "Loading image 1 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/00.tif\n",
            "Loading image 2 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/01.tif\n",
            "Loading image 3 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/02.tif\n",
            "Loading image 4 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/03.tif\n",
            "Loading image 5 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/04.tif\n",
            "Loading image 6 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/05.tif\n",
            "Loading image 7 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/06.tif\n",
            "Loading image 8 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/07.tif\n",
            "Loading image 9 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/08.tif\n",
            "Loading image 10 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/09.tif\n",
            "Loading image 11 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/10.tif\n",
            "Loading image 12 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/11.tif\n",
            "Loading image 13 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/12.tif\n",
            "Loading image 14 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/13.tif\n",
            "Loading image 15 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/14.tif\n",
            "Loading image 16 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/15.tif\n",
            "Loading image 17 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/16.tif\n",
            "Loading image 18 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/17.tif\n",
            "Loading image 19 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/18.tif\n",
            "Loading image 20 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/19.tif\n",
            "Loading image 21 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/20.tif\n",
            "Loading image 22 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/21.tif\n",
            "Loading image 23 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/22.tif\n",
            "Loading image 24 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/23.tif\n",
            "Loading image 25 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/24.tif\n",
            "Loading image 26 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/25.tif\n",
            "Loading image 27 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/26.tif\n",
            "Loading image 28 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/27.tif\n",
            "Loading image 29 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/28.tif\n",
            "Loading image 30 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/29.tif\n",
            "Loading image 31 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/30.tif\n",
            "Loading image 32 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/31.tif\n",
            "Loading image 33 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/32.tif\n",
            "Loading image 34 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/33.tif\n",
            "Loading image 35 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/34.tif\n",
            "Loading image 36 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/35.tif\n",
            "Loading image 37 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/36.tif\n",
            "Loading image 38 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/37.tif\n",
            "Loading image 39 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/38.tif\n",
            "Loading image 40 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/39.tif\n",
            "Loading image 41 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/40.tif\n",
            "Loading image 42 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/41.tif\n",
            "Loading image 43 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/42.tif\n",
            "Loading image 44 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/43.tif\n",
            "Loading image 45 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/44.tif\n",
            "Loading image 46 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/45.tif\n",
            "Loading image 47 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/46.tif\n",
            "Loading image 48 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/47.tif\n",
            "Loading image 49 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/48.tif\n",
            "Loading image 50 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/49.tif\n",
            "Loading image 51 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/50.tif\n",
            "Loading image 52 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/51.tif\n",
            "Loading image 53 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/52.tif\n",
            "Loading image 54 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/53.tif\n",
            "Loading image 55 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/54.tif\n",
            "Loading image 56 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/55.tif\n",
            "Loading image 57 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/56.tif\n",
            "Loading image 58 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/57.tif\n",
            "Loading image 59 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/58.tif\n",
            "Loading image 60 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/59.tif\n",
            "Loading image 61 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/60.tif\n",
            "Loading image 62 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/61.tif\n",
            "Loading image 63 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/62.tif\n",
            "Loading image 64 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/63.tif\n",
            "Successfully loaded 64 images.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 39/39 [02:08<00:00,  3.29s/it]\n",
            "\n",
            "Saving predictions...\n",
            "Done.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mALL_scrolls_tta\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/0r9kebhk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240722_021145-0r9kebhk/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\n",
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/A_Scroll/inkception-3d/wandb/run-20240722_021632-om0rudpa\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mALL_scrolls_tta\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/om0rudpa\u001b[0m\n",
            "\n",
            "Loading image 1 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/00.tif\n",
            "Loading image 2 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/01.tif\n",
            "Loading image 3 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/02.tif\n",
            "Loading image 4 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/03.tif\n",
            "Loading image 5 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/04.tif\n",
            "Loading image 6 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/05.tif\n",
            "Loading image 7 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/06.tif\n",
            "Loading image 8 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/07.tif\n",
            "Loading image 9 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/08.tif\n",
            "Loading image 10 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/09.tif\n",
            "Loading image 11 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/10.tif\n",
            "Loading image 12 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/11.tif\n",
            "Loading image 13 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/12.tif\n",
            "Loading image 14 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/13.tif\n",
            "Loading image 15 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/14.tif\n",
            "Loading image 16 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/15.tif\n",
            "Loading image 17 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/16.tif\n",
            "Loading image 18 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/17.tif\n",
            "Loading image 19 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/18.tif\n",
            "Loading image 20 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/19.tif\n",
            "Loading image 21 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/20.tif\n",
            "Loading image 22 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/21.tif\n",
            "Loading image 23 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/22.tif\n",
            "Loading image 24 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/23.tif\n",
            "Loading image 25 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/24.tif\n",
            "Loading image 26 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/25.tif\n",
            "Loading image 27 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/26.tif\n",
            "Loading image 28 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/27.tif\n",
            "Loading image 29 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/28.tif\n",
            "Loading image 30 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/29.tif\n",
            "Loading image 31 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/30.tif\n",
            "Loading image 32 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/31.tif\n",
            "Loading image 33 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/32.tif\n",
            "Loading image 34 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/33.tif\n",
            "Loading image 35 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/34.tif\n",
            "Loading image 36 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/35.tif\n",
            "Loading image 37 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/36.tif\n",
            "Loading image 38 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/37.tif\n",
            "Loading image 39 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/38.tif\n",
            "Loading image 40 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/39.tif\n",
            "Loading image 41 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/40.tif\n",
            "Loading image 42 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/41.tif\n",
            "Loading image 43 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/42.tif\n",
            "Loading image 44 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/43.tif\n",
            "Loading image 45 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/44.tif\n",
            "Loading image 46 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/45.tif\n",
            "Loading image 47 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/46.tif\n",
            "Loading image 48 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/47.tif\n",
            "Loading image 49 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/48.tif\n",
            "Loading image 50 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/49.tif\n",
            "Loading image 51 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/50.tif\n",
            "Loading image 52 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/51.tif\n",
            "Loading image 53 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/52.tif\n",
            "Loading image 54 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/53.tif\n",
            "Loading image 55 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/54.tif\n",
            "Loading image 56 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/55.tif\n",
            "Loading image 57 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/56.tif\n",
            "Loading image 58 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/57.tif\n",
            "Loading image 59 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/58.tif\n",
            "Loading image 60 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/59.tif\n",
            "Loading image 61 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/60.tif\n",
            "Loading image 62 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/61.tif\n",
            "Loading image 63 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/62.tif\n",
            "Loading image 64 of 64...\n",
            "./eval_segments_shared/20240109095720_og/layers/63.tif\n",
            "Successfully loaded 64 images.\n",
            "Reverse Segment\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 39/39 [02:08<00:00,  3.30s/it]\n",
            "\n",
            "Saving predictions...\n",
            "Done.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mALL_scrolls_tta\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/om0rudpa\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240722_021632-om0rudpa/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_2.py --segment_id 20240109095720_og --start 00 --num_layers 64 --stride 32 --size 64\n",
        "!python inference_timesformer_reversed_2.py --segment_id 20240109095720_og --start 00 --num_layers 64 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8YSh1MBMhFb",
        "outputId": "35fb14b1-d622-4d96-a6a0-36e4bb934d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/A_Scroll/inkception-3d/wandb/run-20240722_021012-z41wulrs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mALL_scrolls_tta\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/z41wulrs\u001b[0m\n",
            "\n",
            "Loading image 1 of 6...\n",
            "./eval_segments_shared/20240109095720_og/layers/00.tif\n",
            "Loading image 2 of 6...\n",
            "./eval_segments_shared/20240109095720_og/layers/01.tif\n",
            "Loading image 3 of 6...\n",
            "./eval_segments_shared/20240109095720_og/layers/02.tif\n",
            "Loading image 4 of 6...\n",
            "./eval_segments_shared/20240109095720_og/layers/03.tif\n",
            "Loading image 5 of 6...\n",
            "./eval_segments_shared/20240109095720_og/layers/04.tif\n",
            "Loading image 6 of 6...\n",
            "./eval_segments_shared/20240109095720_og/layers/05.tif\n",
            "Successfully loaded 6 images.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 39/39 [00:13<00:00,  2.95it/s]\n",
            "\n",
            "Saving predictions...\n",
            "Done.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mALL_scrolls_tta\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/z41wulrs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240722_021012-z41wulrs/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\n",
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/A_Scroll/inkception-3d/wandb/run-20240722_021102-x075lui2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mALL_scrolls_tta\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/x075lui2\u001b[0m\n",
            "\n",
            "Loading image 1 of 6...\n",
            "./eval_segments_shared/20240109095720_og/layers/00.tif\n",
            "Loading image 2 of 6...\n",
            "./eval_segments_shared/20240109095720_og/layers/01.tif\n",
            "Loading image 3 of 6...\n",
            "./eval_segments_shared/20240109095720_og/layers/02.tif\n",
            "Loading image 4 of 6...\n",
            "./eval_segments_shared/20240109095720_og/layers/03.tif\n",
            "Loading image 5 of 6...\n",
            "./eval_segments_shared/20240109095720_og/layers/04.tif\n",
            "Loading image 6 of 6...\n",
            "./eval_segments_shared/20240109095720_og/layers/05.tif\n",
            "Successfully loaded 6 images.\n",
            "Reverse Segment\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 39/39 [00:13<00:00,  2.90it/s]\n",
            "\n",
            "Saving predictions...\n",
            "Done.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mALL_scrolls_tta\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/x075lui2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240722_021102-x075lui2/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_2.py --segment_id 20240109095720_og --start 00 --num_layers 6 --stride 32 --size 64\n",
        "!python inference_timesformer_reversed_2.py --segment_id 20240109095720_og --start 00 --num_layers 6 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS5fox4cMaMn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPI8AaOw74WM"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 00 --end_idx 06 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 00 --end_idx 06 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9z1sf68ItQ5"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 09 --end_idx 16 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 09 --end_idx 16 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytI26bRutoRA"
      },
      "outputs": [],
      "source": [
        "/content/drive/MyDrive/A_Scroll/inkception-3d/models/wild14_deduped_64_pretrained2_20231210121321_0_fr_i3depoch=3-v2_256.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZGLqx4sIya4"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 10 --end_idx 20 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 10 --end_idx 20 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPYKcusPIyfu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8EHiMvu6j0p"
      },
      "source": [
        "##4433\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpKxGgkhHPOQ"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_2_64 --start_idx 015 --end_idx 020 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py   --reverse 1 --segment_id \t20240116164433_2_64 --start_idx 015 --end_idx 020 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu0Vr4xuP53S"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_2_64 --start_idx 010 --end_idx 015 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py   --reverse 1 --segment_id \t20240116164433_2_64 --start_idx 010 --end_idx 015 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCmC1cHS3tYw"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_2_64 --start_idx 030 --end_idx 034 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py   --reverse 1 --segment_id \t20240116164433_2_64 --start_idx 030 --end_idx 034 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQCohFP73tbE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOpJhbI6P55p"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_2_64 --start_idx 050 --end_idx 050 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240116164433_2_64 --start_idx 050 --end_idx 050 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lM8l9tKfP58B"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_2_64 --start_idx 120 --end_idx 128 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240116164433_2_64 --start_idx 120 --end_idx 128 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47Tc1Of4TGt7"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_2_64 --start_idx 070 --end_idx 090 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240116164433_2_64 --start_idx 070 --end_idx 090 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA02Hr6YTGwZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axMiIW6rTGy1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqpE9QT6TG1L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a6JEYWpErqY"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_og --start_idx 10 --end_idx 10 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240116164433_og --start_idx 10 --end_idx 10 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxNugbHxCXEn"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_og --start_idx 00 --end_idx 10 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240116164433_og --start_idx 00 --end_idx 10 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQc0ImT4CXG-"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240116164433_og --start_idx 00 --end_idx 00 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240116164433_og --start_idx 00 --end_idx 00 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vAlmAg-NPQB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-KaxibqNPSS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FucnjW0SNPUy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iEbM-gACXJE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x_zeaw2aQ72"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240107134630_og --start_idx 30 --end_idx 40 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240107134630_og --start_idx 30 --end_idx 40 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVVFZIJStGFN"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240107134630_og --start_idx 20 --end_idx 50 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240107134630_og --start_idx 20 --end_idx 50 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-HI4PV4sEfj"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240107134630_og --start_idx 30 --end_idx 38 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240107134630_og --start_idx 30 --end_idx 38 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ikt7gYSyaQ-J"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id \t20240107134630_48 --start_idx 60 --end_idx 70 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id \t20240107134630_48 --start_idx 60 --end_idx 70 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd9aFSCcaRAo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LVksY4OXDID"
      },
      "outputs": [],
      "source": [
        "20240109095720_64_90to90_stride32_size64_batchsize512_01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGwWoVkFXDLL"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 090 --end_idx 20 --stride 4 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 090 --end_idx 20 --stride 4 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSVljBzXXDNx"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64_90 --start_idx 090 --end_idx 20 --stride 4 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64_90 --start_idx 090 --end_idx 20 --stride 4 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSpyrQSVXDQL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTNdCXgOXDSZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bvJvlXksl3y"
      },
      "source": [
        "##500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGCsnf5MbEXQ"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 169 --end_idx 172 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 169 --end_idx 172 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLqJfL6bd9w3"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 006 --stride 64 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 006 --stride 64 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obq-KTPdd9zH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL8002Jld91n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsfiVUqtbEZv"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 022 --end_idx 022 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 022 --end_idx 022 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKQURpgcMcIX"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 033 --end_idx 033 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 033 --end_idx 033 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwGqUymEMcSv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myYNp3dYbEcZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "950kTMWA2dbY"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 090 --end_idx 110 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 090 --end_idx 110 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbloSxa92ddp"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 025 --end_idx 030 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 025 --end_idx 030 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8JIPqEpX5jm"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 030 --end_idx 035 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 030 --end_idx 035 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Clcy3UAgyeE3"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 069 --end_idx 069 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 069 --end_idx 069 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCrrXAG_bcJ6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srVvUpsTbcMg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKcpSBoYbcPJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kdFLRsbspQW"
      },
      "source": [
        "##550"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwKo3XiTslHq"
      },
      "outputs": [],
      "source": [
        "20231206155550_15to50_stride16_size64_batchsize512_01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx1ya7UfslKd"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231206155550_og --start_idx 15 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231206155550_og --start_idx 15 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKsTb1PzcqPD"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231206155550_og --start_idx 15 --end_idx 16 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231206155550_og --start_idx 15 --end_idx 16 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kGvrBkotH8c"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231206155550_og --start_idx 30 --end_idx 40 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231206155550_og --start_idx 30 --end_idx 40 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0enyVnfKslM1"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231206155550 --start_idx 40 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231206155550 --start_idx 40 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZBxzSu_b0wA"
      },
      "source": [
        "##500 hide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTaxsDB92dZK"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 050 --end_idx 055 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 050 --end_idx 055 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdKsUO_zyeAJ"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 086 --end_idx 086 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 086 --end_idx 086 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAATRZ7GziNI"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 000 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 000 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeWVdyz7zmgA"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 040 --end_idx 040 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 040 --end_idx 040 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypBAU9zSyeCo"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 030 --end_idx 030 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 030 --end_idx 030 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Se1uJrj2rU4"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 052 --end_idx 052 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 052 --end_idx 052 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I1NIeSR2rXV"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 070 --end_idx 110 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 070 --end_idx 110 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGgl2LR92rZO"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 080 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 000 --end_idx 080 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgy8IqBFtx_y"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231205141500_4_86 --start_idx 086 --end_idx 172 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231205141500_4_86 --start_idx 086 --end_idx 172 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDIe_BWoxqh4"
      },
      "outputs": [],
      "source": [
        "# Play an audio beep. Any audio URL will do.\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kz0Z8PXx0IOg"
      },
      "outputs": [],
      "source": [
        "# Play an audio beep. Any audio URL will do.\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://www.myinstants.com/en/instant/mlg-air-horn/?utm_source=copy&utm_medium=share\").play()')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8VaxztV0Fiq"
      },
      "outputs": [],
      "source": [
        "https://www.myinstants.com/en/instant/mlg-air-horn/?utm_source=copy&utm_medium=share"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_oDwJxm2eyN"
      },
      "outputs": [],
      "source": [
        "20240101215220"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvFrXOxdvqYL"
      },
      "source": [
        "##*433"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exndMAEQUw3I"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433_og --start_idx 40 --end_idx 40 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433_og --start_idx 40 --end_idx 40 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTn6163XqDyH"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433_og --start_idx 20 --end_idx 20 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433_og --start_idx 20 --end_idx 20 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8G9-BWAfUxti"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433_og --start_idx 16 --end_idx 16 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433_og --start_idx 16 --end_idx 16 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3kd5CuKUxv4"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433_og --start_idx 10 --end_idx 20 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433_og --start_idx 10 --end_idx 20 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmmPj23pUxyS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrpgMljpVuox"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433_og --start_idx 10 --end_idx 40 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433_og --start_idx 10 --end_idx 40 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3J3i2-4VurP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrTKAnDjVutv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjW2SIKSvuA8"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433_2_64 --start_idx 054 --end_idx 054 --stride 32 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433_2_64 --start_idx 054 --end_idx 054 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0-QSTwav9WV"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 30 --end_idx 36 --stride 16 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 30 --end_idx 36 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGBXSmILwLVC"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 30 --end_idx 36 --stride 16 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 30 --end_idx 36 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maWQ5_5YwFh7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqNFLfF_wFkw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzRYRzyrwFnX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_-_zSkywFp8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GO8SKanLXGU"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 26--end_idx 32 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 26 --end_idx 32 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwMr0SGGyRT0"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 40 --end_idx 58 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 40 --end_idx 58 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we0pyAReyRWa"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 42 --end_idx 52 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 42 --end_idx 42 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNiAr-mmyRY0"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 32 --end_idx 34 --stride 16 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 32 --end_idx 34 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzIp5X6I2eu7"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 42 --end_idx 44 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 42 --end_idx 44 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YW1nlxey2exJ"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 20 --end_idx 30 --stride 16 --size 32\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 20 --end_idx 30 --stride 16 --size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6ecsTNq2e00"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 30 --end_idx 40 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 30 --end_idx 40 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zhMB-ucyRbT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2fSEzFW2cvv"
      },
      "source": [
        "##*0251"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6jIteUl2e0n"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231221180251_og --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231221180251_og --start_idx 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O7DLKvrjRmC"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231221180251_og --start_idx 30 --end_idx 40 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20231221180251_og --start_idx 30 --end_idx 40 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRNvoYk62etg"
      },
      "outputs": [],
      "source": [
        "#!python inference_v23_normal.py --reverse 0 --segment_id 20231221180251_og --start_idx 48 --end_idx 64 --stride 16 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20231221180251_og --start_idx 48 --end_idx 64 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP3IIAWu2ev1"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20231221180251_og --start_idx 00 --end_idx 10 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20231221180251_og --start_idx 00 --end_idx 10 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV1b7UnyjQRD"
      },
      "source": [
        "#632"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCB78Di4WEil"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240625010632 --start_idx 10 --end_idx 20 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240625010632 --start_idx 10 --end_idx 20 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WsDm2-0Dk4W"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240625010632 --start_idx 25 --end_idx 35 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240625010632 --start_idx 25 --end_idx 35 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwFy7fhYCybq"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240625010632 --start_idx 40 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240625010632 --start_idx 40 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsbDPeL2Dk6-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9dbUhtuDk9o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRyW6eM3CyeQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmnGOnpA786D"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240624014055 --start_idx 50 --end_idx 59 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240624014055 --start_idx 50 --end_idx 59 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgoGdKMK8bqz"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240624014055 --start_idx 20 --end_idx 30 --stride 32 --size 64\n",
        "!python inference_v23_nreversed.py --reverse 1 --segment_id 20240624014055 --start_idx 20 --end_idx 30 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eZisq_YwSXC"
      },
      "source": [
        "##959"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jObadyN5vpqN"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 10 --end_idx 16 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 10 --end_idx 16 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4vjoGa7wQeZ"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 20 --end_idx 26 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 20 --end_idx 26 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htznIeZEwkZB"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 30 --end_idx 36 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 30 --end_idx 36 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2NuJ8mOwuvC"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 30 --end_idx 40 --stride 16 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 30 --end_idx 40 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL4VSudewkbc"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 40 --end_idx 46 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 40 --end_idx 46 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peB5IP6I788Y"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240624014055 --start_idx 40 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240624014055 --start_idx 40 --end_idx 50 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PlOfxGXwkdy"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 50 --end_idx 56 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 50 --end_idx 56 --stride 32 --size 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6hUTjW-H0Iu"
      },
      "source": [
        "#gp model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bafVfnoEnieS",
        "outputId": "89a23a7d-e812-4019-f247-4439085fc195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/A_Scroll/inkception-3d\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpQdhsd4IFW"
      },
      "source": [
        "20240623200654_5_64_50to60_stride32_size64_batchsize512_01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to6tGGK_nMkr",
        "outputId": "790c8f37-b973-48e5-f17e-e6ead8782db4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/A_Scroll/inkception-3d/wandb/run-20240725_081344-ybfrjx0u\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mALL_scrolls_tta\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/ybfrjx0u\u001b[0m\n",
            "\n",
            "Loading image 1 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/050.tif\n",
            "Loading image 2 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/051.tif\n",
            "Loading image 3 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/052.tif\n",
            "Loading image 4 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/053.tif\n",
            "Loading image 5 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/054.tif\n",
            "Loading image 6 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/055.tif\n",
            "Loading image 7 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/056.tif\n",
            "Loading image 8 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/057.tif\n",
            "Loading image 9 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/058.tif\n",
            "Loading image 10 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/059.tif\n",
            "Loading image 11 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/060.tif\n",
            "Loading image 12 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/061.tif\n",
            "Loading image 13 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/062.tif\n",
            "Loading image 14 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/063.tif\n",
            "Loading image 15 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/064.tif\n",
            "Loading image 16 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/065.tif\n",
            "Loading image 17 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/066.tif\n",
            "Loading image 18 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/067.tif\n",
            "Loading image 19 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/068.tif\n",
            "Loading image 20 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/069.tif\n",
            "Loading image 21 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/070.tif\n",
            "Loading image 22 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/071.tif\n",
            "Loading image 23 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/072.tif\n",
            "Loading image 24 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/073.tif\n",
            "Loading image 25 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/074.tif\n",
            "Loading image 26 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/075.tif\n",
            "Loading image 27 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/076.tif\n",
            "Loading image 28 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/077.tif\n",
            "Loading image 29 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/078.tif\n",
            "Loading image 30 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/079.tif\n",
            "Successfully loaded 30 images.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            " 55% 3350/6093 [1:22:29<1:07:18,  1.47s/it]"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_5.py --segment_id 20240623200654_5_64 --start 050 --num_layers 30 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a-mcllw63TV",
        "outputId": "9af11ae5-8ff7-4626-b471-ad5b5f535737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initialising...\n",
            "Device type: cuda\n",
            "Device count: 1\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/A_Scroll/inkception-3d/wandb/run-20240725_080445-a55p3auf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mALL_scrolls_tta\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/a55p3auf\u001b[0m\n",
            "\n",
            "Loading image 1 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/050.tif\n",
            "Loading image 2 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/051.tif\n",
            "Loading image 3 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/052.tif\n",
            "Loading image 4 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/053.tif\n",
            "Loading image 5 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/054.tif\n",
            "Loading image 6 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/055.tif\n",
            "Loading image 7 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/056.tif\n",
            "Loading image 8 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/057.tif\n",
            "Loading image 9 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/058.tif\n",
            "Loading image 10 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/059.tif\n",
            "Loading image 11 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/060.tif\n",
            "Loading image 12 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/061.tif\n",
            "Loading image 13 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/062.tif\n",
            "Loading image 14 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/063.tif\n",
            "Loading image 15 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/064.tif\n",
            "Loading image 16 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/065.tif\n",
            "Loading image 17 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/066.tif\n",
            "Loading image 18 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/067.tif\n",
            "Loading image 19 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/068.tif\n",
            "Loading image 20 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/069.tif\n",
            "Loading image 21 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/070.tif\n",
            "Loading image 22 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/071.tif\n",
            "Loading image 23 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/072.tif\n",
            "Loading image 24 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/073.tif\n",
            "Loading image 25 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/074.tif\n",
            "Loading image 26 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/075.tif\n",
            "Loading image 27 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/076.tif\n",
            "Loading image 28 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/077.tif\n",
            "Loading image 29 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/078.tif\n",
            "Loading image 30 of 30...\n",
            "./eval_segments_shared/20240623200654_5_64/layers/079.tif\n",
            "Successfully loaded 30 images.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 56/56 [01:19<00:00,  1.42s/it]\n",
            "\n",
            "Saving predictions...\n",
            "Done.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mALL_scrolls_tta\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius/runs/a55p3auf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ellu/Vesuvius\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240725_080445-a55p3auf/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_4.py --segment_id 20240623200654_5_64 --start 050 --num_layers 30 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmxDTFykoDLa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSUfRuZQnMnB"
      },
      "outputs": [],
      "source": [
        "!python inference_timesformer_2.py --segment_id 20240623200654_5_64 --start 50 --num_layers 10 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIVaJ3WonMpb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWSN1kPEnMrp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-ZQr5SOH1QS"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2rBwwxOH1Si"
      },
      "outputs": [],
      "source": [
        "!python inference_v24_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt\n",
        "!python inference_v24_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03THT9uOH1Uj",
        "outputId": "56ff1784-127d-4890-8bc0-8d0a916dc0cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/A_Scroll/inkception-3d/inference_timesformer_13.py\", line 301, in <module>\n",
            "    model=RegressionPLModel.load_from_checkpoint(args.model_path,strict=False, map_location=device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1543, in load_from_checkpoint\n",
            "    loaded = _load_from_checkpoint(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\", line 63, in _load_from_checkpoint\n",
            "    checkpoint = pl_load(checkpoint_path, map_location=map_location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/cloud_io.py\", line 51, in _load\n",
            "    with fs.open(path_or_url, \"rb\") as f:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/spec.py\", line 1241, in open\n",
            "    f = self._open(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py\", line 184, in _open\n",
            "    return LocalFileOpener(path, mode, fs=self, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py\", line 315, in __init__\n",
            "    self._open()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py\", line 320, in _open\n",
            "    self.f = open(self.path, mode=self.mode)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/A_Scroll/inkception-3d/models/timesformer_wild15_20230702185753_0_fr_i3depoch=12.ckpt'\n"
          ]
        }
      ],
      "source": [
        "#!python inference_timesformer_13.py --reverse 0 --segment_id 20231205141500 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeOxoizEH1W0",
        "outputId": "8011a7e6-5eca-4b95-f82e-07f12a26c568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: inference_timesformer_13.py [--segment_id [SEGMENT_ID ...]] [--segment_path SEGMENT_PATH]\n",
            "                                   [--model_path MODEL_PATH] [--out_path OUT_PATH]\n",
            "                                   [--stride STRIDE] [--start_idx START_IDX] [--workers WORKERS]\n",
            "                                   [--batch_size BATCH_SIZE] [--size SIZE] [--reverse REVERSE]\n",
            "                                   [--device DEVICE] [-h]\n",
            "inference_timesformer_13.py: error: unrecognized arguments: --num_layers 30\n"
          ]
        }
      ],
      "source": [
        "!python inference_timesformer_13.py --reverse 0 --segment_id 20240102231959 --start 20 --num_layers 30 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmC29TD1lKQj"
      },
      "outputs": [],
      "source": [
        " --start 00 --num_layers 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxonSavFZSSN"
      },
      "source": [
        "#title\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzCz4x9vTG83"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aFWA-2IMKiO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5Edq1p7dq6i"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 16 --end_idx 20 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAnH68ng9QZO"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 20 --end_idx 22 --stride 16 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJodCKwjnKAw"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 20 --end_idx 22 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFtrErU89YIX"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 26 --end_idx 32 --stride 16 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfIozmn5wZj5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzerNc6RnKDK"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 50 --end_idx 60 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwYZ4UlXnKF8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhnSPkJKnKIZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfwr4BZZnKKo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nReh1n8rm9JI"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 00 --end_idx 06 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 00 --end_idx 06 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5SIjcMum9MA"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 11 --end_idx 16 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 11 --end_idx 16 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Bfw1VqQm9Rv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNkvaoT3m9UX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxhmOpShm9XB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3BQYONlUwQB"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 32 --end_idx 46 --stride 16 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYFs1hfRUwSR"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 40 --end_idx 50 --stride 32 --size 32 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgZsSNlBUwUd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH9NWuTwMMtV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "F06XkBtlMJRn"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240610063907 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240610063907 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaekvFvyjXav"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240610063907 --start_idx 20 --end_idx 50 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240610063907 --start_idx 20 --end_idx 50 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wad1DOdDjXdm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOowjVsim5f4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HHtkWZtdq9P"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 30 --end_idx 40 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 30 --end_idx 40 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoTS7Uwpdq_W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bHIh5gXdrGQ"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXktZihZXZyb"
      },
      "outputs": [],
      "source": [
        "20231206155550"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5frJKjrYGSL"
      },
      "outputs": [],
      "source": [
        "20240101215220"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_PN1vNyTcMZ"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240109095720 --start_idx 40 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240109095720 --start_idx 40 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6TkEX-IdrIx"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 20 --end_idx 50 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 20 --end_idx 50 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjdq-hkZdrLp"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvVIZMMFw9SK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HSOJiqDw9U7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8kC296mw9W4"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 32 --end_idx 36 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 32 --end_idx 36 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlwc6-yqZ7Nt"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 20 --end_idx 50 --stride 16 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 20 --end_idx 50 --stride 16 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxnttUGMZyFb"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 28 --end_idx 38 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 28 --end_idx 38 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP45gW1ZUmLZ"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ0KOGlTZ4Ni"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 10 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 10 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "076C-G4yZ9L_"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 50 --end_idx 60 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 50 --end_idx 60 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmO5USXSUmN1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlE1_5qNUmQW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3JdLlIKUmS6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puFca7Lrmxm0"
      },
      "source": [
        "##seg 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kTtSeSQO7Oib"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 8 --end_idx 8 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q24IMXrQZQYP"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 8 --end_idx 8 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9012qV3ZQZ-"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 24 --end_idx 24 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGkYLfkAZQil"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 26 --end_idx 26 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wc0hmUi7OlI"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 50 --end_idx 50 --stride 8 -size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uyc90nbLTOOU"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 42 --end_idx 54 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0Vocc6wO7CQ"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 28 --end_idx 30 --stride 8 --size 64\n",
        "#!python inference_v22_reversed.py --reverse 1 --segment_id 20231205141500 --start_idx 00 --end_idx 00 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Brdu2OgHO7Er"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 42 --end_idx 44 --stride 16 --size 64\n",
        "#!python inference_v22_reversed.py --reverse 1 --segment_id 20231205141500 --start_idx 00 --end_idx 00 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cJCLZtVO7G7"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 8 --end_idx 11 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QPEfgq4_wbw"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 4 --end_idx 10 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkjYA4lH_wek"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 18 --end_idx 22 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y13PUBUF_whY"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 38 --end_idx 44 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htzoOYaU_wj0"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 44 --end_idx 48 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktBZBEf7_9ou"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 49 --end_idx 54 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IemlPr9jZ7QK"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 02 --end_idx 03 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20231205141500 --start_idx 02 --end_idx 03 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi64nJ3DcZC0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FciyDmpZ7Sj"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 53 --end_idx 54 --stride 16 --size 64\n",
        "#!python inference_v22_reversed.py --reverse 1 --segment_id 20231205141500 --start_idx 53 --end_idx 60 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6D9xXfCPZ7Uq"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 28 --end_idx 29 --stride 16 --size 64\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20231205141500 --start_idx 28 --end_idx 29 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzlK-mofZ7XL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OQPqIXMZ7Za"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231205141500 --start_idx 28 --end_idx 36 --stride 16 --size 64\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20231205141500 --start_idx 28 --end_idx 36 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSlevCvFRegW"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231206155550 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v22_reversed.py --reverse 1 --segment_id 20231206155550 --start_idx 00 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCCnkDOV1ELK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeLCp-NO1ENz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg2OB8SI1EQq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwDRumGDwPOc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eFNR-F9RUyl"
      },
      "outputs": [],
      "source": [
        "!python inference_v22_normal.py --reverse 0 --segment_id 20231206155550 --start_idx 06 --end_idx 09 --stride 32 --size 64\n",
        "#!python inference_v22_reversed.py --reverse 1 --segment_id 20231206155550--start_idx 00 --end_idx 00 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ujOi2AvwOE8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUmAYkUFsyjd"
      },
      "source": [
        "##630"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-80rQsQyCeuK"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240107134630 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240107134630 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2Z8Qy-qHcp4"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240107134630 --start_idx 0 --end_idx 10 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240107134630 --start_idx 0 --end_idx 10 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQRSa7sHHcsM"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240107134630 --start_idx 10 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240107134630 --start_idx 10 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XZwoOgWHcvJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ys_fpqudNytq"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240107134630 --start_idx 20 --end_idx 34 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240107134630 --start_idx 20 --end_idx 34 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W36hy3X61qFH"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240107134630 --start_idx 50 --end_idx 58 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240107134630 --start_idx 50 --end_idx 58 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JYoWKZkt3AS"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240107134630 --start_idx 0 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240107134630 --start_idx 0 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3OVF3Qit3DB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikT5_yKGt3F8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mhCkCfis95E"
      },
      "source": [
        "##1002"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV1AOUmRCewx"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20231016151002 --start_idx 0 --end_idx 60 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20231016151002 --start_idx 0 --end_idx 20 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf00PuCRCezX"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 50 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 50 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtGh6zTNCe3B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggdb5sRmIuEC"
      },
      "source": [
        "##220"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSn4uoI46drG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RUIitRFIvwX"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 30 --end_idx 34--stride 8 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 30 --end_idx 34 --stride 8 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpR_X3K4Ix1F"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 40 --end_idx 64--stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 40 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-SCnWRtnVuv"
      },
      "source": [
        "###reversed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9G60G-BnKcc"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220_reversed --start_idx 00 --end_idx 01--stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220_reversed --start_idx 00 --end_idx 01 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HZDjHUznaIz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xBpDpbznaLV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUiIP7rlnad_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7XNsjk-kirF"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 60 --end_idx 64--stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 60 --end_idx 64 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PpGlUOEkitc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7kbPNWGkiwM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8PHohzbkd_M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcxUodDikeIZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uT7yItuIx3_"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 30 --end_idx 50--stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 30 --end_idx 50 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF3lnS7IIx6U"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 30 --end_idx 40--stride 16 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 30 --end_idx 40 --stride 16 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ULxz0KfLlHo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWvMkUswLlKN"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 40 --end_idx 54--stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 40 --end_idx 54--stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWi6avj-LlNG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrhgwsXpCeZp"
      },
      "source": [
        "#end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV0cNmF0CjEC"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/A_Scroll/inkception-3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX-T53N016L5"
      },
      "outputs": [],
      "source": [
        "20240101215220"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbmEvwSK18lw"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 0 --end_idx 64 --stride 42 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 0 --end_idx 64 --stride 42 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iOzJ2f718od"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 0 --end_idx 20 --stride 42 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 0 --end_idx 20 --stride 42 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAuSPvp42OCa"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 0 --end_idx 10 --stride 32 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo9vfe2i2GtN"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 0 --end_idx 20 --stride 50 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 0 --end_idx 20 --stride 50 --size 64 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99QuMkR92G1P"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 28 --end_idx 40 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 28 --end_idx 40 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIu3-Qq72G9p"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240101215220 --start_idx 28 --end_idx 40 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240101215220 --start_idx 28 --end_idx 40 --stride 32 --size 128 --model_path /content/drive/MyDrive/A_Scroll/inkception-3d/models/valid_20230827161847_0_fr_i3depoch=7.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxuVSDFW5OND"
      },
      "source": [
        "#OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDVinXGL5PZ7"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "# Load the image from the provided path\n",
        "image_path = \"/content/philodemus_title (3).PNG\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Perform OCR on the image\n",
        "text = pytesseract.image_to_string(image, lang='grc')\n",
        "text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXgmMJxW5Pcj"
      },
      "outputs": [],
      "source": [
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFAEF8Rv5PfM"
      },
      "outputs": [],
      "source": [
        "# Perform OCR on the image using the default language (English) to see if any readable text is captured\n",
        "text = pytesseract.image_to_string(image)\n",
        "text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwt2Fyaam6b2"
      },
      "source": [
        "#hide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bswKeASYOBFi"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 050 --end_idx 080 --stride 8 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 050 --end_idx 080 --stride 8 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syMsVg5IOF-b"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 000 --end_idx 010 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 000 --end_idx 010 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyPIuZvTN9jM"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240109095720_64 --start_idx 000 --end_idx 000 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240109095720_64 --start_idx 000 --end_idx 000 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ5BazWrN9lj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi9lgLebN9ny"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtQbmpTVN9qO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4hK7IDHBLbK"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240107134630_48 --start_idx 00 --end_idx 96 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240107134630_48 --start_idx 00 --end_idx 96 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oEeULHf7w6T"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240107134630_48 --start_idx 20 --end_idx 50 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240107134630_48 --start_idx 20 --end_idx 50 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9V0AG4q7w8t"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240107134630_48 --start_idx 0 --end_idx 10 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240107134630_48 --start_idx 00 --end_idx 10 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq6ccxZR7w_C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXgMnRRv7xBh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z34WxgUX59WF"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240107134630_48 --start_idx 00 --end_idx 16 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240107134630_48 --start_idx 00 --end_idx 16 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL1GfiH-59Yi"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240107134630_48 --start_idx 80 --end_idx 96 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240107134630_48 --start_idx 80 --end_idx 96 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUuHWxql59ax"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiOTEdxdADCr"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 000 --end_idx 020 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 000 --end_idx 020 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXI3p1eYws5k"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 064 --end_idx 064 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 064 --end_idx 064 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLLzk9vaCYxM"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240116164433 --start_idx 108 --end_idx 128 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240116164433 --start_idx 108 --end_idx 128 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w5q4J8ECY1y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ql7oPf_CY4E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G04pL0KvZfsd"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 20 --end_idx 30 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 20 --end_idx 30 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HZhGTT_N7Ca"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20231206155550 --start_idx 00 --end_idx 64 --stride 16 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20231206155550 --start_idx 00 --end_idx 64 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byuvTzHQZemo"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20231206155550 --start_idx 20 --end_idx 50 --stride 16 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20231206155550 --start_idx 20 --end_idx 50 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWK-Xv61Zih5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVSosPgQZikN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y4ll8ikZimj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yk5ZaqtM7dg"
      },
      "outputs": [],
      "source": [
        "# Play an audio beep. Any audio URL will do.\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACRLO3wbZipN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcKQkjWuZiud"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCU0nKnWOtIi"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240704153520 --start_idx 0 --end_idx 64 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240704153520 --start_idx 0 --end_idx 64 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSnX-aD5iJpr"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240704153520 --start_idx 20 --end_idx 50 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240704153520 --start_idx 20 --end_idx 50 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMN8Mz7OcXqM"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240704153520 --start_idx 48 --end_idx 64 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240704153520 --start_idx 48 --end_idx 64 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9La_8mgcXvQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lsgRXEEcXxk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Pi0QkzF5ntn"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240704153520 --start_idx 00 --end_idx 10 --stride 8 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240704153520 --start_idx 00 --end_idx 10 --stride 8 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFCsvY1gBLdo"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240626040604 --start_idx 40 --end_idx 64 --stride 4 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240626040604 --start_idx 40 --end_idx 64 --stride 4 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxaA_HqJBLlC"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240102231959 --start_idx 20 --end_idx 50 --stride 4 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240102231959 --start_idx 20 --end_idx 50 --stride 4 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Vk3c9QlOtFb"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240626040604 --start_idx 00 --end_idx 20 --stride 2 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240626040604 --start_idx 00 --end_idx 20 --stride 2 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUVaKbK-uMjO"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 000 --end_idx 064 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 000 --end_idx 064 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8ZrjOwIuMl2"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 064 --end_idx 128 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 064 --end_idx 128 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ey-IqW-ug7T"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 020 --end_idx 050 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 020 --end_idx 050 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDhh366oSo19"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 060 --end_idx 128 --stride 16 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 060 --end_idx 128 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAL-h5klSo4p"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 000 --end_idx 042 --stride 32 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 000 --end_idx 042 --stride 32 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OR2-F2CCx9L"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 000 --end_idx 128 --stride 08 --size 64\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 000 --end_idx 128 --stride 08 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsrIGMS1o8Cs"
      },
      "outputs": [],
      "source": [
        "!python inference_v25_normal.py --reverse 0 --segment_id 20240701175700 --start_idx 000 --end_idx 128 --stride 16 --size 128\n",
        "!python inference_v25_reversed.py --reverse 1 --segment_id 20240701175700 --start_idx 000 --end_idx 128 --stride 16 --size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-j8U5APuLKu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe2vhYk3uLNj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFINGt2Sug9_"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240627002342 --start_idx 00 --end_idx 64 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240627002342 --start_idx 00 --end_idx 64 --stride 32 --size 128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvfeM3FxuhAQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLIkDBIKuhC2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojmGnWdeN6i5"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240629031634 --start_idx 22 --end_idx 52 --stride 16 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240629031634 --start_idx 22 --end_idx 52 --stride 16 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ovc-rm-N7JS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcvpE5B5780o"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240626040604 --start_idx 00 --end_idx 64 --stride 32 --size 128\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240626040604 --start_idx 00 --end_idx 64 --stride 32 --size 128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPCyoXE1CyZD"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240626040604 --start_idx 20 --end_idx 50 --stride 08 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240626040604 --start_idx 20 --end_idx 50 --stride 08 --size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qchjfUgK_qSY"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240626040604 --start_idx 0 --end_idx 20 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240626040604 --start_idx 0 --end_idx 20 --stride 32 --size 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD0qp7Gl783J"
      },
      "outputs": [],
      "source": [
        "!python inference_v23_normal.py --reverse 0 --segment_id 20240626040604 --start_idx 48 --end_idx 58 --stride 32 --size 64\n",
        "!python inference_v23_reversed.py --reverse 1 --segment_id 20240626040604 --start_idx 48 --end_idx 58 --stride 32 --size 64\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "O0Zxb1PzrbUx",
        "6mqbqcsf7n6M",
        "46qTxzH3m_DC",
        "t2BW9j77nNYu",
        "8k02sycA2FS0",
        "l1rz5Wj0kT9T",
        "qqAvNCfBKHvJ",
        "ApVL-44gdZw7",
        "iaflAeSen9GA",
        "mlpWPgvYIsFb",
        "wVR2deTXbLcs",
        "fhlFz7fyLs0C",
        "dLzTrgFmLe8k",
        "udjB_gD9TrFQ",
        "8AFQjE_VV4dw",
        "-ckuGjaRVre1",
        "pKfV55vSl1_P",
        "18uSgs1enwmp",
        "JcOlXcgSJvTs",
        "bqVhd1vT2fzX",
        "ZJB8bCfsjf97",
        "kH9frdLTdsAZ",
        "a8EHiMvu6j0p",
        "7bvJvlXksl3y",
        "0kdFLRsbspQW",
        "dZBxzSu_b0wA",
        "CvFrXOxdvqYL",
        "X2fSEzFW2cvv",
        "pV1b7UnyjQRD",
        "0eZisq_YwSXC",
        "f6hUTjW-H0Iu",
        "QxonSavFZSSN",
        "puFca7Lrmxm0",
        "rUmAYkUFsyjd",
        "6mhCkCfis95E",
        "ggdb5sRmIuEC",
        "l-SCnWRtnVuv",
        "lrhgwsXpCeZp",
        "mxuVSDFW5OND",
        "lwt2Fyaam6b2"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}